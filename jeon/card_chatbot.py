
import json
import os
import time
import torch
from typing import List, Any, Dict
from dotenv import load_dotenv

# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬
from openai import OpenAI
import cohere
from sentence_transformers import SentenceTransformer
import chromadb

# LangChain ê´€ë ¨
from langchain_openai import ChatOpenAI
from langchain_core.documents import Document
from langchain_core.runnables import RunnablePassthrough
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_community.vectorstores import Chroma
from langchain_cohere import CohereRerank

# íŒ¨í‚¤ì§€ ê²½ë¡œ ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•œ ì²˜ë¦¬
try:
    from langchain.retrievers.contextual_compression import ContextualCompressionRetriever
except ImportError:
    from langchain.retrievers import ContextualCompressionRetriever

from langchain_core.retrievers import BaseRetriever

# 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ==========================================
# [CUSTOM CLASS] 1. ì„ë² ë”© ë° ë¦¬íŠ¸ë¦¬ë²„ ì„¤ì •
# ==========================================

class GemmaEmbeddings:
    """Gemma-300m ì „ìš© ì„ë² ë”© í´ë˜ìŠ¤"""
    def __init__(self, model_path: str):
        device = "cuda" if torch.cuda.is_available() else "cpu"
        self.model = SentenceTransformer(model_path, device=device)

    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        return self.model.encode([f"title: none | text: {text}" for text in texts]).tolist()

    def embed_query(self, text: str) -> List[float]:
        return self.model.encode(f"task: search result | query: {text}").tolist()

class CardANDRetriever(BaseRetriever):
    """ë©€í‹° ì˜ë„ êµì§‘í•©(AND) ê²€ìƒ‰ ë° ì „ì²´ ë°ì´í„° ë³µì› ë¦¬íŠ¸ë¦¬ë²„"""
    vectorstore: Any
    card_map: Dict
    intent_extractor: Any
    search_depth: int = 200

    def _get_relevant_documents(self, query: str) -> List[Document]:
        # 1. ì˜ë„ ì¶”ì¶œ (LLM í™œìš©)
        keywords_json = self.intent_extractor.invoke({"question": query})
        try:
            search_intents = json.loads(keywords_json.replace("```json", "").replace("```", ""))
        except:
            search_intents = [query]

        # 2. ê° ì˜ë„ë³„ ê²€ìƒ‰ ìˆ˜í–‰
        intent_scores = []
        for intent in search_intents:
            results = self.vectorstore.similarity_search_with_relevance_scores(intent, k=self.search_depth)
            current_hits = {str(doc.metadata['card_id']): score for doc, score in results}
            intent_scores.append(current_hits)

        # 3. êµì§‘í•©(AND) í•„í„°ë§
        common_ids = set(intent_scores[0].keys())
        for hits in intent_scores[1:]:
            common_ids &= set(hits.keys())

        if not common_ids:
            common_ids = set(list(intent_scores[0].keys())[:20])

        # 4. ì „ì²´ ë°ì´í„° ë³µì› (ê²€ìƒ‰ì€ idxë¡œ, ë‹µë³€ ë°ì´í„°ëŠ” ì›ë³¸ ì „ì²´ë¡œ)
        final_docs = []
        for c_id in common_ids:
            total_score = sum(intent_map[c_id] for intent_map in intent_scores if c_id in intent_map)
            card = self.card_map.get(c_id) # ì—¬ê¸°ì„œ ëª¨ë“  ì •ë³´ê°€ ë‹´ê¸´ Dictë¥¼ ê°€ì ¸ì˜´
            if not card: continue

            # LLMì—ê²Œ ì „ë‹¬í•  í’ë¶€í•œ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
            # ì—¬ëŸ¬ ì¹´í…Œê³ ë¦¬ì˜ contentë¥¼ í•©ì³ì„œ ì „ë‹¬
            full_benefits = " / ".join(card['full_details'])

            final_docs.append(Document(
                page_content=full_benefits,
                metadata={
                    "total_score": total_score,
                    "card_id": c_id,
                    "name": card['name'],
                    "corp": card['corp'],
                    "annual_fee": card['metadata'].get('annual_fee'),
                    "min_performance": card['metadata'].get('min_performance'),
                    "structured": card['structured'] # ai_structured ì „ì²´ í¬í•¨
                }
            ))

        return sorted(final_docs, key=lambda x: x.metadata['total_score'], reverse=True)

# ==========================================
# [CORE] 2. ë©”ì¸ RAG í´ë˜ìŠ¤
# ==========================================

class CardConciergeRAG:
    def __init__(self, model_path, db_path, data_path):
        self.embeddings = GemmaEmbeddings(model_path)
        self.data_path = data_path

        self.card_map = self._setup_card_map()
        self.vectorstore = Chroma(
            collection_name="card_benefits",  
            persist_directory=db_path, 
            embedding_function=self.embeddings
        )
        self.chain = self._build_chain()

    def _setup_card_map(self):
        """ì›ë³¸ JSONì„ ID ê¸°ë°˜ìœ¼ë¡œ ë§µí•‘ (ëª¨ë“  ì¹´í…Œê³ ë¦¬ ì •ë³´ í†µí•©)"""
        with open(self.data_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        mapping = {}
        for item in data:
            c_id = str(item['metadata']['card_id'])
            if c_id not in mapping:
                mapping[c_id] = {
                    "name": item['metadata']['card_name'], 
                    "corp": item['metadata']['corp'],
                    "metadata": item['metadata'],
                    "full_details": [item['content']], 
                    "structured": item['ai_structured']
                }
            else:
                mapping[c_id]["full_details"].append(item['content'])
        return mapping

    def _build_chain(self):
        # ì˜ë„ ì¶”ì¶œê¸°
        intent_prompt = ChatPromptTemplate.from_template("""
        ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì¹´ë“œ ê²€ìƒ‰ì— ê°€ì¥ ì í•©í•œ 2~3ê°œì˜ ê²€ìƒ‰ ë¬¸ì¥ì„ ìƒì„±í•˜ì„¸ìš”.
        í˜•ì‹: ["ë¬¸ì¥1", "ë¬¸ì¥2"] (JSON ë¦¬ìŠ¤íŠ¸ë¡œë§Œ ì‘ë‹µ)
        ì§ˆë¬¸: {question}
        """)
        intent_extractor = (
            intent_prompt 
            | ChatOpenAI(model="gpt-4.1-mini", temperature=0.1, model_kwargs={"top_p": 0.9}) 
            | StrOutputParser()
        )

        # ë¦¬íŠ¸ë¦¬ë²„ + ë¦¬ë­ì»¤
        base_retriever = CardANDRetriever(
            vectorstore=self.vectorstore, 
            card_map=self.card_map, 
            intent_extractor=intent_extractor,
            search_depth=200
        )
        compressor = CohereRerank(model="rerank-v3.5", top_n=3)
        retriever = ContextualCompressionRetriever(base_compressor=compressor, base_retriever=base_retriever)

        # ìµœì¢… ë‹µë³€ í”„ë¡¬í”„íŠ¸ (ì „ë¬¸ê°€ í˜ë¥´ì†Œë‚˜)
        prompt = ChatPromptTemplate.from_template("""
        ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ìµœê³ ì˜ 'ì‹ ìš©/ì²´í¬ì¹´ë“œ ì¶”ì²œ ì „ë¬¸ê°€, Gemma-Bot'ì…ë‹ˆë‹¤. 
        ì œê³µëœ [ì¹´ë“œ ë°ì´í„°]ë¥¼ ë¶„ì„í•˜ì—¬ ì „ë¬¸ì ì´ë©´ì„œë„ ë‹¤ì •í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.

        ì‚¬ìš©ì ì§ˆë¬¸: {question}
        [ì¹´ë“œ ë°ì´í„°]: {context}

        [ë‹µë³€ ì‘ì„± ê°€ì´ë“œ]
        1. **ì „ë¬¸ê°€ ì¸ì‚¬**: ì†Œë¹„ ë‹ˆì¦ˆë¥¼ ì •í™•íˆ ë¶„ì„í–ˆìŒì„ ì•Œë¦¬ë©° ì‹ ë¢°ê° ìˆê²Œ ì‹œì‘í•˜ì„¸ìš”.
        2. **ìˆœìœ„ ê³ ìˆ˜**: Top 1, 2, 3 ìˆœì„œë¥¼ ì ˆëŒ€ ë°”ê¾¸ì§€ ë§ˆì„¸ìš”.
        3. **ìƒì„¸ ë¶„ì„**: 1ìœ„ ì¹´ë“œì˜ í˜œíƒ(ìˆ˜ì¹˜, í•œë„, ì‹¤ì )ì„ êµ¬ì²´ì ì¸ ì˜ˆì‹œì™€ í•¨ê»˜ ìƒì„¸íˆ ì„¤ëª…í•˜ì„¸ìš”.
           ë¶„ì„ ë§ˆì§€ë§‰ì—ëŠ” "ğŸ”— [ì¹´ë“œ ìƒì„¸ì •ë³´ í™•ì¸í•˜ê¸°](ìƒì„¸ ë§í¬)"ë¥¼ í¬í•¨í•˜ì„¸ìš”.
        4. **ë¹„ì„œì˜ ì¡°ì–¸**: í˜œíƒ ì œì™¸ í•­ëª©(benefit_exclusions)ê³¼ ì‹¤ì  ì œì™¸ í•­ëª©(performance_exclusions)ì„ ì°¸ê³ í•˜ì—¬ ì£¼ì˜ì‚¬í•­ì„ ì˜ˆë¦¬í•˜ê²Œ ì¡°ì–¸í•˜ì„¸ìš”.
        5. **í†¤ì•¤ë§¤ë„ˆ**: í‘œ(Table) ì‚¬ìš© ê¸ˆì§€, ë¶ˆë › í¬ì¸íŠ¸ í™œìš©, ë‹µë³€ì€ í•µì‹¬ ìœ„ì£¼ë¡œ ëª…í™•í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.
        """)

        # ë°ì´í„° êµ¬ì¡°í™” í•¨ìˆ˜ (ê²€ìƒ‰ ê²°ê³¼ -> LLMìš© í…ìŠ¤íŠ¸)
        def format_docs(docs):
            formatted = []
            for i, doc in enumerate(docs):
                m = doc.metadata
                s = m.get('structured', {})
                info = (
                    f"### [ì¶”ì²œ ìˆœìœ„ {i+1}ìœ„] {m.get('name')} ({m.get('corp')})\n"
                    f"- ì—°íšŒë¹„: {m.get('annual_fee', 'ì •ë³´ ì—†ìŒ')}\n"
                    f"- ì „ì›” ì‹¤ì  ê¸°ì¤€: {m.get('min_performance', 'ì •ë³´ ì—†ìŒ')}ì›\n"
                    f"- ìƒì„¸ ë§í¬: https://www.card-gorilla.com/card/detail/{m.get('card_id')}\n"
                    f"- í˜œíƒ ìš”ì•½: {s.get('summary', 'ì •ë³´ ì—†ìŒ')}\n"
                    f"- í˜œíƒ ì œì™¸: {', '.join(s.get('benefit_exclusions', ['ì •ë³´ ì—†ìŒ']))}\n"
                    f"- ì‹¤ì  ì œì™¸: {', '.join(s.get('performance_exclusions', ['ì •ë³´ ì—†ìŒ']))}\n"
                    f"- ì¶”ê°€ ì •ë³´: {s.get('additional_info', 'ì •ë³´ ì—†ìŒ')}\n"
                    f"- ìƒì„¸ í˜œíƒ ë°ì´í„°: {doc.page_content}\n"
                )
                formatted.append(info)
            return "\n\n".join(formatted)

        return (
            {
                "context": retriever | format_docs, 
                "question": RunnablePassthrough()
            }
            | prompt 
            | ChatOpenAI(
                model="gpt-4.1-mini", 
                temperature=0.1, 
                model_kwargs={"top_p": 0.1},
                max_tokens=1500
            ) 
            | StrOutputParser()
        )

    def ask(self, query):
        return self.chain.invoke(query)

# ==========================================
# [CLI] 3. CMD ì¸í„°í˜ì´ìŠ¤
# ==========================================

def run_chatbot():
    print("\nğŸš€ ì¹´ë“œ ì¶”ì²œ ì „ë¬¸ê°€ Gemma-Bot ì‹œìŠ¤í…œ ê°€ë™ ì¤‘...")

    try:
        concierge = CardConciergeRAG(
            model_path='./models/gemma-300m-4080super-extreme',
            db_path='./data/chroma_db',
            data_path='./data/FINAL_MASTER_DATA_FIXED_7757.json'
        )
        print("âœ… ìƒë‹´ ì¤€ë¹„ ì™„ë£Œ!")
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return

    print("\n" + "="*60)
    print("   ğŸ’³ ëŒ€í•œë¯¼êµ­ ìµœê³ ì˜ ì¹´ë“œ ì¶”ì²œ ì „ë¬¸ê°€, Gemma-Bot   ")
    print("      (ì¢…ë£Œí•˜ì‹œë ¤ë©´ 'ì¢…ë£Œ' ë˜ëŠ” 'q'ë¥¼ ì…ë ¥í•˜ì„¸ìš”)      ")
    print("="*60)

    while True:
        user_input = input("\n[ğŸ‘¤ ì§ˆë¬¸]: ").strip()
        if user_input.lower() in ['ì¢…ë£Œ', 'q', 'exit']: break
        if not user_input: continue

        print("\n[ğŸ¤– Gemma-Bot]: ìµœì ì˜ ì¹´ë“œë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...", end="", flush=True)
        start_time = time.time()

        try:
            response = concierge.ask(user_input)
            print(f"\r[ğŸ¤– Gemma-Bot] ({time.time() - start_time:.2f}ì´ˆ):")
            print("-" * 60 + "\n" + response + "\n" + "-" * 60)
        except Exception as e:
            print(f"\nâŒ ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    run_chatbot()
