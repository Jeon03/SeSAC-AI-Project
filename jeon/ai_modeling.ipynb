{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e114f7d3",
   "metadata": {},
   "source": [
    "# 1. í™˜ê²½ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ac568a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentence-transformers pandas scikit-learn torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae6c33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba5ffe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses, evaluation, models, LoggingHandler\n",
    "\n",
    "# ë¡œê¹… ì„¤ì •\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s', level=logging.INFO, handlers=[LoggingHandler()])\n",
    "\n",
    "# GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"âœ… í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ì¥ì¹˜: {device}\")\n",
    "\n",
    "\n",
    "# .env íŒŒì¼ ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ì—ì„œ í† í° ê°€ì ¸ì˜¤ê¸°\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "if hf_token:\n",
    "    # í† í°ì„ ì‚¬ìš©í•˜ì—¬ ë¡œê·¸ì¸\n",
    "    login(token=hf_token)\n",
    "    print(\"âœ… Hugging Face ë¡œê·¸ì¸ ì„±ê³µ!\")\n",
    "else:\n",
    "    print(\"âŒ .env íŒŒì¼ì—ì„œ HF_TOKENì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b86d3a",
   "metadata": {},
   "source": [
    "# 2. ë°ì´í„°ì…‹ ë¡œë“œ ë° ë¶„í•  (Train,Val,Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969a5461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "file_path = './data/final_dataset.json' # ìƒì„±í•˜ì‹  íŒŒì¼ëª… í™•ì¸\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    full_dataset = json.load(f)\n",
    "\n",
    "# 2. ë°ì´í„° ë¶„í•  (Train 80% : Temp 20%)\n",
    "train_data, temp_data = train_test_split(\n",
    "    full_dataset, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# 3. ë‚˜ë¨¸ì§€ 20%ë¥¼ ë°˜ìœ¼ë¡œ ë‚˜ëˆ  Val 10% : Test 10%\n",
    "val_data, test_data = train_test_split(\n",
    "    temp_data, \n",
    "    test_size=0.5, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"ğŸ“Š ë°ì´í„° ë¶„í•  ê²°ê³¼\")\n",
    "print(f\"Â· Train: {len(train_data)}ê±´\")\n",
    "print(f\"Â· Validation: {len(val_data)}ê±´\")\n",
    "print(f\"Â· Test: {len(test_data)}ê±´\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730eefb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ë°ì´í„°ëŠ” Triplet(Anchor, Positive, Negative) êµ¬ì¡°ë¡œ ìƒì„±\n",
    "train_samples = [\n",
    "    InputExample(texts=[d['anchor'], d['positive'], d['negative']]) \n",
    "    for d in train_data\n",
    "]\n",
    "\n",
    "# Validation ë°ì´í„°ëŠ” ìœ ì‚¬ë„ ì¸¡ì •ì„ ìœ„í•´ (Anchor, Positive) ìŒìœ¼ë¡œ ìƒì„±\n",
    "val_samples = [\n",
    "    InputExample(texts=[d['anchor'], d['positive']]) \n",
    "    for d in val_data\n",
    "]\n",
    "\n",
    "# í•™ìŠµ ë°ì´í„° ë¡œë” ì„¤ì • (Batch SizeëŠ” ë©”ëª¨ë¦¬ì— ë”°ë¼ 16~32 ì¡°ì ˆ)\n",
    "train_dataloader = DataLoader(train_samples, shuffle=True, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c11aaf6",
   "metadata": {},
   "source": [
    "# 3. ëª¨ë¸ ì •ì˜ ë° ì†ì‹¤í•¨ìˆ˜ ì„¤ì •\n",
    "\n",
    "- Googleì˜ ìµœì‹  embeddinggemma-300m ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "- ì§ˆë¬¸(Anchor)ê³¼ ì •ë‹µ(Positive)ì€ ê°€ê¹ê²Œ, ì˜¤ë‹µ(Negative)ì€ ë©€ê²Œ ë§Œë“œëŠ” Triplet Lossë¥¼ ì‚¬ìš©í•˜ë©°, ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ì¤€ ë§ˆì§„ì„ 0.5ë¡œ ì„¤ì •í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "708cf6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ google/embeddinggemma-300m ë¡œë”© ì¤‘...\n",
      "2026-02-20 21:29:22,417 - Use pytorch device_name: cuda:0\n",
      "2026-02-20 21:29:22,418 - Load pretrained SentenceTransformer: google/embeddinggemma-300m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b35dd30f1614bba81be664a5b9e830f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/573 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jeon\\anaconda3\\envs\\sesac-env\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Jeon\\.cache\\huggingface\\hub\\models--google--embeddinggemma-300m. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49b388f82df54b758aa5a9ba52a47d30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/997 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7719bfef7cb4252a2df316e6332a547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/18.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ed0571af44f4f42bf70b55eb169b27e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/58.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "604b019401164f51a479b975bd1ac602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.49k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebab181f25244fedb1979202d6a0852f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.21G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f8045308b8e4ffea73616058bb42d5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.16M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d259a4492c14383a8e36549526ab63a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.69M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14d46127cfdf410a9478501c79462ba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcd9fe3dd3a14d2c9b3249f287ec75ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/35.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f14fe1a900c407193549c0195da1874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8c988af83c04ed19d4f7086ff4024f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/312 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "962f9cedfaec47e3815e3dc62511ff09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/134 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c2e73bbd5be4961871aee70bef260b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2_Dense/model.safetensors:   0%|          | 0.00/9.44M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2407bd77f4c247df81cf3079691ac7ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/134 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "609e59f7ea4841cfbf14d64027bc66f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "3_Dense/model.safetensors:   0%|          | 0.00/9.44M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-20 21:29:55,364 - 14 prompts are loaded, with the keys: ['query', 'document', 'BitextMining', 'Clustering', 'Classification', 'InstructionRetrieval', 'MultilabelClassification', 'PairClassification', 'Reranking', 'Retrieval', 'Retrieval-query', 'Retrieval-document', 'STS', 'Summarization']\n",
      "âœ… êµ¬ê¸€ ìµœì‹  ëª¨ë¸ ë¡œë“œ ì„±ê³µ!\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, losses, evaluation\n",
    "from datetime import datetime\n",
    "\n",
    "# 1. êµ¬ê¸€ ìµœì‹  Gemma ì„ë² ë”© ëª¨ë¸ ë¡œë“œ (2025ë…„í˜•)\n",
    "model_name = 'google/embeddinggemma-300m'\n",
    "\n",
    "print(f\"ğŸš€ {model_name} ë¡œë”© ì¤‘...\")\n",
    "# trust_remote_code=TrueëŠ” ìµœì‹  ëª¨ë¸ ì•„í‚¤í…ì²˜ë¥¼ ì•ˆì „í•˜ê²Œ ë¶ˆëŸ¬ì˜¤ê¸° ìœ„í•´ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "model = SentenceTransformer(model_name, trust_remote_code=True)\n",
    "print(\"âœ… êµ¬ê¸€ ìµœì‹  ëª¨ë¸ ë¡œë“œ ì„±ê³µ!\")\n",
    "\n",
    "# 2. Triplet Loss ì„¤ì •\n",
    "# Gemma ëª¨ë¸ì€ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³µê°„ì—ì„œ ë§¤ìš° ì •ë°€í•˜ê²Œ ë™ì‘í•˜ë¯€ë¡œ ë§ˆì§„ 0.5ê°€ ì ë‹¹í•©ë‹ˆë‹¤.\n",
    "train_loss = losses.TripletLoss(\n",
    "    model=model, \n",
    "    distance_metric=losses.TripletDistanceMetric.COSINE, \n",
    "    triplet_margin=0.5\n",
    ")\n",
    "\n",
    "# 3. ê²€ì¦ê¸° ì„¤ì •\n",
    "# validation ë°ì´í„°ë¡œ í•™ìŠµ ì¤‘ ì„±ëŠ¥(ìœ ì‚¬ë„ ì ìˆ˜)ì„ ì²´í¬í•©ë‹ˆë‹¤.\n",
    "val_evaluator = evaluation.EmbeddingSimilarityEvaluator.from_input_examples(\n",
    "    val_samples, \n",
    "    name='gemma-benefit-val',\n",
    "    main_similarity='cosine'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce652e1e",
   "metadata": {},
   "source": [
    "# 4. ëª¨ë¸ íŒŒì¸íŠœë‹ (Fine-tuning) ì‹¤í–‰\n",
    "\n",
    "- ë³¸ê²©ì ì¸ í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤. í•™ìŠµ ì†ë„ í–¥ìƒì„ ìœ„í•´ use_amp=Trueë¥¼ ì‚¬ìš©í•˜ë©°, 5 ì—í¬í¬ ë™ì•ˆ ê²€ì¦ ì ìˆ˜ê°€ ê°€ì¥ ë†’ì€ ëª¨ë¸ì„ ìë™ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09817372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ êµ¬ê¸€ Gemma-300m íŒŒì¸íŠœë‹ ì‹œì‘...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c510db45725a47139097268ad5d65ee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='127' max='1945' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 127/1945 22:32 < 5:27:45, 0.09 it/s, Epoch 0.32/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Gemma-benefit-val Pearson Cosine</th>\n",
       "      <th>Gemma-benefit-val Spearman Cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-20 21:40:23,173 - EmbeddingSimilarityEvaluator: Evaluating the model on the gemma-benefit-val dataset in epoch 0.2570694087403599 after 100 steps:\n",
      "2026-02-20 21:40:26,339 - Cosine-Similarity:\tPearson: nan\tSpearman: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jeon\\anaconda3\\envs\\sesac-env\\Lib\\site-packages\\sentence_transformers\\evaluation\\EmbeddingSimilarityEvaluator.py:195: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  eval_pearson, _ = pearsonr(labels, scores)\n",
      "c:\\Users\\Jeon\\anaconda3\\envs\\sesac-env\\Lib\\site-packages\\sentence_transformers\\evaluation\\EmbeddingSimilarityEvaluator.py:196: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  eval_spearman, _ = spearmanr(labels, scores)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-20 21:40:26,343 - Save model to ./output/gemma_card_finetuned_20260220_213426\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mğŸš€ êµ¬ê¸€ Gemma-300m íŒŒì¸íŠœë‹ ì‹œì‘...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# 2. ëª¨ë¸ í•™ìŠµ (fit) ì‹¤í–‰\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_objectives\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loss\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_evaluator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# 100ê±¸ìŒë§ˆë‹¤ val_samplesë¡œ ì„±ëŠ¥ ì²´í¬\u001b[39;49;00m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                          \u001b[49m\u001b[38;5;66;43;03m# 8,000ê±´ ë°ì´í„° ê¸°ì¤€ 5 ì—í¬í¬ê°€ ì ì ˆ\u001b[39;49;00m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluation_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;66;43;03m# ì„±ëŠ¥ ê²€ì¦ ì£¼ê¸°\u001b[39;49;00m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# í•™ìŠµ ì´ˆê¸° ì•ˆì •í™” êµ¬ê°„\u001b[39;49;00m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_best_model\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;66;43;03m# ì ìˆ˜ê°€ ê°€ì¥ ë†’ì€ ëª¨ë¸ë§Œ ìµœì¢… ì €ì¥\u001b[39;49;00m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2e-5\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m# Gemma ê°™ì€ ìµœì‹  ëª¨ë¸ì— ê¶Œì¥ë˜ëŠ” í•™ìŠµë¥ \u001b[39;49;00m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_amp\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m                      \u001b[49m\u001b[38;5;66;43;03m# Mixed Precision ì‚¬ìš© (í•™ìŠµ ì†ë„ í–¥ìƒ ë° ë©”ëª¨ë¦¬ ì ˆì•½)\u001b[39;49;00m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m             \u001b[49m\u001b[38;5;66;43;03m# ì£¼í”¼í„° ë…¸íŠ¸ë¶ì—ì„œ ì§„í–‰ë¥  í™•ì¸\u001b[39;49;00m\n\u001b[32m     22\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mâœ¨ í•™ìŠµ ì™„ë£Œ! ìµœì ì˜ ëª¨ë¸ ì €ì¥ ê²½ë¡œ: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jeon\\anaconda3\\envs\\sesac-env\\Lib\\site-packages\\sentence_transformers\\fit_mixin.py:408\u001b[39m, in \u001b[36mFitMixin.fit\u001b[39m\u001b[34m(self, train_objectives, evaluator, epochs, steps_per_epoch, scheduler, warmup_steps, optimizer_class, optimizer_params, weight_decay, evaluation_steps, output_path, save_best_model, max_grad_norm, use_amp, callback, show_progress_bar, checkpoint_path, checkpoint_save_steps, checkpoint_save_total_limit, resume_from_checkpoint)\u001b[39m\n\u001b[32m    405\u001b[39m         logger.warning(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCheckpoint directory does not exist or is not a directory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheckpoint_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    406\u001b[39m         resume_from_checkpoint = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m408\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jeon\\anaconda3\\envs\\sesac-env\\Lib\\site-packages\\transformers\\trainer.py:2325\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2323\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2324\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2326\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2327\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2328\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2329\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2330\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jeon\\anaconda3\\envs\\sesac-env\\Lib\\site-packages\\transformers\\trainer.py:2674\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2667\u001b[39m context = (\n\u001b[32m   2668\u001b[39m     functools.partial(\u001b[38;5;28mself\u001b[39m.accelerator.no_sync, model=model)\n\u001b[32m   2669\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i != \u001b[38;5;28mlen\u001b[39m(batch_samples) - \u001b[32m1\u001b[39m\n\u001b[32m   2670\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type != DistributedType.DEEPSPEED\n\u001b[32m   2671\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext\n\u001b[32m   2672\u001b[39m )\n\u001b[32m   2673\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m-> \u001b[39m\u001b[32m2674\u001b[39m     tr_loss_step = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2676\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2677\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2678\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m   2679\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch.isinf(tr_loss_step))\n\u001b[32m   2680\u001b[39m ):\n\u001b[32m   2681\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2682\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jeon\\anaconda3\\envs\\sesac-env\\Lib\\site-packages\\transformers\\trainer.py:4071\u001b[39m, in \u001b[36mTrainer.training_step\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m   4068\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type == DistributedType.DEEPSPEED:\n\u001b[32m   4069\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mscale_wrt_gas\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4071\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maccelerator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4073\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss.detach()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jeon\\anaconda3\\envs\\sesac-env\\Lib\\site-packages\\accelerate\\accelerator.py:2848\u001b[39m, in \u001b[36mAccelerator.backward\u001b[39m\u001b[34m(self, loss, **kwargs)\u001b[39m\n\u001b[32m   2846\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   2847\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.scaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2848\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2849\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m learning_rate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.has_lomo_optimizer:\n\u001b[32m   2850\u001b[39m     \u001b[38;5;28mself\u001b[39m.lomo_backward(loss, learning_rate)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jeon\\anaconda3\\envs\\sesac-env\\Lib\\site-packages\\torch\\_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jeon\\anaconda3\\envs\\sesac-env\\Lib\\site-packages\\torch\\autograd\\__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jeon\\anaconda3\\envs\\sesac-env\\Lib\\site-packages\\torch\\autograd\\graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from sentence_transformers import evaluation\n",
    "import os\n",
    "\n",
    "# 1. ì €ì¥ ê²½ë¡œ ë° ë¡œê·¸ í´ë” ìƒì„±\n",
    "output_path = f\"./output/gemma_card_finetuned_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "print(\"ğŸš€ êµ¬ê¸€ Gemma-300m íŒŒì¸íŠœë‹ ì‹œì‘...\")\n",
    "\n",
    "# 2. ëª¨ë¸ í•™ìŠµ (fit) ì‹¤í–‰\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    evaluator=val_evaluator,           # 100ê±¸ìŒë§ˆë‹¤ val_samplesë¡œ ì„±ëŠ¥ ì²´í¬\n",
    "    epochs=5,                          # 8,000ê±´ ë°ì´í„° ê¸°ì¤€ 5 ì—í¬í¬ê°€ ì ì ˆ\n",
    "    evaluation_steps=100,              # ì„±ëŠ¥ ê²€ì¦ ì£¼ê¸°\n",
    "    warmup_steps=int(len(train_dataloader) * 0.1), # í•™ìŠµ ì´ˆê¸° ì•ˆì •í™” êµ¬ê°„\n",
    "    output_path=output_path,\n",
    "    save_best_model=True,              # ì ìˆ˜ê°€ ê°€ì¥ ë†’ì€ ëª¨ë¸ë§Œ ìµœì¢… ì €ì¥\n",
    "    optimizer_params={'lr': 2e-5},     # Gemma ê°™ì€ ìµœì‹  ëª¨ë¸ì— ê¶Œì¥ë˜ëŠ” í•™ìŠµë¥ \n",
    "    use_amp=True,                      # Mixed Precision ì‚¬ìš© (í•™ìŠµ ì†ë„ í–¥ìƒ ë° ë©”ëª¨ë¦¬ ì ˆì•½)\n",
    "    show_progress_bar=True             # ì£¼í”¼í„° ë…¸íŠ¸ë¶ì—ì„œ ì§„í–‰ë¥  í™•ì¸\n",
    ")\n",
    "\n",
    "print(f\"âœ¨ í•™ìŠµ ì™„ë£Œ! ìµœì ì˜ ëª¨ë¸ ì €ì¥ ê²½ë¡œ: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9eff041",
   "metadata": {},
   "source": [
    "## í•™ìŠµ ì „"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79bfd4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š [í•™ìŠµ ì „ ë² ì´ìŠ¤ë¼ì¸ í…ŒìŠ¤íŠ¸ ì‹œì‘]\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7129ee99e504d7ba14573e9a0b0865d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "140c83a8196c4818af33049f82781b19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Sample 1\n",
      "ì§ˆë¬¸: í•™ì›ë¹„ì™€ í¸ì˜ì ì—ì„œ ìì£¼ ê²°ì œë¥¼ í•˜ëŠ”ë°, ì´ëŸ° ê³³ì—ì„œ ...\n",
      "ìœ ì‚¬ë„ ì ìˆ˜: 0.6868\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c477a96c0e954bce88d1ddc56e16402e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3589c31f2ee742f69b703a8530dc99ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Sample 2\n",
      "ì§ˆë¬¸: ë§¤ë‹¬ 200ë§Œì› ì´ìƒ ì‚¬ìš©í•˜ë©´ 1.5% í•˜ë‚˜ë¨¸ë‹ˆê°€ ì ë¦½...\n",
      "ìœ ì‚¬ë„ ì ìˆ˜: 0.7889\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import util\n",
    "\n",
    "# 1. ìƒìœ„ 2ê°œ ìƒ˜í”Œ ê°€ì ¸ì˜¤ê¸°\n",
    "sample_data = [\n",
    "    {\n",
    "        \"anchor\": \"í•™ì›ë¹„ì™€ í¸ì˜ì ì—ì„œ ìì£¼ ê²°ì œë¥¼ í•˜ëŠ”ë°, ì´ëŸ° ê³³ì—ì„œ 5% í• ì¸ì„ ë°›ì„ ìˆ˜ ìˆëŠ” ì¹´ë“œê°€ ìˆì„ê¹Œìš”? ì „ì›” ì‹¤ì  ì¡°ê±´ì´ ê¶ê¸ˆí•©ë‹ˆë‹¤.\",\n",
    "        \"positive\": \"ì´ ì¹´ë“œëŠ” í•™ì›, í¸ì˜ì , ì»¤í”¼ì „ë¬¸ì ì—ì„œ 5% í• ì¸ì„ ì œê³µí•˜ë©°, ì „ì›” ì´ìš©ì‹¤ì ì´ 40ë§Œì› ì´ìƒì¼ ê²½ìš° ì ìš©ë©ë‹ˆë‹¤.\"\n",
    "    },\n",
    "    {\n",
    "        \"anchor\": \"ë§¤ë‹¬ 200ë§Œì› ì´ìƒ ì‚¬ìš©í•˜ë©´ 1.5% í•˜ë‚˜ë¨¸ë‹ˆê°€ ì ë¦½ëœë‹¤ê³  í•˜ëŠ”ë°, ì´ í˜œíƒì´ ì–´ë–¤ ê°€ë§¹ì ì—ì„œ ì ìš©ë˜ëŠ”ì§€ ê¶ê¸ˆí•´ìš”. í•´ì™¸ ê²°ì œ ì‹œì—ë„ ì ë¦½ì´ ë˜ë‚˜ìš”?\",\n",
    "        \"positive\": \"ê¸°ë³¸ì ìœ¼ë¡œ ì§€ë‚œë‹¬ 200ë§Œì› ì´ìƒ ì‚¬ìš© ì‹œ 1.5%ì˜ í•˜ë‚˜ë¨¸ë‹ˆê°€ ì ë¦½ë©ë‹ˆë‹¤. í•´ì™¸ ë§¤ì¶œ ë˜í•œ ì›í™” ì²­êµ¬ ê¸ˆì•¡ì— ëŒ€í•´ ì ë¦½ í˜œíƒì´ ì ìš©ë©ë‹ˆë‹¤.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"ğŸ“Š [í•™ìŠµ ì „ ë² ì´ìŠ¤ë¼ì¸ í…ŒìŠ¤íŠ¸ ì‹œì‘]\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for i, sample in enumerate(sample_data):\n",
    "    # êµ¬ê¸€ ëª¨ë¸ì˜ ì„±ëŠ¥ ê·¹ëŒ€í™”ë¥¼ ìœ„í•´ 'query: ' ì ‘ë‘ì–´ ê¶Œì¥\n",
    "    anchor_emb = model.encode(f\"query: {sample['anchor']}\", convert_to_tensor=True)\n",
    "    positive_emb = model.encode(f\"passage: {sample['positive']}\", convert_to_tensor=True)\n",
    "    \n",
    "    # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°\n",
    "    score = util.cos_sim(anchor_emb, positive_emb).item()\n",
    "    \n",
    "    print(f\"âœ… Sample {i+1}\")\n",
    "    print(f\"ì§ˆë¬¸: {sample['anchor'][:30]}...\")\n",
    "    print(f\"ìœ ì‚¬ë„ ì ìˆ˜: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12895c59",
   "metadata": {},
   "source": [
    "## í•™ìŠµ í›„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79abdc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë² ìŠ¤íŠ¸ ëª¨ë¸ ë¡œë“œ\n",
    "best_model = SentenceTransformer(output_path)\n",
    "\n",
    "print(\"ğŸ” [ìµœì¢… ì„±ëŠ¥ í…ŒìŠ¤íŠ¸]\")\n",
    "for i, sample in enumerate(test_data[:2]):\n",
    "    anchor_emb = best_model.encode(f\"query: {sample['anchor']}\", convert_to_tensor=True)\n",
    "    pos_emb = best_model.encode(f\"passage: {sample['positive']}\", convert_to_tensor=True)\n",
    "    \n",
    "    score = util.cos_sim(anchor_emb, pos_emb).item()\n",
    "    print(f\"Sample {i+1} ìœ ì‚¬ë„: {score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sesac-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
