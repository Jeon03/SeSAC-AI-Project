{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ac568a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentence-transformers pandas scikit-learn torch\n",
    "# !pip install -U sentence_transformers\n",
    "# !pip install huggingface_hub\n",
    "# !pip install chromadb\n",
    "# !pip install -qU cohere langchain_cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "346d7a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b86d3a",
   "metadata": {},
   "source": [
    "# ë°ì´í„°ì…‹ ë¡œë“œ ë° ë¶„í•  (Train,Val,Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969a5461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìµœì í™” ì „\n",
    "# ì´ˆê¸° í•™ìŠµ ëª¨ë¸\n",
    "\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses, evaluation\n",
    "\n",
    "# 1. ëª¨ë¸ ë° ë°ì´í„° ë¡œë“œ (ê²½ë¡œëŠ” ì—¬ìš±ë‹˜ í™˜ê²½ì— ë§ì¶° í™•ì¸í•´ ì£¼ì„¸ìš”)\n",
    "model_id = \"google/embeddinggemma-300m\"\n",
    "model = SentenceTransformer(model_id)\n",
    "\n",
    "def load_json_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# ë°ì´í„° ê²½ë¡œ ë‹¤ì‹œ í•œ ë²ˆ ì²´í¬!\n",
    "train_data = load_json_data('./data/train_dataset.json')\n",
    "val_data = load_json_data('./data/val_dataset.json')\n",
    "\n",
    "# 2. í•™ìŠµìš© ë°ì´í„° ê°ì²´(InputExample) ìƒì„±\n",
    "train_examples = [\n",
    "    InputExample(texts=[item['anchor'], item['positive'], item['negative']])\n",
    "    for item in train_data\n",
    "]\n",
    "\n",
    "# 3. ë°ì´í„° ë¡œë” ë° ì†ì‹¤ í•¨ìˆ˜ ì„¤ì •\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model)\n",
    "\n",
    "# 4. ê²€ì¦ê¸°(Evaluator) ì„¤ì •\n",
    "# í•™ìŠµ ì¤‘ê°„ì— ëª¨ë¸ì˜ ì‹¤ë ¥ì´ ì–¼ë§ˆë‚˜ ëŠ˜ì—ˆëŠ”ì§€ ì²´í¬í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.\n",
    "queries = {str(i): item['anchor'] for i, item in enumerate(val_data)}\n",
    "corpus = {str(i): item['positive'] for i, item in enumerate(val_data)}\n",
    "relevant_docs = {str(i): {str(i)} for i, item in enumerate(val_data)}\n",
    "\n",
    "evaluator = evaluation.InformationRetrievalEvaluator(\n",
    "    queries, corpus, relevant_docs, name=\"card-val-task\"\n",
    ")\n",
    "\n",
    "# 5. í•™ìŠµ ì‹¤í–‰ (model.fit ë°©ì‹ - ëª¨ë“  ë²„ì „ì—ì„œ í˜¸í™˜ë¨)\n",
    "print(\"ğŸš€ [ì•ˆì „ ëª¨ë“œ] Gemma-300M í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    evaluator=evaluator,\n",
    "    epochs=3,                  # ì „ì²´ ë°ì´í„°ë¥¼ 3ë²ˆ í›‘ìŠµë‹ˆë‹¤.\n",
    "    warmup_steps=100,          # ì´ˆê¸° ì•ˆì •í™” ë‹¨ê³„\n",
    "    output_path=\"./models/gemma-300m-finetuned-card\",\n",
    "    evaluation_steps=200,      # 200ë²ˆì˜ ê±¸ìŒë§ˆë‹¤ ì‹œí—˜ì„ ë´…ë‹ˆë‹¤.\n",
    "    save_best_model=True,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "print(\"âœ¨ ëª¨ë“  ê³¼ì •ì´ ëë‚¬ìŠµë‹ˆë‹¤! ./models/gemma-300m-finetuned-card í´ë”ë¥¼ í™•ì¸í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d472ce09",
   "metadata": {},
   "source": [
    "## Gemma-300m ê¸°ë°˜ ì¹´ë“œ í˜œíƒ ê²€ìƒ‰ ëª¨ë¸ íŒŒì¸íŠœë‹\n",
    "\n",
    "- ì´ˆê²½ëŸ‰ íš¨ìœ¨ì„±: íŒŒë¼ë¯¸í„° ìˆ˜ê°€ ì•½ 3ì–µ ê°œë¡œ ì ì–´, ë§¤ìš° ë¹ ë¥¸ í•™ìŠµê³¼ ì¶”ë¡  ì†ë„ë¥¼ ë³´ì¥í•©ë‹ˆë‹¤.\n",
    "- ê°•ë ¥í•œ ê¸°ë³¸ ì„±ëŠ¥: ì‘ì€ ì²´ê¸‰ì„ì—ë„ ë¶ˆêµ¬í•˜ê³  Googleì˜ ìµœì‹  ì•„í‚¤í…ì²˜ê°€ ì ìš©ë˜ì–´, ë¬¸ì¥ì˜ ë§¥ë½ì„ íŒŒì•…í•˜ëŠ” ëŠ¥ë ¥ì´ ë›°ì–´ë‚©ë‹ˆë‹¤.\n",
    "- RAG ìµœì í™”: ì§€ì‹œì–´ë¥¼ ì´í•´í•˜ëŠ” ëŠ¥ë ¥ì´ íƒì›”í•˜ì—¬, ê²€ìƒ‰ ê¸°ë°˜ ìƒì„± ì‹œìŠ¤í…œì˜ í•µì‹¬ì¸ 'ë¬¸ì„œ ì„ë² ë”©' ì‘ì—…ì— ì í•©í•©ë‹ˆë‹¤.\n",
    "\n",
    "Gemma ì„ë² ë”© ëª¨ë¸ì€ íŠ¹ì • ì§€ì‹œì–´(Instruction)ê°€ í¬í•¨ë  ë•Œ ìµœìƒì˜ ì„±ëŠ¥ì„ ë°œíœ˜í•©ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ ì¿¼ë¦¬ì™€ ë¬¸ì„œì— ê°ê° ì ‘ë‘ì‚¬ë¥¼ ë¶™ì—¬ì£¼ëŠ” ì „ì²˜ë¦¬ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "- Query: task: search result | query: {ì§ˆë¬¸}\n",
    "- Document: title: {ì¹´ë“œëª…} | text: {í˜œíƒ ë‚´ìš©}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee5a1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ [Extreme Mode] RTX 4080 Super ê°€ë™! (Batch: 128)\n",
      "ğŸ› ï¸ í™œì„±í™” ê¸°ìˆ : AMP(í˜¼í•©ì •ë°€ë„) + Gradient Checkpointing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e06dae58d3a4107ae13911b7848d035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='490' max='490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [490/490 20:13, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Card-val-task Cosine Accuracy@1</th>\n",
       "      <th>Card-val-task Cosine Accuracy@3</th>\n",
       "      <th>Card-val-task Cosine Accuracy@5</th>\n",
       "      <th>Card-val-task Cosine Accuracy@10</th>\n",
       "      <th>Card-val-task Cosine Precision@1</th>\n",
       "      <th>Card-val-task Cosine Precision@3</th>\n",
       "      <th>Card-val-task Cosine Precision@5</th>\n",
       "      <th>Card-val-task Cosine Precision@10</th>\n",
       "      <th>Card-val-task Cosine Recall@1</th>\n",
       "      <th>Card-val-task Cosine Recall@3</th>\n",
       "      <th>Card-val-task Cosine Recall@5</th>\n",
       "      <th>Card-val-task Cosine Recall@10</th>\n",
       "      <th>Card-val-task Cosine Ndcg@10</th>\n",
       "      <th>Card-val-task Cosine Mrr@10</th>\n",
       "      <th>Card-val-task Cosine Map@100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.603871</td>\n",
       "      <td>0.767742</td>\n",
       "      <td>0.832258</td>\n",
       "      <td>0.913548</td>\n",
       "      <td>0.603871</td>\n",
       "      <td>0.255914</td>\n",
       "      <td>0.166452</td>\n",
       "      <td>0.091355</td>\n",
       "      <td>0.603871</td>\n",
       "      <td>0.767742</td>\n",
       "      <td>0.832258</td>\n",
       "      <td>0.913548</td>\n",
       "      <td>0.752219</td>\n",
       "      <td>0.701285</td>\n",
       "      <td>0.705925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.829677</td>\n",
       "      <td>0.896774</td>\n",
       "      <td>0.958710</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.276559</td>\n",
       "      <td>0.179355</td>\n",
       "      <td>0.095871</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.829677</td>\n",
       "      <td>0.896774</td>\n",
       "      <td>0.958710</td>\n",
       "      <td>0.815290</td>\n",
       "      <td>0.769704</td>\n",
       "      <td>0.772001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.669677</td>\n",
       "      <td>0.833548</td>\n",
       "      <td>0.899355</td>\n",
       "      <td>0.958710</td>\n",
       "      <td>0.669677</td>\n",
       "      <td>0.277849</td>\n",
       "      <td>0.179871</td>\n",
       "      <td>0.095871</td>\n",
       "      <td>0.669677</td>\n",
       "      <td>0.833548</td>\n",
       "      <td>0.899355</td>\n",
       "      <td>0.958710</td>\n",
       "      <td>0.811697</td>\n",
       "      <td>0.764829</td>\n",
       "      <td>0.767191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.668387</td>\n",
       "      <td>0.832258</td>\n",
       "      <td>0.892903</td>\n",
       "      <td>0.962581</td>\n",
       "      <td>0.668387</td>\n",
       "      <td>0.277419</td>\n",
       "      <td>0.178581</td>\n",
       "      <td>0.096258</td>\n",
       "      <td>0.668387</td>\n",
       "      <td>0.832258</td>\n",
       "      <td>0.892903</td>\n",
       "      <td>0.962581</td>\n",
       "      <td>0.813547</td>\n",
       "      <td>0.766013</td>\n",
       "      <td>0.768089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.843871</td>\n",
       "      <td>0.883871</td>\n",
       "      <td>0.958710</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.281290</td>\n",
       "      <td>0.176774</td>\n",
       "      <td>0.095871</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.843871</td>\n",
       "      <td>0.883871</td>\n",
       "      <td>0.958710</td>\n",
       "      <td>0.817749</td>\n",
       "      <td>0.772779</td>\n",
       "      <td>0.775222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.676129</td>\n",
       "      <td>0.849032</td>\n",
       "      <td>0.907097</td>\n",
       "      <td>0.961290</td>\n",
       "      <td>0.676129</td>\n",
       "      <td>0.283011</td>\n",
       "      <td>0.181419</td>\n",
       "      <td>0.096129</td>\n",
       "      <td>0.676129</td>\n",
       "      <td>0.849032</td>\n",
       "      <td>0.907097</td>\n",
       "      <td>0.961290</td>\n",
       "      <td>0.818403</td>\n",
       "      <td>0.772653</td>\n",
       "      <td>0.775015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.681290</td>\n",
       "      <td>0.850323</td>\n",
       "      <td>0.910968</td>\n",
       "      <td>0.966452</td>\n",
       "      <td>0.681290</td>\n",
       "      <td>0.283441</td>\n",
       "      <td>0.182194</td>\n",
       "      <td>0.096645</td>\n",
       "      <td>0.681290</td>\n",
       "      <td>0.850323</td>\n",
       "      <td>0.910968</td>\n",
       "      <td>0.966452</td>\n",
       "      <td>0.823616</td>\n",
       "      <td>0.777909</td>\n",
       "      <td>0.779802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.667097</td>\n",
       "      <td>0.843871</td>\n",
       "      <td>0.904516</td>\n",
       "      <td>0.966452</td>\n",
       "      <td>0.667097</td>\n",
       "      <td>0.281290</td>\n",
       "      <td>0.180903</td>\n",
       "      <td>0.096645</td>\n",
       "      <td>0.667097</td>\n",
       "      <td>0.843871</td>\n",
       "      <td>0.904516</td>\n",
       "      <td>0.966452</td>\n",
       "      <td>0.817409</td>\n",
       "      <td>0.769590</td>\n",
       "      <td>0.771451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.676129</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.899355</td>\n",
       "      <td>0.962581</td>\n",
       "      <td>0.676129</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.179871</td>\n",
       "      <td>0.096258</td>\n",
       "      <td>0.676129</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.899355</td>\n",
       "      <td>0.962581</td>\n",
       "      <td>0.817619</td>\n",
       "      <td>0.771388</td>\n",
       "      <td>0.773507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.669677</td>\n",
       "      <td>0.847742</td>\n",
       "      <td>0.899355</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.669677</td>\n",
       "      <td>0.282581</td>\n",
       "      <td>0.179871</td>\n",
       "      <td>0.096000</td>\n",
       "      <td>0.669677</td>\n",
       "      <td>0.847742</td>\n",
       "      <td>0.899355</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.817036</td>\n",
       "      <td>0.771040</td>\n",
       "      <td>0.773590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.685161</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.895484</td>\n",
       "      <td>0.950968</td>\n",
       "      <td>0.685161</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.179097</td>\n",
       "      <td>0.095097</td>\n",
       "      <td>0.685161</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.895484</td>\n",
       "      <td>0.950968</td>\n",
       "      <td>0.818279</td>\n",
       "      <td>0.775812</td>\n",
       "      <td>0.778683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.690323</td>\n",
       "      <td>0.845161</td>\n",
       "      <td>0.912258</td>\n",
       "      <td>0.970323</td>\n",
       "      <td>0.690323</td>\n",
       "      <td>0.281720</td>\n",
       "      <td>0.182452</td>\n",
       "      <td>0.097032</td>\n",
       "      <td>0.690323</td>\n",
       "      <td>0.845161</td>\n",
       "      <td>0.912258</td>\n",
       "      <td>0.970323</td>\n",
       "      <td>0.829791</td>\n",
       "      <td>0.784917</td>\n",
       "      <td>0.786583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.696774</td>\n",
       "      <td>0.849032</td>\n",
       "      <td>0.908387</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.696774</td>\n",
       "      <td>0.283011</td>\n",
       "      <td>0.181677</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.696774</td>\n",
       "      <td>0.849032</td>\n",
       "      <td>0.908387</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.831281</td>\n",
       "      <td>0.787729</td>\n",
       "      <td>0.789521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.701935</td>\n",
       "      <td>0.850323</td>\n",
       "      <td>0.913548</td>\n",
       "      <td>0.963871</td>\n",
       "      <td>0.701935</td>\n",
       "      <td>0.283441</td>\n",
       "      <td>0.182710</td>\n",
       "      <td>0.096387</td>\n",
       "      <td>0.701935</td>\n",
       "      <td>0.850323</td>\n",
       "      <td>0.913548</td>\n",
       "      <td>0.963871</td>\n",
       "      <td>0.832307</td>\n",
       "      <td>0.790119</td>\n",
       "      <td>0.792181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.700645</td>\n",
       "      <td>0.859355</td>\n",
       "      <td>0.908387</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.700645</td>\n",
       "      <td>0.286452</td>\n",
       "      <td>0.181677</td>\n",
       "      <td>0.096000</td>\n",
       "      <td>0.700645</td>\n",
       "      <td>0.859355</td>\n",
       "      <td>0.908387</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.830609</td>\n",
       "      <td>0.789134</td>\n",
       "      <td>0.791403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.708387</td>\n",
       "      <td>0.864516</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.963871</td>\n",
       "      <td>0.708387</td>\n",
       "      <td>0.288172</td>\n",
       "      <td>0.184000</td>\n",
       "      <td>0.096387</td>\n",
       "      <td>0.708387</td>\n",
       "      <td>0.864516</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.963871</td>\n",
       "      <td>0.838111</td>\n",
       "      <td>0.797484</td>\n",
       "      <td>0.799747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>245</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.701935</td>\n",
       "      <td>0.865806</td>\n",
       "      <td>0.916129</td>\n",
       "      <td>0.957419</td>\n",
       "      <td>0.701935</td>\n",
       "      <td>0.288602</td>\n",
       "      <td>0.183226</td>\n",
       "      <td>0.095742</td>\n",
       "      <td>0.701935</td>\n",
       "      <td>0.865806</td>\n",
       "      <td>0.916129</td>\n",
       "      <td>0.957419</td>\n",
       "      <td>0.832854</td>\n",
       "      <td>0.792566</td>\n",
       "      <td>0.795245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.717419</td>\n",
       "      <td>0.861935</td>\n",
       "      <td>0.907097</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.717419</td>\n",
       "      <td>0.287312</td>\n",
       "      <td>0.181419</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.717419</td>\n",
       "      <td>0.861935</td>\n",
       "      <td>0.907097</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.839469</td>\n",
       "      <td>0.798764</td>\n",
       "      <td>0.800650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.701935</td>\n",
       "      <td>0.859355</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.972903</td>\n",
       "      <td>0.701935</td>\n",
       "      <td>0.286452</td>\n",
       "      <td>0.184000</td>\n",
       "      <td>0.097290</td>\n",
       "      <td>0.701935</td>\n",
       "      <td>0.859355</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.972903</td>\n",
       "      <td>0.838182</td>\n",
       "      <td>0.794776</td>\n",
       "      <td>0.796393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>294</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.707097</td>\n",
       "      <td>0.867097</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.971613</td>\n",
       "      <td>0.707097</td>\n",
       "      <td>0.289032</td>\n",
       "      <td>0.184000</td>\n",
       "      <td>0.097161</td>\n",
       "      <td>0.707097</td>\n",
       "      <td>0.867097</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.971613</td>\n",
       "      <td>0.841360</td>\n",
       "      <td>0.799336</td>\n",
       "      <td>0.800853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.707097</td>\n",
       "      <td>0.867097</td>\n",
       "      <td>0.917419</td>\n",
       "      <td>0.966452</td>\n",
       "      <td>0.707097</td>\n",
       "      <td>0.289032</td>\n",
       "      <td>0.183484</td>\n",
       "      <td>0.096645</td>\n",
       "      <td>0.707097</td>\n",
       "      <td>0.867097</td>\n",
       "      <td>0.917419</td>\n",
       "      <td>0.966452</td>\n",
       "      <td>0.838074</td>\n",
       "      <td>0.796670</td>\n",
       "      <td>0.798422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.716129</td>\n",
       "      <td>0.864516</td>\n",
       "      <td>0.914839</td>\n",
       "      <td>0.962581</td>\n",
       "      <td>0.716129</td>\n",
       "      <td>0.288172</td>\n",
       "      <td>0.182968</td>\n",
       "      <td>0.096258</td>\n",
       "      <td>0.716129</td>\n",
       "      <td>0.864516</td>\n",
       "      <td>0.914839</td>\n",
       "      <td>0.962581</td>\n",
       "      <td>0.838357</td>\n",
       "      <td>0.798684</td>\n",
       "      <td>0.800517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.712258</td>\n",
       "      <td>0.865806</td>\n",
       "      <td>0.916129</td>\n",
       "      <td>0.966452</td>\n",
       "      <td>0.712258</td>\n",
       "      <td>0.288602</td>\n",
       "      <td>0.183226</td>\n",
       "      <td>0.096645</td>\n",
       "      <td>0.712258</td>\n",
       "      <td>0.865806</td>\n",
       "      <td>0.916129</td>\n",
       "      <td>0.966452</td>\n",
       "      <td>0.839544</td>\n",
       "      <td>0.798842</td>\n",
       "      <td>0.800732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>343</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.713548</td>\n",
       "      <td>0.861935</td>\n",
       "      <td>0.916129</td>\n",
       "      <td>0.970323</td>\n",
       "      <td>0.713548</td>\n",
       "      <td>0.287312</td>\n",
       "      <td>0.183226</td>\n",
       "      <td>0.097032</td>\n",
       "      <td>0.713548</td>\n",
       "      <td>0.861935</td>\n",
       "      <td>0.916129</td>\n",
       "      <td>0.970323</td>\n",
       "      <td>0.842013</td>\n",
       "      <td>0.800934</td>\n",
       "      <td>0.802610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.704516</td>\n",
       "      <td>0.869677</td>\n",
       "      <td>0.922581</td>\n",
       "      <td>0.965161</td>\n",
       "      <td>0.704516</td>\n",
       "      <td>0.289892</td>\n",
       "      <td>0.184516</td>\n",
       "      <td>0.096516</td>\n",
       "      <td>0.704516</td>\n",
       "      <td>0.869677</td>\n",
       "      <td>0.922581</td>\n",
       "      <td>0.965161</td>\n",
       "      <td>0.838062</td>\n",
       "      <td>0.797009</td>\n",
       "      <td>0.798959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.703226</td>\n",
       "      <td>0.860645</td>\n",
       "      <td>0.916129</td>\n",
       "      <td>0.965161</td>\n",
       "      <td>0.703226</td>\n",
       "      <td>0.286882</td>\n",
       "      <td>0.183226</td>\n",
       "      <td>0.096516</td>\n",
       "      <td>0.703226</td>\n",
       "      <td>0.860645</td>\n",
       "      <td>0.916129</td>\n",
       "      <td>0.965161</td>\n",
       "      <td>0.835630</td>\n",
       "      <td>0.793908</td>\n",
       "      <td>0.795843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>392</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.699355</td>\n",
       "      <td>0.865806</td>\n",
       "      <td>0.914839</td>\n",
       "      <td>0.965161</td>\n",
       "      <td>0.699355</td>\n",
       "      <td>0.288602</td>\n",
       "      <td>0.182968</td>\n",
       "      <td>0.096516</td>\n",
       "      <td>0.699355</td>\n",
       "      <td>0.865806</td>\n",
       "      <td>0.914839</td>\n",
       "      <td>0.965161</td>\n",
       "      <td>0.834620</td>\n",
       "      <td>0.792575</td>\n",
       "      <td>0.794671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.705806</td>\n",
       "      <td>0.865806</td>\n",
       "      <td>0.914839</td>\n",
       "      <td>0.965161</td>\n",
       "      <td>0.705806</td>\n",
       "      <td>0.288602</td>\n",
       "      <td>0.182968</td>\n",
       "      <td>0.096516</td>\n",
       "      <td>0.705806</td>\n",
       "      <td>0.865806</td>\n",
       "      <td>0.914839</td>\n",
       "      <td>0.965161</td>\n",
       "      <td>0.836892</td>\n",
       "      <td>0.795642</td>\n",
       "      <td>0.797683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.714839</td>\n",
       "      <td>0.868387</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.714839</td>\n",
       "      <td>0.289462</td>\n",
       "      <td>0.184000</td>\n",
       "      <td>0.096000</td>\n",
       "      <td>0.714839</td>\n",
       "      <td>0.868387</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.839677</td>\n",
       "      <td>0.800734</td>\n",
       "      <td>0.803017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.717419</td>\n",
       "      <td>0.863226</td>\n",
       "      <td>0.918710</td>\n",
       "      <td>0.962581</td>\n",
       "      <td>0.717419</td>\n",
       "      <td>0.287742</td>\n",
       "      <td>0.183742</td>\n",
       "      <td>0.096258</td>\n",
       "      <td>0.717419</td>\n",
       "      <td>0.863226</td>\n",
       "      <td>0.918710</td>\n",
       "      <td>0.962581</td>\n",
       "      <td>0.841337</td>\n",
       "      <td>0.802176</td>\n",
       "      <td>0.804069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>441</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.716129</td>\n",
       "      <td>0.861935</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.962581</td>\n",
       "      <td>0.716129</td>\n",
       "      <td>0.287312</td>\n",
       "      <td>0.184000</td>\n",
       "      <td>0.096258</td>\n",
       "      <td>0.716129</td>\n",
       "      <td>0.861935</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.962581</td>\n",
       "      <td>0.840754</td>\n",
       "      <td>0.801402</td>\n",
       "      <td>0.803311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.712258</td>\n",
       "      <td>0.863226</td>\n",
       "      <td>0.918710</td>\n",
       "      <td>0.963871</td>\n",
       "      <td>0.712258</td>\n",
       "      <td>0.287742</td>\n",
       "      <td>0.183742</td>\n",
       "      <td>0.096387</td>\n",
       "      <td>0.712258</td>\n",
       "      <td>0.863226</td>\n",
       "      <td>0.918710</td>\n",
       "      <td>0.963871</td>\n",
       "      <td>0.839723</td>\n",
       "      <td>0.799639</td>\n",
       "      <td>0.801446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.716129</td>\n",
       "      <td>0.867097</td>\n",
       "      <td>0.921290</td>\n",
       "      <td>0.966452</td>\n",
       "      <td>0.716129</td>\n",
       "      <td>0.289032</td>\n",
       "      <td>0.184258</td>\n",
       "      <td>0.096645</td>\n",
       "      <td>0.716129</td>\n",
       "      <td>0.867097</td>\n",
       "      <td>0.921290</td>\n",
       "      <td>0.966452</td>\n",
       "      <td>0.842792</td>\n",
       "      <td>0.802967</td>\n",
       "      <td>0.804561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.716129</td>\n",
       "      <td>0.867097</td>\n",
       "      <td>0.921290</td>\n",
       "      <td>0.966452</td>\n",
       "      <td>0.716129</td>\n",
       "      <td>0.289032</td>\n",
       "      <td>0.184258</td>\n",
       "      <td>0.096645</td>\n",
       "      <td>0.716129</td>\n",
       "      <td>0.867097</td>\n",
       "      <td>0.921290</td>\n",
       "      <td>0.966452</td>\n",
       "      <td>0.842961</td>\n",
       "      <td>0.803182</td>\n",
       "      <td>0.804776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š [REPORT] Step: 20 | Epoch: 0.40816326530612246 | Accuracy@1: 0.7522\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 40 | Epoch: 0.8163265306122449 | Accuracy@1: 0.8153\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 49 | Epoch: 1.0 | Accuracy@1: 0.8117\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 60 | Epoch: 1.2244897959183674 | Accuracy@1: 0.8135\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 80 | Epoch: 1.6326530612244898 | Accuracy@1: 0.8177\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 98 | Epoch: 2.0 | Accuracy@1: 0.8184\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 100 | Epoch: 2.0408163265306123 | Accuracy@1: 0.8236\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 120 | Epoch: 2.4489795918367347 | Accuracy@1: 0.8174\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 140 | Epoch: 2.857142857142857 | Accuracy@1: 0.8176\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 147 | Epoch: 3.0 | Accuracy@1: 0.8170\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 160 | Epoch: 3.2653061224489797 | Accuracy@1: 0.8183\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 180 | Epoch: 3.673469387755102 | Accuracy@1: 0.8298\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 196 | Epoch: 4.0 | Accuracy@1: 0.8313\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 200 | Epoch: 4.081632653061225 | Accuracy@1: 0.8323\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 220 | Epoch: 4.489795918367347 | Accuracy@1: 0.8306\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 240 | Epoch: 4.8979591836734695 | Accuracy@1: 0.8381\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 245 | Epoch: 5.0 | Accuracy@1: 0.8329\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 260 | Epoch: 5.3061224489795915 | Accuracy@1: 0.8395\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 280 | Epoch: 5.714285714285714 | Accuracy@1: 0.8382\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 294 | Epoch: 6.0 | Accuracy@1: 0.8414\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 300 | Epoch: 6.122448979591836 | Accuracy@1: 0.8381\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 320 | Epoch: 6.530612244897959 | Accuracy@1: 0.8384\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 340 | Epoch: 6.938775510204081 | Accuracy@1: 0.8395\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 343 | Epoch: 7.0 | Accuracy@1: 0.8420\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 360 | Epoch: 7.346938775510204 | Accuracy@1: 0.8381\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 380 | Epoch: 7.755102040816326 | Accuracy@1: 0.8356\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 392 | Epoch: 8.0 | Accuracy@1: 0.8346\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 400 | Epoch: 8.16326530612245 | Accuracy@1: 0.8369\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 420 | Epoch: 8.571428571428571 | Accuracy@1: 0.8397\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 440 | Epoch: 8.979591836734693 | Accuracy@1: 0.8413\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 441 | Epoch: 9.0 | Accuracy@1: 0.8408\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 460 | Epoch: 9.387755102040817 | Accuracy@1: 0.8397\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 480 | Epoch: 9.795918367346939 | Accuracy@1: 0.8428\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 490 | Epoch: 10.0 | Accuracy@1: 0.8430\n",
      "âœ¨ ëª¨ë“  ê³¼ì • ì™„ë£Œ! ìµœì ì˜ ëª¨ë¸ì€ ./models/gemma-300m-4080super-extremeì— ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import os\n",
    "import gc\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses, evaluation\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "# 1. GPU ë©”ëª¨ë¦¬ ì´ˆê¸°í™” \n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 2. ëª¨ë¸ ë¡œë“œ ë° ê·¸ë˜ë””ì–¸íŠ¸ ì²´í¬í¬ì¸íŒ… í™œì„±í™”\n",
    "\n",
    "MODEL_ID = \"google/embeddinggemma-300m\"\n",
    "OUTPUT_PATH = \"./models/gemma-300m-4080super-extreme\"\n",
    "model = SentenceTransformer(MODEL_ID)\n",
    "model[0].auto_model.gradient_checkpointing_enable()\n",
    "\n",
    "# 3. Gemma ê³µì‹ ì§€ì‹œì–´ í¬ë§· í•¨ìˆ˜\n",
    "def format_query(text):\n",
    "    return f\"task: search result | query: {text}\"\n",
    "\n",
    "def format_doc(content, title=\"none\"):\n",
    "    return f\"title: {title} | text: {content}\"\n",
    "\n",
    "def load_json_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# ë°ì´í„° ë¡œë“œ\n",
    "train_data = load_json_data('./data/train_dataset.json')\n",
    "val_data = load_json_data('./data/val_dataset.json')\n",
    "\n",
    "# 4. í•™ìŠµ ë°ì´í„°ì…‹ êµ¬ì„± (Prefix ì ìš©)\n",
    "train_examples = []\n",
    "for item in train_data:\n",
    "    card_title = item.get('metadata', {}).get('card_name', 'ì¹´ë“œí˜œíƒ')\n",
    "    train_examples.append(InputExample(texts=[\n",
    "        format_query(item['anchor']), \n",
    "        format_doc(item['positive'], title=card_title),\n",
    "        format_doc(item['negative'], title=card_title)\n",
    "    ]))\n",
    "\n",
    "\n",
    "BATCH_SIZE = 128 \n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=BATCH_SIZE)\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model)\n",
    "\n",
    "# 6. ê²€ì¦ê¸° ì„¤ì •\n",
    "val_queries = {str(i): format_query(item['anchor']) for i, item in enumerate(val_data)}\n",
    "val_corpus = {str(i): format_doc(item['positive']) for i, item in enumerate(val_data)}\n",
    "val_relevant_docs = {str(i): {str(i)} for i, item in enumerate(val_data)}\n",
    "\n",
    "evaluator = evaluation.InformationRetrievalEvaluator(\n",
    "    val_queries, val_corpus, val_relevant_docs, name=\"card-val-task\"\n",
    ")\n",
    "\n",
    "# 7. ì§„í–‰ ìƒí™© ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì½œë°±\n",
    "def training_callback(score, epoch, steps):\n",
    "    print(f\"\\nğŸ“Š [REPORT] Step: {steps} | Epoch: {epoch} | Accuracy@1: {score:.4f}\")\n",
    "\n",
    "# 8. ìµœì í™” í•™ìŠµ ì‹¤í–‰\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    evaluator=evaluator,\n",
    "    epochs=10,\n",
    "    warmup_steps=100,\n",
    "    optimizer_params={'lr': 2e-5},\n",
    "    output_path=OUTPUT_PATH,\n",
    "    evaluation_steps=20,     # ë°°ì¹˜ê°€ í¬ë¯€ë¡œ 20ìŠ¤í…ë§ˆë‹¤ ì ìˆ˜ í™•ì¸ (ì§„í–‰ ìƒí™© ì²´í¬)\n",
    "    save_best_model=True,\n",
    "    show_progress_bar=True,\n",
    "    use_amp=True,            # í˜¼í•© ì •ë°€ë„ í™œì„±í™”\n",
    "    callback=training_callback # ì‹¤ì‹œê°„ ì ìˆ˜ ì¶œë ¥\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc881280",
   "metadata": {},
   "source": [
    "# ëª¨ë¸ ì„±ëŠ¥ í‰ê°€\n",
    "\n",
    "InformationRetrievalEvaluatorë¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ ì‹œìŠ¤í…œì˜ í•µì‹¬ êµ¬ì„± ìš”ì†Œë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "- Queries: ì‚¬ìš©ìê°€ ë˜ì§ˆ ìˆ˜ ìˆëŠ” ì§ˆë¬¸ ì˜ˆì‹œ.\n",
    "- Corpus: ê²€ìƒ‰ ëŒ€ìƒì´ ë˜ëŠ” ì „ì²´ ì¹´ë“œ í˜œíƒ ë°ì´í„°ë² ì´ìŠ¤.\n",
    "- Relevant Docs: íŠ¹ì • ì§ˆë¬¸ì— ëŒ€í•´ ë°˜ë“œì‹œ ì°¾ì•„ë‚´ì•¼ í•˜ëŠ” 'ì •ë‹µ ë¬¸ì„œ' ë§¤í•‘."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9cf2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer you are loading from './models/gemma-300m-4080super-extreme' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì´ìš©í•œ ì‹¬ì¸µ ì„±ëŠ¥ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...\n",
      "\n",
      "========================= [Gemma-300M ìµœì¢… ê²€ìƒ‰ ì„±ì í‘œ] =========================\n",
      "âœ… Accuracy@1 (Hit Rate)          : 0.7384\n",
      "âœ… Accuracy@10 (Hit Rate)         : 0.9613\n",
      "âœ… MRR@10                         : 0.8191\n",
      "âœ… NDCG@10                        : 0.8540\n",
      "âœ… Precision@10                   : 0.0961\n",
      "âœ… Recall@10                      : 0.9613\n",
      "==============================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer, evaluation\n",
    "\n",
    "# 1. ëª¨ë¸ ë¡œë“œ\n",
    "FINAL_MODEL_PATH = \"./models/gemma-300m-4080super-extreme\"\n",
    "final_model = SentenceTransformer(FINAL_MODEL_PATH)\n",
    "\n",
    "# 2. ë°ì´í„° ë¡œë“œ\n",
    "def load_json_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "test_data = load_json_data('./data/test_dataset.json')\n",
    "\n",
    "# 3. Evaluator ì„¤ì •\n",
    "test_queries = {str(i): item['anchor'] for i, item in enumerate(test_data)}\n",
    "test_corpus = {str(i): item['positive'] for i, item in enumerate(test_data)}\n",
    "test_relevant_docs = {str(i): {str(i)} for i, item in enumerate(test_data)}\n",
    "\n",
    "# í‰ê°€ ì´ë¦„(name)ì„ ê¸°ì¤€ìœ¼ë¡œ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ì˜ í‚¤ ê°’ì´ ìƒì„±ë©ë‹ˆë‹¤.\n",
    "TASK_NAME = \"card-test-task\"\n",
    "test_evaluator = evaluation.InformationRetrievalEvaluator(\n",
    "    test_queries, test_corpus, test_relevant_docs, name=TASK_NAME\n",
    ")\n",
    "\n",
    "# 4. ìµœì¢… í‰ê°€ ì‹¤í–‰\n",
    "print(\"ğŸ” í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì´ìš©í•œ ì‹¬ì¸µ ì„±ëŠ¥ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "results = test_evaluator(final_model)\n",
    "\n",
    "# 5. ìƒì„¸ ì§€í‘œ ì¶œë ¥ ë¡œì§\n",
    "def print_detailed_report(res, name):\n",
    "    \n",
    "    metrics = [\n",
    "        # [Accuracy@1] \"í•œ ë°©ì— ë§ì¶œ í™•ë¥ \"\n",
    "        # ì‚¬ìš©ìê°€ ì§ˆë¬¸í•˜ìë§ˆì ë¦¬ìŠ¤íŠ¸ì˜ ê°€ì¥ ì²« ë²ˆì§¸(1ìœ„)ì— ì •ë‹µì´ ìˆì„ í™•ë¥ ì…ë‹ˆë‹¤.\n",
    "        (\"Accuracy@1 (Hit Rate)\", f\"{name}_cosine_accuracy@1\"),\n",
    "        \n",
    "        # [Accuracy@10] \"10ìœ„ê¶Œ ì•ˆì— ì •ë‹µì´ ìˆì„ í™•ë¥ \"\n",
    "        # 1ìœ„ëŠ” ì•„ë‹ˆë”ë¼ë„ 10ìœ„ ì•ˆì—ë§Œ ì •ë‹µì´ ìˆìœ¼ë©´ ì„±ê³µìœ¼ë¡œ ì¹¨. ì‹œìŠ¤í…œì˜ ì•ˆì •ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.\n",
    "        (\"Accuracy@10 (Hit Rate)\", f\"{name}_cosine_accuracy@10\"),\n",
    "        \n",
    "        # [MRR@10] \"ì •ë‹µì´ ìƒë‹¨ì— ë°°ì¹˜ë˜ëŠ” ëŠ¥ë ¥\"\n",
    "        # ì •ë‹µì´ 1ë“±ì´ë©´ 1ì , 2ë“±ì´ë©´ 0.5ì ... ì‹ìœ¼ë¡œ ì ìˆ˜ë¥¼ ë§¤ê²¨ ì •ë‹µì´ ì–¼ë§ˆë‚˜ ì•ìª½ì— ì ë ¤ ìˆëŠ”ì§€ ì¸¡ì •í•©ë‹ˆë‹¤.\n",
    "        (\"MRR@10\", f\"{name}_cosine_mrr@10\"),\n",
    "        \n",
    "        # [NDCG@10] \"ê²€ìƒ‰ ê²°ê³¼ì˜ ì¢…í•©ì ì¸ í’ˆì§ˆ\"\n",
    "        # ì •ë‹µ ë¬¸ì„œê°€ ìƒë‹¨ì— ì˜ ì •ë ¬ë˜ì–´ ìˆëŠ”ì§€ ì ìˆ˜ë¥¼ ë§¤ê¸°ëŠ” ì§€í‘œë¡œ, êµ¬ê¸€ ê°™ì€ ê²€ìƒ‰ ì—”ì§„ì´ ê°€ì¥ ì¤‘ì‹œí•©ë‹ˆë‹¤.\n",
    "        (\"NDCG@10\", f\"{name}_cosine_ndcg@10\"),\n",
    "        \n",
    "        # [Precision@10] \"ì¶”ì²œëœ 10ê°œ ì¤‘ ì •ë‹µì˜ ë†ë„\"\n",
    "        # ë½‘ì•„ì¤€ 10ê°œ ì¤‘ì— ì§„ì§œ ì •ë‹µì´ ëª‡ ê°œ ì„ì—¬ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤. (ì •ë‹µì´ 1ê°œë©´ 0.1ì´ ë§Œì )\n",
    "        (\"Precision@10\", f\"{name}_cosine_precision@10\"),\n",
    "        \n",
    "        # [Recall@10] \"ì •ë‹µì„ ë†“ì¹˜ì§€ ì•Šê³  ì°¾ì•„ë‚¸ ë¹„ìœ¨\"\n",
    "        # ì „ì²´ ì •ë‹µ ì¤‘ ëª¨ë¸ì´ 10ìœ„ ì•ˆì— ê±´ì ¸ ì˜¬ë¦° ë¹„ìœ¨ì…ë‹ˆë‹¤. í˜„ì¬ Accuracy@10ê³¼ ìˆ˜ì¹˜ê°€ ê°™ìŠµë‹ˆë‹¤.\n",
    "        (\"Recall@10\", f\"{name}_cosine_recall@10\"),\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\n{'='*25} [Gemma-300M ìµœì¢… ê²€ìƒ‰ ì„±ì í‘œ] {'='*25}\")\n",
    "    for label, key in metrics:\n",
    "        val = res.get(key, 0)\n",
    "        print(f\"âœ… {label:<30} : {val:.4f}\")\n",
    "    print(f\"{'='*78}\\n\")\n",
    "\n",
    "print_detailed_report(results, TASK_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce652e1e",
   "metadata": {},
   "source": [
    "# Gemma-300M & ChromaDB ê¸°ë°˜ ì¹´ë“œ ê²€ìƒ‰ ì‹œìŠ¤í…œ êµ¬ì¶•\n",
    "\n",
    "- í•™ìŠµëœ ì„ë² ë”© ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë²¡í„°í™”í•˜ê³ , ì´ë¥¼ ChromaDBì— ì €ì¥í•˜ì—¬ ìœ ì‚¬ë„ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "- Vector DB: ChromaDB (ë°ì´í„°ë¥¼ í•˜ë“œë””ìŠ¤í¬ì— ì˜êµ¬ ì €ì¥ ë° ê´€ë¦¬)\n",
    "- Embedding Model: ì—¬ìš±ë‹˜ì´ ì§ì ‘ íŠœë‹í•œ Gemma-300M ëª¨ë¸ ì‚¬ìš©\n",
    "- í•µì‹¬ ì„¤ì •: ë²¡í„° ê°„ ê±°ë¦¬ ì¸¡ì • ë°©ì‹ì„ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¡œ ì„¤ì •í•˜ì—¬ ë¬¸ë§¥ì  ìœ ì‚¬ì„± ì¸¡ì •\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "754ba8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ ëª¨ë¸ì„ ë¡œë“œ ì¤‘ì…ë‹ˆë‹¤... (Device: cuda)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer you are loading from './models/gemma-300m-4080super-extreme' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n",
      "C:\\Users\\Jeon\\AppData\\Local\\Temp\\ipykernel_38488\\3610440556.py:36: DeprecationWarning: The class GemmaEmbeddingFunction does not implement __init__. This will be required in a future version.\n",
      "  embedding_fn = GemmaEmbeddingFunction()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ ê¸°ì¡´ ChromaDBë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤. (ì €ì¥ëœ ë°ì´í„°: 7757ê±´)\n",
      "\n",
      "ğŸ” ë¶„ì„ëœ ì˜ë„: ['ë°°ë‹¬ì˜ë¯¼ì¡± ìš”ê¸°ìš” ì¿ íŒ¡ì´ì¸  ë°°ë‹¬ ìŒì‹ í• ì¸ í˜œíƒ', 'ë„·í”Œë¦­ìŠ¤ ë””ì¦ˆë‹ˆí”ŒëŸ¬ìŠ¤ ì™“ì±  OTT ìŠ¤íŠ¸ë¦¬ë° í• ì¸ í˜œíƒ']\n",
      "âœ… êµì§‘í•© í•„í„°ë§ ê²°ê³¼: 28ê±´ ë°œê²¬\n",
      "=====================================================================================\n",
      "1. [ë¡¯ë°ì¹´ë“œ] ë””ì§€ë¡œì¹´ Monaco (ì¢…í•© ì ìˆ˜: 0.8458)\n",
      "     - ë„·í”Œë¦­ìŠ¤, ìœ íŠœë¸Œí”„ë¦¬ë¯¸ì—„, ì™“ì± , ë©œë¡ , ì§€ë‹ˆë®¤ì§ì—ì„œ 50% ê²°ì œì¼ í• ì¸ì´ ì œê³µë©ë‹ˆë‹¤.\n",
      "     - ë°°ë‹¬ì˜ ë¯¼ì¡±, ì¿ íŒ¡ì´ì¸ , ìš”ê¸°ìš”ì—ì„œ 5% ê²°ì œì¼ í• ì¸ í˜œíƒ ì œê³µ.\n",
      "-------------------------------------------------------------------------------------\n",
      "2. [í˜„ëŒ€ì¹´ë“œ] í˜„ëŒ€ì¹´ë“œZ ontact (ì¢…í•© ì ìˆ˜: 0.8417)\n",
      "     - ë°°ë‹¬ ì•± ì´ìš©ê¸ˆì•¡ì˜ 10% ì²­êµ¬ í• ì¸ í˜œíƒ ì œê³µ\n",
      "     - ë””ì§€í„¸ ì½˜í…ì¸  ì„œë¹„ìŠ¤ ì´ìš©ê¸ˆì•¡ì˜ 30% ì²­êµ¬ í• ì¸ ì œê³µ\n",
      "-------------------------------------------------------------------------------------\n",
      "3. [ë¡¯ë°ì¹´ë“œ] ë±…í¬ìƒëŸ¬ë“œ ë¹¨ëŒ€ì¹´ë“œ (ì¢…í•© ì ìˆ˜: 0.8276)\n",
      "     - ë„·í”Œë¦­ìŠ¤, ìœ íŠœë¸Œ, ì™“ì± , ë©œë¡ ì—ì„œ 50% ê²°ì œì¼ í• ì¸ í˜œíƒ ì œê³µ.\n",
      "     - ë°°ë‹¬ì˜ë¯¼ì¡±ê³¼ ìš”ê¸°ìš”ì—ì„œ 1ë§Œì› ì´ìƒ ê²°ì œ ì‹œ 1ì²œì› í• ì¸ í˜œíƒì´ ì œê³µë©ë‹ˆë‹¤.\n",
      "-------------------------------------------------------------------------------------\n",
      "4. [í•˜ë‚˜ì¹´ë“œ] ì›ë”ì¹´ë“œ 2.0 DAILY (ì¢…í•© ì ìˆ˜: 0.7757)\n",
      "     - ë”œë¦¬ë²„ë¦¬ ì„œë¹„ìŠ¤ì—ì„œ 10% í• ì¸ì„ ì œê³µí•˜ëŠ” ì¹´ë“œ í˜œíƒì…ë‹ˆë‹¤.\n",
      "     - ì˜ìƒ ìŠ¤íŠ¸ë¦¬ë° ì„œë¹„ìŠ¤ì— ëŒ€í•´ ìµœëŒ€ 40% í• ì¸ í˜œíƒì„ ì œê³µí•©ë‹ˆë‹¤.\n",
      "-------------------------------------------------------------------------------------\n",
      "5. [KBêµ­ë¯¼ì¹´ë“œ] ë ˆê³ ëœë“œë§¤ë‹ˆì•„ì¹´ë“œ (ì¢…í•© ì ìˆ˜: 0.7683)\n",
      "     - êµ¬ë… ì„œë¹„ìŠ¤ì— ëŒ€í•´ 20% ì²­êµ¬í• ì¸ì„ ì œê³µí•˜ëŠ” ì¹´ë“œì…ë‹ˆë‹¤.\n",
      "     - ë ˆê³ ëœë“œë§¤ë‹ˆì•„ì¹´ë“œëŠ” ë°°ë‹¬ì•±ì—ì„œ 10% ì²­êµ¬í• ì¸ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
      "-------------------------------------------------------------------------------------\n",
      "6. [í•˜ë‚˜ì¹´ë“œ] ì›ë”ì¹´ë“œ 2.0 LIFE (ì¢…í•© ì ìˆ˜: 0.7584)\n",
      "     - ë”œë¦¬ë²„ë¦¬ ì„œë¹„ìŠ¤ì—ì„œ 10% í• ì¸ í˜œíƒì„ ì œê³µí•©ë‹ˆë‹¤.\n",
      "     - ì›ë”ì¹´ë“œ 2.0 LIFEëŠ” ìë™ì´ì²´ë¥¼ í†µí•´ ì˜ìƒ ìŠ¤íŠ¸ë¦¬ë°ê³¼ ìƒí™œìš”ê¸ˆì— ëŒ€í•œ í• ì¸ í˜œíƒì„ ì œê³µí•©ë‹ˆë‹¤.\n",
      "-------------------------------------------------------------------------------------\n",
      "7. [ë¡¯ë°ì¹´ë“œ] LOCA Mobility ë°˜ëµ ì¹´ë“œ (ì¢…í•© ì ìˆ˜: 0.7465)\n",
      "     - ì˜¨ë¼ì¸ì‡¼í•‘ì—ì„œ íŠ¹ì • ê¸ˆì•¡ ì´ìƒ ì´ìš© ì‹œ í• ì¸ í˜œíƒ ì œê³µ\n",
      "     - ìŠ¤íŠ¸ë¦¬ë° ì„œë¹„ìŠ¤ì™€ ë©¤ë²„ì‹­ ì„œë¹„ìŠ¤ì— ëŒ€í•œ í• ì¸ í˜œíƒ ì œê³µ.\n",
      "-------------------------------------------------------------------------------------\n",
      "8. [ë¡¯ë°ì¹´ë“œ] LOCA for Coffee (ì¢…í•© ì ìˆ˜: 0.7292)\n",
      "     - ë°°ë‹¬ì˜ë¯¼ì¡±ê³¼ ìš”ê¸°ìš”ì—ì„œ 10% í• ì¸ í˜œíƒì„ ì œê³µí•©ë‹ˆë‹¤.\n",
      "     - ë„·í”Œë¦­ìŠ¤, ìœ íˆ¬ë¸Œ, ì™“ì± , ë©œë¡ , ì§€ë‹ˆë®¤ì§ì—ì„œ 20% í• ì¸ í˜œíƒ ì œê³µ.\n",
      "-------------------------------------------------------------------------------------\n",
      "9. [ìš°ë¦¬ì¹´ë“œ] NU Uniq (ì¢…í•© ì ìˆ˜: 0.7110)\n",
      "     - ë„·í”Œë¦­ìŠ¤, ìœ íŠœë¸Œ í”„ë¦¬ë¯¸ì—„, ë©œë¡ , ë””ì¦ˆë‹ˆí”ŒëŸ¬ìŠ¤ì—ì„œ 5% í• ì¸ ì œê³µ\n",
      "     - ë°°ë‹¬ì˜ë¯¼ì¡±, Bë§ˆíŠ¸, ì¿ íŒ¡ì´ì¸ ì—ì„œ 1.5% í• ì¸ í˜œíƒ ì œê³µ\n",
      "-------------------------------------------------------------------------------------\n",
      "10. [í•˜ë‚˜ì¹´ë“œ] ì›ë” Co brand(ì§‘ì—…) ì œíœ´ ì¹´ë“œ (ì¢…í•© ì ìˆ˜: 0.7101)\n",
      "     - ì˜¨ë¼ì¸ì‹í’ˆ ë° ì‡¼í•‘ì—ì„œ 4.0% ì²­êµ¬í• ì¸ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
      "     - ë”œë¦¬ë²„ë¦¬ ì„œë¹„ìŠ¤ì—ì„œ ì²­êµ¬í• ì¸ í˜œíƒì„ ì œê³µí•©ë‹ˆë‹¤.\n",
      "-------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# ë°ì´í„° ê²½ë¡œ ë° ëª¨ë¸ ê²½ë¡œ ì„¤ì •\n",
    "INPUT_FILE = './data/FINAL_MASTER_DATA_FIXED_7757.json'      # 7,757ê±´ì˜ ì¹´ë“œ ì›ë³¸ ë°ì´í„°\n",
    "MODEL_PATH = './models/gemma-300m-4080super-extreme'          # í•™ìŠµì‹œí‚¨ Gemma ì„ë² ë”© ëª¨ë¸\n",
    "CHROMA_DB_PATH = './data/chroma_db'                         # ë²¡í„° ë°ì´í„°ê°€ ì €ì¥ë  í´ë” ê²½ë¡œ\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"ğŸ“¦ ëª¨ë¸ì„ ë¡œë“œ ì¤‘ì…ë‹ˆë‹¤... (Device: {device})\")\n",
    "\n",
    "# SentenceTransformerë¥¼ í†µí•´ Gemma ëª¨ë¸ì„ ë©”ëª¨ë¦¬ì— ì˜¬ë¦½ë‹ˆë‹¤.\n",
    "model = SentenceTransformer(MODEL_PATH, device=device)\n",
    "\n",
    "# ==========================================\n",
    "# ChromaDB ì»¤ìŠ¤í…€ ì„ë² ë”© í•¨ìˆ˜ ì •ì˜\n",
    "# ==========================================\n",
    "# ChromaDBê°€ ìŠ¤ìŠ¤ë¡œ ì„ë² ë”©ì„ í•˜ì§€ ì•Šê³ , Gemma ëª¨ë¸ì„ ì‚¬ìš©í•˜ë„ë¡ ë‹¤ë¦¬ë¥¼ ë†“ì•„ì£¼ëŠ” í´ë˜ìŠ¤ì…ë‹ˆë‹¤.\n",
    "class GemmaEmbeddingFunction(embedding_functions.EmbeddingFunction):\n",
    "    def __call__(self, input_texts):\n",
    "    \n",
    "        passages = [f\"title: none | text: {text}\" for text in input_texts]\n",
    "        embeddings = model.encode(passages, convert_to_tensor=False)\n",
    "        return embeddings.tolist()  # DB ì €ì¥ì„ ìœ„í•´ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë°˜í™˜\n",
    "\n",
    "# ==========================================\n",
    "# ChromaDB ì´ˆê¸°í™” ë° ë°ì´í„° ì¸ë±ì‹±\n",
    "# ==========================================\n",
    "# ë°ì´í„°ë¥¼ í•˜ë“œë””ìŠ¤í¬ì— ì˜êµ¬ ì €ì¥í•˜ëŠ” í´ë¼ì´ì–¸íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "client = chromadb.PersistentClient(path=CHROMA_DB_PATH)\n",
    "embedding_fn = GemmaEmbeddingFunction()\n",
    "\n",
    "# 'card_benefits'ë¼ëŠ” ì´ë¦„ì˜ ë°ì´í„° ì €ì¥ ê³µê°„(ì»¬ë ‰ì…˜)ì„ ë§Œë“­ë‹ˆë‹¤.\n",
    "# metadata={\"hnsw:space\": \"cosine\"}ëŠ” ë²¡í„° ê°„ì˜ ê±°ë¦¬ë¥¼ 'ì½”ì‚¬ì¸ ìœ ì‚¬ë„'ë¡œ ê³„ì‚°í•˜ê² ë‹¤ëŠ” ì„¤ì •ì…ë‹ˆë‹¤.\n",
    "collection = client.get_or_create_collection(\n",
    "    name=\"card_benefits\",\n",
    "    embedding_function=embedding_fn,\n",
    "    metadata={\"hnsw:space\": \"cosine\"} \n",
    ")\n",
    "\n",
    "# DBì— ë°ì´í„°ê°€ í•˜ë‚˜ë„ ì—†ë‹¤ë©´ ìµœì´ˆ 1íšŒ ì¸ë±ì‹±ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "if collection.count() == 0:\n",
    "    print(\"ì¸ë±ì‹±ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "    with open(INPUT_FILE, 'r', encoding='utf-8') as f:\n",
    "        master_data = json.load(f)\n",
    "    \n",
    "    # 7,757ê±´ì˜ ë°ì´í„°ë¥¼ DB í˜•ì‹ì— ë§ê²Œ ë¶„ë¦¬í•©ë‹ˆë‹¤.\n",
    "    documents = [item['embedding_input'] for item in master_data]   # ê²€ìƒ‰ ëŒ€ìƒ í…ìŠ¤íŠ¸\n",
    "    metadatas = [item['metadata'] for item in master_data]          # ì¹´ë“œ ì´ë¦„, íšŒì‚¬ ë“± ë¶€ê°€ ì •ë³´\n",
    "    \n",
    "    # ë‚˜ì¤‘ì— ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ë°”ë¡œ ìš”ì•½ì„ ë³´ì—¬ì£¼ê¸° ìœ„í•´ ë©”íƒ€ë°ì´í„°ì— ë¯¸ë¦¬ ë„£ì–´ë‘¡ë‹ˆë‹¤.\n",
    "    for i, m in enumerate(metadatas):\n",
    "        m['summary'] = master_data[i]['ai_structured']['summary']\n",
    "    \n",
    "    # ê° ë°ì´í„°ì˜ ê³ ìœ  ID ìƒì„± (card_0, card_1...)\n",
    "    ids = [f\"card_{i}\" for i in range(len(master_data))]\n",
    "\n",
    "    #500ê°œì”© ë‚˜ëˆ ì„œ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "    batch_size = 500\n",
    "    for i in range(0, len(documents), batch_size):\n",
    "        collection.add(\n",
    "            documents=documents[i:i+batch_size],\n",
    "            metadatas=metadatas[i:i+batch_size],\n",
    "            ids=ids[i:i+batch_size]\n",
    "        )\n",
    "    print(f\"âœ… ì´ {collection.count()}ê±´ì˜ ë°ì´í„° ì €ì¥ ì™„ë£Œ!\")\n",
    "else:\n",
    "    print(f\"ğŸ”„ ê¸°ì¡´ ChromaDBë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤. (ì €ì¥ëœ ë°ì´í„°: {collection.count()}ê±´)\")\n",
    "\n",
    "# ==========================================\n",
    "# ë‹¤ì¤‘ ì˜ë„ êµì°¨ ê²€ìƒ‰ (AND ë¡œì§)\n",
    "# ==========================================\n",
    "def find_combined_card_chroma(query_list, top_k=10, search_depth=100):\n",
    "    \"\"\"\n",
    "    query_list: ['ì˜ë„1', 'ì˜ë„2'] ê²€ìƒ‰ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸\n",
    "    top_k: ìµœì¢…ì ìœ¼ë¡œ ëª‡ ê°œë¥¼ ë³´ì—¬ì¤„ ê²ƒì¸ê°€\n",
    "    search_depth: ê° ì˜ë„ë³„ë¡œ ìƒìœ„ ëª‡ ê°œê¹Œì§€ í›‘ì–´ë³¼ ê²ƒì¸ê°€ (ê¹Šì„ìˆ˜ë¡ ì •í™•í•¨)\n",
    "    \"\"\"\n",
    "    intent_hits = []\n",
    "\n",
    "    # --- 1ë‹¨ê³„: ê° ì˜ë„ë³„ ê°œë³„ ê²€ìƒ‰ ---\n",
    "    for sub_query in query_list:\n",
    "        # ì§ˆë¬¸ìš© ê³µì‹ í”„ë¡¬í”„íŠ¸ ì ìš© (í•™ìŠµ ì‹œ instructionê³¼ ì¼ì¹˜ì‹œì¼œì•¼ í•¨)\n",
    "        query_text = f\"task: search result | query: {sub_query}\"\n",
    "        \n",
    "        # DBì—ì„œ ìœ ì‚¬í•œ ì¹´ë“œ search_depthë§Œí¼ ì¶”ì¶œ\n",
    "        results = collection.query(\n",
    "            query_texts=[query_text],\n",
    "            n_results=search_depth,\n",
    "            include=['metadatas', 'distances']\n",
    "        )\n",
    "        \n",
    "        current_hits = {}\n",
    "        for i in range(len(results['ids'][0])):\n",
    "            meta = results['metadatas'][0][i]\n",
    "            name = meta['card_name']\n",
    "            \n",
    "            # [ìœ ì‚¬ë„ ê³„ì‚°] ê±°ë¦¬ê°€ 0ì´ë©´ ì ìˆ˜ëŠ” 1ì (ë§Œì ), ê±°ë¦¬ê°€ 1ì´ë©´ ì ìˆ˜ëŠ” 0ì \n",
    "            score = 1 - results['distances'][0][i]\n",
    "            \n",
    "            # ê°™ì€ ì¹´ë“œê°€ ì¤‘ë³µ ê²€ìƒ‰ë  ê²½ìš° ê°€ì¥ ì ìˆ˜ê°€ ë†’ì€ ê²ƒë§Œ ê¸°ë¡\n",
    "            if name not in current_hits:\n",
    "                current_hits[name] = {\n",
    "                    \"score\": score,\n",
    "                    \"benefit\": meta.get('summary', 'í˜œíƒ ì •ë³´ ì—†ìŒ'),\n",
    "                    \"corp\": meta['corp']\n",
    "                }\n",
    "        intent_hits.append(current_hits)\n",
    "\n",
    "    # --- 2ë‹¨ê³„: êµì§‘í•©(Intersection) ì°¾ê¸° ---\n",
    "    # ëª¨ë“  ì˜ë„ ë¦¬ìŠ¤íŠ¸ì— ì´ë¦„ì´ ê³µí†µì ìœ¼ë¡œ ì¡´ì¬í•˜ëŠ” ì¹´ë“œë§Œ ê³¨ë¼ëƒ…ë‹ˆë‹¤.\n",
    "    common_names = set(intent_hits[0].keys()) # ì²« ë²ˆì§¸ ì˜ë„ ê²°ê³¼ë“¤\n",
    "    for hits in intent_hits[1:]:\n",
    "        common_names &= set(hits.keys())      # ì´í›„ ì˜ë„ë“¤ê³¼ ê³„ì† ê²¹ì¹˜ëŠ” ê²ƒë§Œ ë‚¨ê¹€\n",
    "\n",
    "    # --- 3ë‹¨ê³„: ê²°ê³¼ ë³‘í•© ë° ì ìˆ˜ í•©ì‚° ---\n",
    "    final_recommendations = []\n",
    "    for name in common_names:\n",
    "        # ê° ì˜ë„ì—ì„œ ë°›ì€ ìœ ì‚¬ë„ ì ìˆ˜ë¥¼ ëª¨ë‘ ë”í•©ë‹ˆë‹¤ (ì¢…í•© ì ìˆ˜)\n",
    "        total_score = sum(hits[name]['score'] for hits in intent_hits)\n",
    "        # ê° ì˜ë„ ê²€ìƒ‰ ì‹œ ë°œê²¬ëœ í˜œíƒ ìš”ì•½ë“¤ì„ ì¤‘ë³µ ì—†ì´ ìˆ˜ì§‘í•©ë‹ˆë‹¤.\n",
    "        all_benefits = list(set([hits[name]['benefit'] for hits in intent_hits]))\n",
    "        corp = intent_hits[0][name]['corp']\n",
    "        \n",
    "        final_recommendations.append({\n",
    "            \"name\": name,\n",
    "            \"corp\": corp,\n",
    "            \"score\": total_score,\n",
    "            \"benefits\": all_benefits\n",
    "        })\n",
    "\n",
    "    # --- 4ë‹¨ê³„: ìµœì¢… ì •ë ¬ ë° ì¶œë ¥ ---\n",
    "    # ì¢…í•© ì ìˆ˜(score)ê°€ ë†’ì€ ìˆœì„œëŒ€ë¡œ ìƒìœ„ top_kê°œ ì„ ì •\n",
    "    final_recommendations = sorted(final_recommendations, key=lambda x: x['score'], reverse=True)[:top_k]\n",
    "\n",
    "    print(f\"\\nğŸ” ë¶„ì„ëœ ì˜ë„: {query_list}\")\n",
    "    print(f\"âœ… êµì§‘í•© í•„í„°ë§ ê²°ê³¼: {len(common_names)}ê±´ ë°œê²¬\")\n",
    "    print(\"=\"*85)\n",
    "    \n",
    "    for i, res in enumerate(final_recommendations):\n",
    "        # ìµœì¢… ê²°ê³¼ ì¶œë ¥\n",
    "        print(f\"{i+1}. [{res['corp']}] {res['name']} (ì¢…í•© ì ìˆ˜: {res['score']:.4f})\")\n",
    "        for b in res['benefits']:\n",
    "            print(f\"     - {b}\")\n",
    "        print(\"-\" * 85)\n",
    "\n",
    "# ==========================================\n",
    "# 5. ì‹¤í–‰ í…ŒìŠ¤íŠ¸\n",
    "# ==========================================\n",
    "# ì‚¬ìš©ìì˜ ë³µí•©ì ì¸ ì§ˆë¬¸ì„ ë‘ ê°œì˜ í•µì‹¬ ì˜ë„ë¡œ ë‚˜ëˆ„ì–´ ì…ë ¥í•©ë‹ˆë‹¤.\n",
    "intents = [\n",
    "    \"ë°°ë‹¬ì˜ë¯¼ì¡± ìš”ê¸°ìš” ì¿ íŒ¡ì´ì¸  ë°°ë‹¬ ìŒì‹ í• ì¸ í˜œíƒ\", \n",
    "    \"ë„·í”Œë¦­ìŠ¤ ë””ì¦ˆë‹ˆí”ŒëŸ¬ìŠ¤ ì™“ì±  OTT ìŠ¤íŠ¸ë¦¬ë° í• ì¸ í˜œíƒ\"\n",
    "]\n",
    "\n",
    "# í•¨ìˆ˜ í˜¸ì¶œ\n",
    "find_combined_card_chroma(intents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652d7a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer you are loading from './models/gemma-300m-4080super-extreme' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n",
      "C:\\Users\\Jeon\\AppData\\Local\\Temp\\ipykernel_38488\\916593743.py:53: DeprecationWarning: The class GemmaEmbeddingFunction does not implement __init__. This will be required in a future version.\n",
      "  embedding_function=GemmaEmbeddingFunction()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¶”ì¶œëœ í‚¤ì›Œë“œ: ['ë°°ë‹¬ì˜ë¯¼ì¡± ìš”ê¸°ìš” ì¿ íŒ¡ì´ì¸  ë°°ë‹¬ ìŒì‹ í• ì¸ í˜œíƒ', 'ë„·í”Œë¦­ìŠ¤ ë””ì¦ˆë‹ˆí”ŒëŸ¬ìŠ¤ ì™“ì±  OTT ìŠ¤íŠ¸ë¦¬ë° í• ì¸ í˜œíƒ']\n",
      "Cohere v3.5 ë¦¬ë­í‚¹ ì¤‘... (í›„ë³´: 48ê°œ)\n",
      "ì•ˆë…•í•˜ì„¸ìš”, ì „ì—¬ìš±ë‹˜! ì‚¬íšŒì´ˆë…„ìƒìœ¼ë¡œì„œ ë°°ë‹¬ ìŒì‹ê³¼ OTT ìŠ¤íŠ¸ë¦¬ë° í• ì¸ í˜œíƒì„ ì›í•˜ì‹ ë‹¤ë‹ˆ, ê¼­ ë§ëŠ” ì¹´ë“œë¥¼ ì¶”ì²œí•´ë“œë¦´ê²Œìš”. ë°°ë‹¬ì˜ë¯¼ì¡±, ìš”ê¸°ìš”, ì¿ íŒ¡ì´ì¸  ê°™ì€ ë°°ë‹¬ì•±ê³¼ ë„·í”Œë¦­ìŠ¤, ë””ì¦ˆë‹ˆí”ŒëŸ¬ìŠ¤, ì™“ì±  ë“± OTT ìŠ¤íŠ¸ë¦¬ë° í• ì¸ê¹Œì§€ ì±™ê¸¸ ìˆ˜ ìˆëŠ” ì¹´ë“œ Top 3ë¥¼ ì†Œê°œí•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
      "\n",
      "1. ì‚¼ì„± iD SELECT ALL ì¹´ë“œ (ì‚¼ì„±ì¹´ë“œ)  \n",
      "2. ì›ë”ì¹´ë“œ 2.0 DAILY (í•˜ë‚˜ì¹´ë“œ)  \n",
      "3. ë ˆê³ ëœë“œë§¤ë‹ˆì•„ì¹´ë“œ (KBêµ­ë¯¼ì¹´ë“œ)  \n",
      "\n",
      "íŠ¹íˆ 1ìœ„ì¸ ì‚¼ì„± iD SELECT ALL ì¹´ë“œëŠ” ë°°ë‹¬ì•±ê³¼ OTT ìŠ¤íŠ¸ë¦¬ë° í• ì¸ í˜œíƒì´ ì•„ì£¼ ì•Œì°¨ì„œ ì „ì—¬ìš±ë‹˜ê»˜ ê°•ë ¥ ì¶”ì²œë“œë ¤ìš”.\n",
      "\n",
      "- ë°°ë‹¬ì•±(ë°°ë‹¬ì˜ë¯¼ì¡±, ìš”ê¸°ìš”, ì¿ íŒ¡ì´ì¸ )ì—ì„œ 7% í• ì¸ í˜œíƒì„ ë“œë¦½ë‹ˆë‹¤.  \n",
      "- ë„·í”Œë¦­ìŠ¤, ë””ì¦ˆë‹ˆ+, ìœ íŠœë¸Œ, í‹°ë¹™ ë“± ë””ì§€í„¸ì½˜í…ì¸  ì •ê¸°ê²°ì œ ì‹œ 50% í• ì¸ë„ ì œê³µí•´ìš”. (ì›” ìµœëŒ€ 5,000ì› í•œë„)  \n",
      "- ë°°ë‹¬ì•± í• ì¸ê³¼ OTT í• ì¸ ëª¨ë‘ ì „ì›” ì´ìš©ê¸ˆì•¡ 40ë§Œì› ì´ìƒ ì‹œ ì ìš©ë˜ë©°, ì›” ìµœëŒ€ í• ì¸í•œë„ëŠ” ë°°ë‹¬ì•± 7,000ì›, OTT 5,000ì›ì…ë‹ˆë‹¤.  \n",
      "- ë°°ë‹¬ì•± í• ì¸ì€ ê³µì‹ ì•±ì´ë‚˜ í™ˆí˜ì´ì§€ ê²°ì œ ê±´ì— í•œí•˜ë©°, ê°€ë§¹ì  ì§ì ‘ ê²°ì œëŠ” ì œì™¸ë©ë‹ˆë‹¤.  \n",
      "- ì´ì™¸ì—ë„ ì•„íŒŒíŠ¸ ê´€ë¦¬ë¹„, í†µì‹ ë¹„, êµìœ¡ë¹„ ë“± ë‹¤ì–‘í•œ ìƒí™œ í• ì¸ ì˜µì…˜ì„ ë§¤ì›” ì„ íƒí•´ í˜œíƒì„ ë§ì¶¤ ì„¤ì •í•  ìˆ˜ ìˆì–´ìš”.  \n",
      "\n",
      "ì‹¤ì „ íŒì„ ë“œë¦¬ìë©´, ì‚¼ì„± iD SELECT ALL ì¹´ë“œëŠ” ì „ì›” ì‹¤ì  40ë§Œì› ì´ìƒë¶€í„° í˜œíƒì´ ì œê³µë˜ë‹ˆ, ë§¤ë‹¬ ì¹´ë“œ ì‚¬ìš© ê¸ˆì•¡ì„ ì²´í¬í•´ ì£¼ì„¸ìš”. ê·¸ë¦¬ê³  í• ì¸ ì œì™¸ í•­ëª©ì´ ê½¤ ìˆìœ¼ë‹ˆ, ê³µê³¼ê¸ˆ, ìƒí’ˆê¶Œ êµ¬ë§¤, ë¬´ì´ì í• ë¶€, ê°„í¸ê²°ì œ ì¼ë¶€ ë“±ì€ í• ì¸ ëŒ€ìƒì—ì„œ ì œì™¸ëœë‹¤ëŠ” ì ë„ ê¼­ ê¸°ì–µí•´ ì£¼ì„¸ìš”. íŠ¹íˆ ë°°ë‹¬ì•±ê³¼ OTT í• ì¸ì€ ê³µì‹ ì•±ì´ë‚˜ í™ˆí˜ì´ì§€ë¥¼ í†µí•œ ì •ê¸°ê²°ì œì—ë§Œ ì ìš©ë˜ë‹ˆ, ê²°ì œ ë°©ë²•ì„ ê¼¼ê¼¼íˆ í™•ì¸í•˜ì‹œë©´ ì¢‹ìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì „ì—¬ìš±ë‹˜ê»˜ì„œ ë°°ë‹¬ê³¼ OTTë¥¼ ìì£¼ ì´ìš©í•˜ì‹ ë‹¤ë©´ ì‚¼ì„± iD SELECT ALL ì¹´ë“œê°€ ì‹¤ì† ìˆê³  í¸ë¦¬í•œ ì„ íƒì´ ë  ê±°ì˜ˆìš”. ê¶ê¸ˆí•œ ì  ìˆìœ¼ë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”! ë“ ë“ í•œ ê¸ˆìœµ ë¹„ì„œ Gemma-Botì´ í•­ìƒ í•¨ê»˜í•˜ê² ìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "import chromadb\n",
    "import cohere\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "# 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (API í‚¤)\n",
    "load_dotenv()\n",
    "OPENAI_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "COHERE_KEY = os.getenv(\"COHERE_API_KEY\")\n",
    "\n",
    "# 2. ë¡œì»¬ ê²½ë¡œ ë° ì„¤ì •\n",
    "INPUT_FILE = './data/FINAL_MASTER_DATA_FIXED_7757.json'\n",
    "MODEL_PATH = './models/gemma-300m-4080super-extreme'    \n",
    "CHROMA_DB_PATH = './data/chroma_db'\n",
    "\n",
    "# 3. ëª¨ë¸ ë° í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "bi_encoder = SentenceTransformer(MODEL_PATH, device=device)\n",
    "openai_client = OpenAI(api_key=OPENAI_KEY)\n",
    "co = cohere.ClientV2(api_key=COHERE_KEY)\n",
    "\n",
    "# 4. ë°ì´í„° ë¦¬í•˜ì´ë“œë ˆì´ì…˜ ë§µ ìƒì„± (ID ê¸°ë°˜ ë³µì›)\n",
    "with open(INPUT_FILE, 'r', encoding='utf-8') as f:\n",
    "    master_data = json.load(f)\n",
    "\n",
    "card_master_map = {}\n",
    "for item in master_data:\n",
    "    c_id = item['metadata']['card_id']\n",
    "    if c_id not in card_master_map:\n",
    "        card_master_map[c_id] = {\n",
    "            \"name\": item['metadata']['card_name'],\n",
    "            \"corp\": item['metadata']['corp'],\n",
    "            \"full_details\": [item['content']], \n",
    "            \"structured\": item['ai_structured']\n",
    "        }\n",
    "    else:\n",
    "        card_master_map[c_id][\"full_details\"].append(item['content'])\n",
    "\n",
    "# 5. ChromaDB ì—°ê²° ë° ì„ë² ë”© í•¨ìˆ˜ ì„¤ì •\n",
    "class GemmaEmbeddingFunction(embedding_functions.EmbeddingFunction):\n",
    "    def __call__(self, input_texts):\n",
    "        passages = [f\"title: none | text: {text}\" for text in input_texts]\n",
    "        return bi_encoder.encode(passages, convert_to_tensor=False).tolist()\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path=CHROMA_DB_PATH)\n",
    "collection = chroma_client.get_collection(\n",
    "    name=\"card_benefits\", \n",
    "    embedding_function=GemmaEmbeddingFunction()\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# [HELPER] ë™ì  ì˜ë„ ì¶”ì¶œ í•¨ìˆ˜\n",
    "# ==========================================\n",
    "def extract_search_intents(user_query):\n",
    "    \"\"\"ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ê²€ìƒ‰ìš© í•µì‹¬ í‚¤ì›Œë“œë¥¼ ë™ì ìœ¼ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤.\"\"\"\n",
    "\n",
    "    \n",
    "    prompt = f\"\"\"ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬, ì¹´ë“œ í˜œíƒ ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰ì— ê°€ì¥ ì í•©í•œ 2~3ê°œì˜ ìƒì„¸ ê²€ìƒ‰ ë¬¸ì¥ì„ ìƒì„±í•´ì¤˜.\n",
    "            [ê°€ì´ë“œ]\n",
    "            - ë‹¨ìˆœí•œ í‚¤ì›Œë“œê°€ ì•„ë‹Œ, í˜œíƒì˜ ì¢…ë¥˜ì™€ ëŒ€í‘œ ë¸Œëœë“œê°€ í¬í•¨ëœ ì§§ì€ ë¬¸ì¥ìœ¼ë¡œ ë§Œë“œì„¸ìš”.\n",
    "            - ì˜ˆ: \"ì»¤í”¼ í• ì¸ë˜ê³  êµí†µë¹„ ì•„ë¼ëŠ” ì¹´ë“œ\"\n",
    "            - ê²°ê³¼: [\"ìŠ¤íƒ€ë²…ìŠ¤ íˆ¬ì¸ ë“± ì»¤í”¼ ì „ë¬¸ì  í• ì¸ í˜œíƒ\", \"ë²„ìŠ¤ ì§€í•˜ì²  íƒì‹œ ëŒ€ì¤‘êµí†µ ì´ìš© í• ì¸ í˜œíƒ\"]\n",
    "            \n",
    "            ì§ˆë¬¸: {user_query}\n",
    "            í˜•ì‹: [\"ë¬¸ì¥1\", \"ë¬¸ì¥2\"] (JSON ë¦¬ìŠ¤íŠ¸ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”)\"\"\"\n",
    "    \n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.1,  # ê²€ìƒ‰ í‚¤ì›Œë“œ ì¶”ì¶œì€ 'ì •í™•ë„'ê°€ ìƒëª…ì´ë¯€ë¡œ ë‚®ì€ ê°’ì„ ì¶”ì²œ\n",
    "        top_p=0.9         # ë‹µë³€ì˜ ì¼ê´€ì„±ì„ ë†’ì´ê¸° ìœ„í•œ ë³´ì¡° ì„¤ì •\n",
    "    )\n",
    "    try:\n",
    "        return json.loads(response.choices[0].message.content)\n",
    "    except:\n",
    "        return [user_query]\n",
    "\n",
    "# ==========================================\n",
    "# [CORE] í†µí•© RAG í•¨ìˆ˜\n",
    "# ==========================================\n",
    "def card_concierge_rag(user_query, top_n=3):\n",
    "    \n",
    "    # [Step 1] ë™ì  ì˜ë„ ì¶”ì¶œ\n",
    "    search_intents = extract_search_intents(user_query)\n",
    "    print(f\"ì¶”ì¶œëœ í‚¤ì›Œë“œ: {search_intents}\")\n",
    "\n",
    "    # [Step 2] ChromaDB êµì°¨ ê²€ìƒ‰ (AND ë¡œì§)\n",
    "    intent_hits = []\n",
    "    for intent in search_intents:\n",
    "        query_text = f\"task: search result | query: {intent}\"\n",
    "        results = collection.query(\n",
    "            query_texts=[query_text],\n",
    "            n_results=200,\n",
    "            include=['metadatas']\n",
    "        )\n",
    "        ids = {m['card_id'] for m in results['metadatas'][0]}\n",
    "        intent_hits.append(ids)\n",
    "\n",
    "    # êµì§‘í•© í•„í„°ë§\n",
    "    common_ids = intent_hits[0]\n",
    "    for h in intent_hits[1:]:\n",
    "        common_ids &= h\n",
    "\n",
    "    if not common_ids:\n",
    "        print(\"âš ï¸ êµì§‘í•© ê²°ê³¼ê°€ ì—†ì–´ ë‹¨ì¼ ì˜ë„ ê²°ê³¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.\")\n",
    "        common_ids = intent_hits[0]\n",
    "\n",
    "    # [Step 3] Cohere v3.5 ë¦¬ë­í‚¹\n",
    "    candidate_ids = list(common_ids)\n",
    "    rerank_docs = []\n",
    "    for c_id in candidate_ids:\n",
    "        card = card_master_map[c_id]\n",
    "        context = f\"ì¹´ë“œëª…: {card['name']} | ìƒì„¸í˜œíƒ: {' '.join(card['full_details'])}\"\n",
    "        rerank_docs.append(context)\n",
    "\n",
    "    print(f\"Cohere v3.5 ë¦¬ë­í‚¹ ì¤‘... (í›„ë³´: {len(rerank_docs)}ê°œ)\")\n",
    "    rerank_response = co.rerank(\n",
    "        model=\"rerank-v3.5\",\n",
    "        query=user_query,\n",
    "        documents=rerank_docs,\n",
    "        top_n=top_n\n",
    "    )\n",
    "\n",
    "# [Step 4] ë°ì´í„° ë³µì› ë° LLM ë‹µë³€ ìƒì„± (GPT-5-Nano)\n",
    "    final_context = \"\"\n",
    "    for i, hit in enumerate(rerank_response.results):\n",
    "        best_id = candidate_ids[hit.index]\n",
    "        card = card_master_map[best_id]\n",
    "        # ìˆœìœ„ ì •ë³´ì™€ í•¨ê»˜ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±\n",
    "        final_context += f\"### [Top {i+1}] {card['name']} ({card['corp']})\\n\"\n",
    "        final_context += f\"- ì‹¤ì ì¡°ê±´: {card['structured']['condition']}\\n\"\n",
    "        final_context += f\"- ìƒì„¸ ë°ì´í„°: {' / '.join(card['full_details'])}\\n\\n\"\n",
    "\n",
    "    prompt = f\"\"\"ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ìµœê³ ì˜ 'ì‹ ìš©/ì²´í¬ì¹´ë“œ ì¶”ì²œ ì „ë¬¸ê°€'ì…ë‹ˆë‹¤. \n",
    "    ì œê³µëœ [ì¹´ë“œ ë°ì´í„°]ë¥¼ ë¶„ì„í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì „ë¬¸ì ì´ë©´ì„œë„ ë‹¤ì •í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.\n",
    "\n",
    "    ì‚¬ìš©ì ì§ˆë¬¸: {user_query}\n",
    "\n",
    "    [ì¹´ë“œ ë°ì´í„°]\n",
    "    {final_context}\n",
    "\n",
    "    [ë‹µë³€ ì‘ì„± ê°€ì´ë“œ]\n",
    "    1. **ì „ë¬¸ê°€ ì¸ì‚¬**: ì‚¬ìš©ìì˜ ì†Œë¹„ ë‹ˆì¦ˆë¥¼ ì •í™•íˆ ì§šì–´ì£¼ë©°, ì „ë¬¸ê°€ë¡œì„œ ì‹ ë¢°ê° ìˆê³  ë‹¤ì •í•œ ì¸ì‚¬ë¥¼ ê±´ë„¤ì„¸ìš”.\n",
    "    2. **Top 3 ëª©ë¡**: ì¶”ì²œí•˜ëŠ” ìƒìœ„ 3ê°œ ì¹´ë“œì˜ ì´ë¦„ê³¼ ì¹´ë“œì‚¬ë¥¼ ë°ì´í„° ìˆœì„œëŒ€ë¡œ ëª…í™•íˆ ë‚˜ì—´í•˜ì„¸ìš”.\n",
    "    3. **Top 1 ì‹¬ì¸µ ë¶„ì„**: 1ìœ„ë¡œ ì„ ì •ëœ ì¹´ë“œê°€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ í˜œíƒì„ êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–»ê²Œ ì œê³µí•˜ëŠ”ì§€(ìˆ˜ì¹˜, í• ì¸ í•œë„, ì‹¤ì  ì¡°ê±´ ë“±) ì „ë¬¸ê°€ì˜ ì‹œì„ ì—ì„œ ìƒì„¸íˆ ì„¤ëª…í•˜ì„¸ìš”.\n",
    "    4. **ì‹¤ì „ ì¡°ì–¸**: 1ìœ„ ì¹´ë“œë¥¼ ì‚¬ìš©í•  ë•Œ ì£¼ì˜í•´ì•¼ í•  ì „ì›” ì‹¤ì ì™¸ í•­ëª©ì´ë‚˜ í˜œíƒ ì œì™¸ ëŒ€ìƒ ë“±ì„ ë¹„ì„œì²˜ëŸ¼ ì„¸ì‹¬í•˜ê²Œ ì¡°ì–¸í•´ ì£¼ì„¸ìš”.\n",
    "    5. **í†¤ì•¤ë§¤ë„ˆ**: í‘œëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”. ì½ê¸° í¸í•œ ë¬¸ì¥ê³¼ ë¶ˆë › í¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ê³ , ì‚¬ìš©ìê°€ í˜œíƒì„ ì¶©ë¶„íˆ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì „ì²´ ë¶„ëŸ‰ì„ ì ì ˆíˆ ì¡°ì ˆí•˜ì„¸ìš”.\"\"\"\n",
    "\n",
    "    # gpt-4.1-mini í˜¸ì¶œ (íŒŒë¼ë¯¸í„° ìµœì í™”)\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\", \n",
    "                \"content\": \"ë‹¹ì‹ ì€ ì œê³µëœ ë°ì´í„°ì˜ ìˆœìœ„ë¥¼ ì—„ê²©íˆ ì¤€ìˆ˜í•˜ë©°, ì •í™•í•œ ìˆ˜ì¹˜ì— ê¸°ë°˜í•´ ì¡°ì–¸í•˜ëŠ” ì‹ ìš©ì¹´ë“œ ì¶”ì²œ ì „ë¬¸ê°€ Gemma-Botì…ë‹ˆë‹¤.\"\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.1,  # ì¼ê´€ì„± ìˆëŠ” ë‹µë³€ ìœ ë„\n",
    "        top_p=0.1,        # ìˆœìœ„ ë° íŒ©íŠ¸ ê³ ì •\n",
    "        max_tokens=1000   # ì ì ˆí•œ ë¶„ëŸ‰ í™•ë³´\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# ==========================================\n",
    "# ì‹¤í–‰ë¶€\n",
    "# ==========================================\n",
    "if __name__ == \"__main__\":\n",
    "    user_q = \"ì‚¬íšŒì´ˆë…„ìƒì¸ë° ë°°ë‹¬ì˜ë¯¼ì¡± ìš”ê¸°ìš” ì¿ íŒ¡ì´ì¸  ë°°ë‹¬ ìŒì‹ í• ì¸ í˜œíƒì´ ìˆê³ , ë„·í”Œë¦­ìŠ¤ ë””ì¦ˆë‹ˆí”ŒëŸ¬ìŠ¤ ì™“ì±  OTT ìŠ¤íŠ¸ë¦¬ë° í• ì¸ í˜œíƒë„ ìˆëŠ” ì¹´ë“œë¥¼ ì¶”ì²œí•´ì¤˜\"\n",
    "    \n",
    "    result = card_concierge_rag(user_q)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f765dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer you are loading from './models/gemma-300m-4080super-extreme' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n",
      "C:\\Users\\Jeon\\AppData\\Local\\Temp\\ipykernel_38488\\2004021981.py:52: DeprecationWarning: The class GemmaEmbeddingFunction does not implement __init__. This will be required in a future version.\n",
      "  embedding_function=GemmaEmbeddingFunction()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ì§ˆë¬¸ ë¶„ì„ ì¤‘...\n",
      "ğŸ¯ ì¶”ì¶œëœ ê²€ìƒ‰ ì˜ë„: ['ë°°ë‹¬ì˜ë¯¼ì¡± ìš”ê¸°ìš” ì¿ íŒ¡ì´ì¸  ë°°ë‹¬ ìŒì‹ í• ì¸', 'ë„·í”Œë¦­ìŠ¤ ë””ì¦ˆë‹ˆí”ŒëŸ¬ìŠ¤ ì™“ì±  OTT ìŠ¤íŠ¸ë¦¬ë° í• ì¸']\n",
      "\n",
      "âœ¨ [ê¸ˆìœµ ë¹„ì„œ Gemma-Bot ë‹µë³€]:\n",
      "\n",
      "ì•ˆë…•í•˜ì„¸ìš” ì „ì—¬ìš±ë‹˜ â€” ì‚¬íšŒì´ˆë…„ìƒì´ë¼ ì¹´ë“œ ê³ ë¥´ê¸° ê³ ë¯¼ ë§ìœ¼ì‹œì£ . ì°¨ê·¼ì°¨ê·¼ ë„ì™€ë“œë¦´ê²Œìš”. ë¨¼ì € ì œê³µí•´ì£¼ì‹  ì¹´ë“œ ë°ì´í„° ê¸°ì¤€ìœ¼ë¡œ ë¶„ì„í•œ ê²°ê³¼ì™€ ì‹¤ì „ íŒì„ ì •ë¦¬í•´ ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "- Top 3 ì¹´ë“œ (ì œê³µëœ ë°ì´í„° ê¸°ì¤€)\n",
      "  - ëŸ­í‚¤ ìœ ì¹´ë“œ (ì½”ë‚˜ì¹´ë“œ)\n",
      "  - ì•„ëª¨ë ˆí¼ì‹œí”½ IBKì¹´ë“œ (IBKê¸°ì—…ì€í–‰)\n",
      "  - I-Mileage (ì•„ì‹œì•„ë‚˜) (IBKê¸°ì—…ì€í–‰)\n",
      "\n",
      "- ì¤‘ìš”í•œ í™•ì¸ì‚¬í•­\n",
      "  - ì œê³µëœ ì¹´ë“œ ë°ì´í„°ì—ëŠ” ìš”ì²­í•˜ì‹  â€˜ë°°ë‹¬ì•±(ë°°ë‹¬ì˜ë¯¼ì¡±Â·ìš”ê¸°ìš”Â·ì¿ íŒ¡ì´ì¸ ) í• ì¸â€™ì´ë‚˜ â€˜OTT(ë„·í”Œë¦­ìŠ¤Â·ë””ì¦ˆë‹ˆí”ŒëŸ¬ìŠ¤Â·ì™“ì± ) ìŠ¤íŠ¸ë¦¬ë° í• ì¸â€™ì´ ëª…ì‹œëœ ì¹´ë“œëŠ” ì—†ìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ì´ ë°ì´í„° ë‚´ì—ì„œëŠ” ë°°ë‹¬ í• ì¸ê³¼ OTT í• ì¸ì„ ë™ì‹œì— ì¶©ì¡±í•˜ëŠ” ì¹´ë“œë¥¼ ì¶”ì²œë“œë¦¬ê¸° ì–´ë µìŠµë‹ˆë‹¤.\n",
      "\n",
      "- Top 1(ëŸ­í‚¤ ìœ ì¹´ë“œ) ìƒì„¸ í˜œíƒÂ·í•œë„\n",
      "  - ë°œê¸‰ì‚¬: ì½”ë‚˜ì¹´ë“œ\n",
      "  - ì „ì›” ì‹¤ì : ì „ì›” ì‹¤ì  ì¡°ê±´ ì—†ìŒ (ë°ì´í„°ìƒ ë³„ë„ ì‹¤ì  í•„ìš” ì—†ìŒ)\n",
      "  - í˜œíƒ í•­ëª© ë° ìˆ˜ì¹˜\n",
      "    - ì»¤í”¼ë¹ˆ 15% í• ì¸ â€” ê¸°ë³¸ í˜œíƒìœ¼ë¡œ, ë°ì´í„°ìƒ ì „ì›” ì‹¤ì  ì—†ì´ ì ìš©ë˜ëŠ” ê²ƒìœ¼ë¡œ í‘œê¸°ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
      "    - í”„ë¡œëª¨ì…˜: 1ë§Œì› ì´ìƒ ê²°ì œí•  ë•Œë§ˆë‹¤ â€˜4ê°œ í–‰ìš´ë²ˆí˜¸ ëŸ­í‚¤ê¶Œâ€™ 1ì¥ ë°œê¸‰ â€” ê²°ì œ 1ë§Œì› ë‹¨ìœ„ë¡œ ëŸ­í‚¤ê¶Œì„ ì§€ê¸‰(í”„ë¡œëª¨ì…˜ ê´€ë ¨ ì•ˆë‚´ëŠ” ìœ íŠœë¸Œ â€˜ëŸ­í‚¤ë¡œì½”ì‡¼â€™ ë“±ì—ì„œ í™•ì¸ ê°€ëŠ¥)\n",
      "  - í•œë„Â·íšŸìˆ˜\n",
      "    - ë°ì´í„°ì— ë³„ë„ì˜ ì›”ë³„/ì—°ê°„ í• ì¸í•œë„ë‚˜ íšŸìˆ˜ ì œí•œì€ ëª…ì‹œë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. (ë”°ë¼ì„œ ì‹¤ì œ ì•½ê´€ì—ì„œ í•œë„Â·ì œì™¸í•­ëª©ì„ ë°˜ë“œì‹œ í™•ì¸í•˜ì„¸ìš”.)\n",
      "  - ê¸°íƒ€\n",
      "    - ë°ì´í„°ì—ì„  ì»¤í”¼ í˜œíƒê³¼ í”„ë¡œëª¨ì…˜ë§Œ ëª…ì‹œë˜ì–´ ìˆìœ¼ë©°, ë°°ë‹¬Â·OTT ê´€ë ¨ í˜œíƒì€ í‘œê¸°ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
      "\n",
      "- ì‹¤ì „ íŒ (ê¼­ í™•ì¸í•˜ì„¸ìš”)\n",
      "  - ì œê³µ ë°ì´í„°ìƒ ì „ì›” ì‹¤ì  ì—†ìŒìœ¼ë¡œ í‘œê¸°ë˜ì–´ ìˆì§€ë§Œ, ì‹¤ì œë¡œëŠ” íŠ¹ì • í”„ë¡œëª¨ì…˜ì´ë‚˜ ê°€ë§¹ì Â·ê²°ì œìˆ˜ë‹¨(ì•±ê²°ì œÂ·ê°„í¸ê²°ì œÂ·ì •ê¸°ê²°ì œ ë“±)ì— ë”°ë¼ ì ìš© ì—¬ë¶€ê°€ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìœ¼ë‹ˆ ì•½ê´€Â·ìœ ì˜ì‚¬í•­ì„ í™•ì¸í•˜ì„¸ìš”.\n",
      "  - ì¹´ë“œ í˜œíƒì€ ì¢…ì¢… â€˜ì˜¨ë¼ì¸ ì˜ˆë§¤ ì œì™¸â€™, â€˜í”„ë¡œëª¨ì…˜ ê¸°ê°„ í•œì •â€™, â€˜ì¼ë¶€ ê°€ë§¹ì  ì œì™¸â€™ ë“± ì˜ˆì™¸ê°€ ìˆìœ¼ë‹ˆ ìƒì„¸ ì•½ê´€ê³¼ ì´ë²¤íŠ¸ ê³µì§€ë¥¼ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤.\n",
      "  - ì¼ë°˜ì ìœ¼ë¡œ ì¹´ë“œì‚¬ ì•½ê´€ì—ì„œ í• ì¸ ì œì™¸ í•­ëª©(í˜„ê¸ˆì„œë¹„ìŠ¤Â·ì´ìÂ·ì„¸ê¸ˆÂ·ìƒí’ˆê¶Œ êµ¬ë§¤Â·ì„ ë¶ˆì¹´ë“œ ì¶©ì „ ë“±)ì€ ê³µí†µì ìœ¼ë¡œ ì¡´ì¬í•˜ë¯€ë¡œ ìœ ì˜í•˜ì„¸ìš”.\n",
      "  - ì›í•˜ì‹œë©´ ì „ëµ ì œì•ˆ:\n",
      "    - í•œ ì¥ìœ¼ë¡œ ëª¨ë‘ ì¶©ì¡±ë˜ëŠ” ì¹´ë“œë¥¼ ì°¾ê¸°ë³´ë‹¤, ë°°ë‹¬ ì „ìš© í• ì¸ ì¹´ë“œ + OTT ì „ìš© í• ì¸ ì¹´ë“œ ê°ê° í•œ ì¥ì”© ì¡°í•©í•˜ëŠ” ê²ƒì´ í˜„ì‹¤ì ì´ê³  í˜œíƒ ê·¹ëŒ€í™”ì— ìœ ë¦¬í•©ë‹ˆë‹¤.\n",
      "    - ì£¼ìš” ì¹´ë“œì‚¬(ì‹ í•œÂ·êµ­ë¯¼Â·ì‚¼ì„±Â·í˜„ëŒ€ ë“±)ì˜ â€˜ë°°ë‹¬ íŠ¹í™”â€™ ì¹´ë“œì™€ â€˜ì½˜í…ì¸ /êµ¬ë…â€™ íŠ¹í™” ì¹´ë“œë¥¼ ë¹„êµí•´ ë³´ì„¸ìš”.\n",
      "\n",
      "- ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ\n",
      "  - ì œê°€ ì œê³µëœ ë°ì´í„° ë°–ì—ì„œ ë°°ë‹¬Â·OTT í˜œíƒì´ í™•ì‹¤íˆ ë¶™ì€ ì¹´ë“œë“¤ì„ ì°¾ì•„ ì¶”ì²œí•´ ë“œë¦´ê²Œìš”. \n",
      "  - ìš°ì„ ìˆœìœ„ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”: (1) ë°°ë‹¬ í• ì¸ ìš°ì„ , (2) OTT í• ì¸ ìš°ì„ , (3) í•œ ì¥ìœ¼ë¡œ ê°€ëŠ¥í•œ ìµœëŒ€ ì¡°í•© â€” ì–´ë–¤ ê±¸ ì›í•˜ì‹œë‚˜ìš”?\n",
      "\n",
      "ì›í•˜ì‹œë©´ ë°”ë¡œ ì™¸ë¶€ ì¹´ë“œ ìƒí’ˆë“¤ì„ ì¡°ì‚¬í•´ì„œ ë°°ë‹¬ì•±Â·OTTë³„ë¡œ êµ¬ì²´ì  ì¹´ë“œ ì¶”ì²œê³¼ ì˜ˆìƒ í˜œíƒ ê³„ì‚°ê¹Œì§€ í•´ë“œë¦´ê²Œìš”. ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ ë„ì™€ë“œë¦´ê¹Œìš”?\n"
     ]
    }
   ],
   "source": [
    "# ë¦¬ë­í‚¹ ì œì™¸ ë²„ì „\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "import chromadb\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "# 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (OpenAI API í‚¤ ë“±)\n",
    "load_dotenv()\n",
    "OPENAI_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# 2. ë¡œì»¬ ê²½ë¡œ ë° ì„¤ì •\n",
    "INPUT_FILE = './data/FINAL_MASTER_DATA_FIXED_7757.json'\n",
    "MODEL_PATH = './models/gemma-300m-4080super-extreme'    # í•™ìŠµì‹œí‚¨ Gemma ëª¨ë¸\n",
    "CHROMA_DB_PATH = './data/chroma_db'\n",
    "\n",
    "# 3. ëª¨ë¸ ë° í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "bi_encoder = SentenceTransformer(MODEL_PATH, device=device)\n",
    "openai_client = OpenAI(api_key=OPENAI_KEY)\n",
    "\n",
    "# 4. ë°ì´í„° ë¦¬í•˜ì´ë“œë ˆì´ì…˜ ë§µ ìƒì„± (ID ê¸°ë°˜ ìƒì„¸ ë°ì´í„° ë³µì›ìš©)\n",
    "with open(INPUT_FILE, 'r', encoding='utf-8') as f:\n",
    "    master_data = json.load(f)\n",
    "\n",
    "card_master_map = {}\n",
    "for item in master_data:\n",
    "    c_id = item['metadata']['card_id']\n",
    "    if c_id not in card_master_map:\n",
    "        card_master_map[c_id] = {\n",
    "            \"name\": item['metadata']['card_name'],\n",
    "            \"corp\": item['metadata']['corp'],\n",
    "            \"full_details\": [item['content']], \n",
    "            \"structured\": item['ai_structured']\n",
    "        }\n",
    "    else:\n",
    "        card_master_map[c_id][\"full_details\"].append(item['content'])\n",
    "\n",
    "# 5. ChromaDB ì—°ê²° ë° ì»¤ìŠ¤í…€ ì„ë² ë”© í•¨ìˆ˜ ì„¤ì •\n",
    "class GemmaEmbeddingFunction(embedding_functions.EmbeddingFunction):\n",
    "    def __call__(self, input_texts):\n",
    "        # í•™ìŠµ ì‹œ ì‚¬ìš©í•œ ì ‘ë‘ì‚¬(Prefix) ì ìš©\n",
    "        passages = [f\"title: none | text: {text}\" for text in input_texts]\n",
    "        return bi_encoder.encode(passages, convert_to_tensor=False).tolist()\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path=CHROMA_DB_PATH)\n",
    "collection = chroma_client.get_collection(\n",
    "    name=\"card_benefits\", \n",
    "    embedding_function=GemmaEmbeddingFunction()\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# [HELPER] ë™ì  ì˜ë„ ì¶”ì¶œ í•¨ìˆ˜ (GPT-4.1 mini ì‚¬ìš©)\n",
    "# ==========================================\n",
    "def extract_search_intents(user_query):\n",
    "    \"\"\"ì‚¬ìš©ìì˜ ë³µí•© ì§ˆë¬¸ì„ ê²€ìƒ‰ì— ìµœì í™”ëœ ê°œë³„ ì˜ë„ë¡œ ë¶„ë¦¬í•©ë‹ˆë‹¤.\"\"\"\n",
    "    prompt = f\"\"\"ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬, ì¹´ë“œ í˜œíƒ ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰ì— ê°€ì¥ ì í•©í•œ 2~3ê°œì˜ ìƒì„¸ ê²€ìƒ‰ ë¬¸ì¥ì„ ìƒì„±í•´ì¤˜.\n",
    "            [ê°€ì´ë“œ]\n",
    "            - ë‹¨ìˆœ í‚¤ì›Œë“œê°€ ì•„ë‹Œ ë¸Œëœë“œë¥¼ í¬í•¨í•œ êµ¬ì²´ì ì¸ í˜œíƒ ë¬¸ì¥ìœ¼ë¡œ ë§Œë“œì„¸ìš”.\n",
    "            - ì˜ˆ: \"ìŠ¤íƒ€ë²…ìŠ¤ ì»¤í”¼ í• ì¸\", \"ë°°ë¯¼/ìš”ê¸°ìš” ë°°ë‹¬ í• ì¸\"\n",
    "            \n",
    "            ì§ˆë¬¸: {user_query}\n",
    "            í˜•ì‹: [\"ë¬¸ì¥1\", \"ë¬¸ì¥2\"] (JSON ë¦¬ìŠ¤íŠ¸ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”)\"\"\"\n",
    "    \n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    try:\n",
    "        return json.loads(response.choices[0].message.content)\n",
    "    except:\n",
    "        return [user_query]\n",
    "\n",
    "# ==========================================\n",
    "# [CORE] í†µí•© RAG í•¨ìˆ˜ (ë¦¬ë­í‚¹ ì œì™¸ ìµœì í™” ë²„ì „)\n",
    "# ==========================================\n",
    "def card_concierge_rag(user_query, top_n=3):\n",
    "    print(f\"ğŸ” ì§ˆë¬¸ ë¶„ì„ ì¤‘...\")\n",
    "    search_intents = extract_search_intents(user_query)\n",
    "    print(f\"ğŸ¯ ì¶”ì¶œëœ ê²€ìƒ‰ ì˜ë„: {search_intents}\")\n",
    "\n",
    "    # [Step 1] ê° ì˜ë„ë³„ ê²€ìƒ‰ ë° ì ìˆ˜ í•©ì‚°\n",
    "    card_scores = {} # {card_id: [score1, score2, ...]}\n",
    "\n",
    "    for intent in search_intents:\n",
    "        query_text = f\"task: search result | query: {intent}\"\n",
    "        results = collection.query(\n",
    "            query_texts=[query_text],\n",
    "            n_results=1000,  # í›„ë³´êµ° ìˆ˜ì§‘\n",
    "            include=['metadatas', 'distances']\n",
    "        )\n",
    "        \n",
    "        for i in range(len(results['metadatas'][0])):\n",
    "            m = results['metadatas'][0][i]\n",
    "            dist = results['distances'][0][i]\n",
    "            c_id = m['card_id']\n",
    "            # ì½”ì‚¬ì¸ ê±°ë¦¬(Distance)ë¥¼ ìœ ì‚¬ë„ ì ìˆ˜(Score)ë¡œ ë³€í™˜ (1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìœ ì‚¬)\n",
    "            score = 1 - dist\n",
    "            \n",
    "            if c_id not in card_scores:\n",
    "                card_scores[c_id] = []\n",
    "            card_scores[c_id].append(score)\n",
    "\n",
    "    # [Step 2] êµì§‘í•©(Intersection) ê¸°ë°˜ ìµœì¢… í›„ë³´ ì„ ì •\n",
    "    final_candidates = []\n",
    "    num_required_intents = len(search_intents)\n",
    "\n",
    "    for c_id, scores in card_scores.items():\n",
    "        # ëª¨ë“  ê²€ìƒ‰ ì˜ë„ì—ì„œ ê³µí†µì ìœ¼ë¡œ ë°œê²¬ëœ ì¹´ë“œë§Œ í•„í„°ë§ (AND ë¡œì§)\n",
    "        if len(scores) == num_required_intents:\n",
    "            avg_score = sum(scores) / num_required_intents\n",
    "            final_candidates.append((c_id, avg_score))\n",
    "\n",
    "    # êµì§‘í•© ê²°ê³¼ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ë‹¨ì¼ ì˜ë„ ìƒìœ„ ê²°ê³¼ë¡œ ë³´ì™„\n",
    "    if len(final_candidates) < top_n:\n",
    "        print(\"âš ï¸ ëª¨ë“  ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì¹´ë“œê°€ ë¶€ì¡±í•˜ì—¬ ìœ ì‚¬ë„ ê¸°ë°˜ìœ¼ë¡œ ë³´ì™„í•©ë‹ˆë‹¤.\")\n",
    "        for c_id, scores in card_scores.items():\n",
    "            if (c_id, sum(scores)/len(scores)) not in final_candidates:\n",
    "                final_candidates.append((c_id, max(scores)))\n",
    "\n",
    "    # ì ìˆ˜ ë†’ì€ ìˆœ ì •ë ¬\n",
    "    final_candidates = sorted(final_candidates, key=lambda x: x[1], reverse=True)[:top_n]\n",
    "\n",
    "    # [Step 3] ë°ì´í„° ë³µì› ë° ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±\n",
    "    final_context = \"\"\n",
    "    for i, (c_id, score) in enumerate(final_candidates):\n",
    "        card = card_master_map[c_id]\n",
    "        final_context += f\"### [Top {i+1}] {card['name']} ({card['corp']})\\n\"\n",
    "        final_context += f\"- ê²€ìƒ‰ ë§¤ì¹­ ì ìˆ˜: {score:.4f}\\n\"\n",
    "        final_context += f\"- ì‹¤ì  ì¡°ê±´: {card['structured']['condition']}\\n\"\n",
    "        final_context += f\"- ìƒì„¸ í˜œíƒ: {' / '.join(card['full_details'][:2])}\\n\\n\" # ê°€ë…ì„±ì„ ìœ„í•´ ìƒìœ„ 2ê°œ í˜œíƒ ìœ„ì£¼\n",
    "\n",
    "    # [Step 4] ìµœì¢… ë‹µë³€ ìƒì„± (GPT-5-mini ì‚¬ìš©)\n",
    "    prompt = f\"\"\"ë‹¹ì‹ ì€ ì „ì—¬ìš±ë‹˜ì˜ ë“ ë“ í•œ 'ê¸ˆìœµ ë¹„ì„œ Gemma-Bot'ì…ë‹ˆë‹¤. \n",
    "ì œê³µëœ [ì¹´ë“œ ë°ì´í„°]ë¥¼ ë¶„ì„í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹¤ì •í•˜ê³  ëª…í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.\n",
    "\n",
    "ì‚¬ìš©ì ì§ˆë¬¸: {user_query}\n",
    "\n",
    "[ì¹´ë“œ ë°ì´í„°]\n",
    "{final_context}\n",
    "\n",
    "[ë‹µë³€ ì‘ì„± ê°€ì´ë“œ]\n",
    "1. **ì¹œì ˆí•œ ì¸ì‚¬**: ì‚¬ìš©ìì˜ ìƒí™©(ì‚¬íšŒì´ˆë…„ìƒ ë“±)ì„ ê³µê°í•˜ë©° ì‹œì‘í•˜ì„¸ìš”.\n",
    "2. **Top 3 ëª©ë¡**: ì¶”ì²œí•˜ëŠ” ì¹´ë“œì˜ ì´ë¦„ê³¼ ì¹´ë“œì‚¬ë¥¼ ë‚˜ì—´í•˜ì„¸ìš”.\n",
    "3. **Top 1 ì§‘ì¤‘ ë¶„ì„**: 1ìœ„ ì¹´ë“œì˜ í˜œíƒ ìˆ˜ì¹˜ì™€ í•œë„ë¥¼ ì•„ì£¼ ìƒì„¸íˆ ì„¤ëª…í•˜ì„¸ìš”.\n",
    "4. **ì‹¤ì „ íŒ**: ì „ì›” ì‹¤ì  ì œì™¸ í•­ëª© ë“± ì£¼ì˜ì‚¬í•­ì„ ì¡°ì–¸í•˜ì„¸ìš”.\n",
    "5. **í†¤ì•¤ë§¤ë„ˆ**: í‘œ ì—†ì´ ë¶ˆë › í¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ê³ , ì „ë¬¸ì ì´ë©´ì„œë„ ë”°ëœ»í•œ ì–´ì¡°ë¥¼ ìœ ì§€í•˜ì„¸ìš”.\"\"\"\n",
    "\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-5-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"ë°ì´í„° ê¸°ë°˜ì˜ ì •í™•í•˜ê³  ë‹¤ì •í•œ ê¸ˆìœµ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# ==========================================\n",
    "# ì‹¤í–‰ë¶€\n",
    "# ==========================================\n",
    "if __name__ == \"__main__\":\n",
    "    user_q = \"ì‚¬íšŒì´ˆë…„ìƒì¸ë° ë°°ë‹¬ì˜ë¯¼ì¡± ìš”ê¸°ìš” ì¿ íŒ¡ì´ì¸  ë°°ë‹¬ ìŒì‹ í• ì¸ í˜œíƒì´ ìˆê³ , ë„·í”Œë¦­ìŠ¤ ë””ì¦ˆë‹ˆí”ŒëŸ¬ìŠ¤ ì™“ì±  OTT ìŠ¤íŠ¸ë¦¬ë° í• ì¸ í˜œíƒë„ ìˆëŠ” ì¹´ë“œë¥¼ ì¶”ì²œí•´ì¤˜\"\n",
    "    \n",
    "    result = card_concierge_rag(user_q)\n",
    "    print(\"\\nâœ¨ [ê¸ˆìœµ ë¹„ì„œ Gemma-Bot ë‹µë³€]:\\n\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be146508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== CARD FACT CHECK ==============================\n",
      "ğŸ’³ ì¹´ë“œëª…: ì‚¼ì„± iD SELECT ALL ì¹´ë“œ (ì‚¼ì„±ì¹´ë“œ)\n",
      "ğŸ†” Card ID: 2885\n",
      "ğŸ’° ì—°íšŒë¹„: êµ­ë‚´ì „ìš© [20,000]ì› / í•´ì™¸ê²¸ìš© [20,000]ì›\n",
      "ğŸ“‰ ìµœì†Œì‹¤ì : 400000ì›\n",
      "=============================================================================\n",
      "\n",
      "[1] ì¹´í…Œê³ ë¦¬: ê¸°ë³¸/ì „ê°€ë§¹ì  > ì„ íƒí˜• (ì„ íƒí˜•)\n",
      "   ğŸ“ AI ìš”ì•½: ì‚¼ì„± iD SELECT ALL ì¹´ë“œì—ì„œ ì„ íƒí•œ ì˜µì…˜ì— ë”°ë¼ ë‹¤ì–‘í•œ í• ì¸ í˜œíƒì„ ì œê³µí•©ë‹ˆë‹¤.\n",
      "   ğŸ¢ ì£¼ìš” ê°€ë§¹ì : êµ­ë‚´ ê°€ë§¹ì , ì˜¨ë¼ì¸ì‡¼í•‘ëª°, ì˜ë£Œ, ë°°ë‹¬ì•±, ìŒì‹ì , í¸ì˜ì , í• ì¸ì , ì£¼ìœ \n",
      "   âœ… ìƒì„¸ ì¡°ê±´: ì „ì›” ì‹¤ì  ì¡°ê±´ ìš”ì•½ ì •ë³´ ì—†ìŒ\n",
      "   ğŸ’¡ í˜œíƒ ìƒì„¸: êµ­ë‚´ ê°€ë§¹ì  0.7% í• ì¸, ì•„íŒŒíŠ¸ ê´€ë¦¬ë¹„ 10% í• ì¸, í†µì‹  10% í• ì¸, êµìœ¡ 10% í• ì¸, ì˜¨ë¼ì¸ì‡¼í•‘ëª° 7% í• ì¸, ì˜ë£Œ 7% í• ì¸, ë°°ë‹¬ì•± 7% í• ì¸, ìŒì‹ì  7% í• ì¸, í¸ì˜ì  7% í• ì¸, í• ì¸ì  7% í• ì¸, ì£¼ìœ  7% í• ì¸\n",
      "   âš ï¸ ì‹¤ì  ì œì™¸: ['ì „ì›” ì‹¤ì  ê³„ì‚°ì—ì„œ ì œì™¸ë˜ëŠ” í•­ëª© ì •ë³´ ì—†ìŒ']\n",
      "-----------------------------------------------------------------------------\n",
      "[2] ì¹´í…Œê³ ë¦¬: ê¸°ë³¸/ì „ê°€ë§¹ì  > í• ì¸ (í• ì¸)\n",
      "   ğŸ“ AI ìš”ì•½: ì‚¼ì„± iD SELECT ALL ì¹´ë“œë¡œ ë‹¤ì–‘í•œ ê°€ë§¹ì ì—ì„œ í• ì¸ í˜œíƒì„ ì œê³µí•©ë‹ˆë‹¤.\n",
      "   ğŸ¢ ì£¼ìš” ê°€ë§¹ì : êµ­ë‚´ ê°€ë§¹ì , ì•„íŒŒíŠ¸ ê´€ë¦¬ë¹„, í†µì‹ , êµìœ¡, ì˜¨ë¼ì¸ì‡¼í•‘ëª°, ì˜ë£Œ, ë°°ë‹¬ì•±, ìŒì‹ì , í¸ì˜ì , í• ì¸ì , ì£¼ìœ \n",
      "   âœ… ìƒì„¸ ì¡°ê±´: ì „ì›” ì‹¤ì ì— ê´€ê³„ì—†ì´ í• ì¸ ì œê³µ, ì „ì›” ì‹¤ì  40ë§Œì› ë¯¸ë§Œ ì‹œì—ë„ í˜œíƒ ì œê³µ\n",
      "   ğŸ’¡ í˜œíƒ ìƒì„¸: {'êµ­ë‚´ ê°€ë§¹ì ': '0.7% í• ì¸', 'ì•„íŒŒíŠ¸ ê´€ë¦¬ë¹„, í†µì‹ ': '10% í• ì¸', 'êµìœ¡': '10% í• ì¸', 'ì˜¨ë¼ì¸ì‡¼í•‘, ì˜ë£Œ, ë°°ë‹¬ì•±': '7% í• ì¸', 'ìŒì‹ì , í¸ì˜ì , í• ì¸ì , ì£¼ìœ ': '7% í• ì¸'}\n",
      "-----------------------------------------------------------------------------\n",
      "[3] ì¹´í…Œê³ ë¦¬: ì‡¼í•‘/ìƒí™œ > ìƒí™œ (ìƒí™œ)\n",
      "   ğŸ“ AI ìš”ì•½: ì‚¼ì„± iD SELECT ALL ì¹´ë“œë¡œ ìƒí™œ í¸ì˜ ì˜ì—­ì—ì„œ 5% í• ì¸ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
      "   ğŸ¢ ì£¼ìš” ê°€ë§¹ì : ë‹¤ì´ì†Œ, NOL í‹°ì¼“, ì•Œë¼ë”˜, ì™€ì¸ì•¤ëª¨ì–´\n",
      "   âœ… ìƒì„¸ ì¡°ê±´: ì „ì›” ì´ìš©ê¸ˆì•¡ 40ë§Œì› ì´ìƒ ì‹œ ì œê³µ\n",
      "   ğŸ’¡ í˜œíƒ ìƒì„¸: 5% í• ì¸\n",
      "-----------------------------------------------------------------------------\n",
      "[4] ì¹´í…Œê³ ë¦¬: ë””ì§€í„¸/í†µì‹  > ë””ì§€í„¸êµ¬ë… (ë””ì§€í„¸êµ¬ë…)\n",
      "   ğŸ“ AI ìš”ì•½: ë””ì§€í„¸ ì½˜í…ì¸  ë° ë©¤ë²„ì‹­ì— ëŒ€í•´ 50% í• ì¸ í˜œíƒì„ ì œê³µí•©ë‹ˆë‹¤.\n",
      "   ğŸ¢ ì£¼ìš” ê°€ë§¹ì : ë„·í”Œë¦­ìŠ¤, ë””ì¦ˆë‹ˆ+, ìœ íŠœë¸Œ, í‹°ë¹™, ì¿ íŒ¡ ì™€ìš° ë©¤ë²„ì‹­, ë„¤ì´ë²„í”ŒëŸ¬ìŠ¤ ë©¤ë²„ì‹­\n",
      "   âœ… ìƒì„¸ ì¡°ê±´: ì „ì›” ì‹¤ì  40ë§Œì› ì´ìƒ ì‹œ ì œê³µ, ë°œê¸‰ì›” +1ê°œì›”ê¹Œì§€ëŠ” 40ë§Œì› ë¯¸ë§Œ ì‹œì—ë„ ì œê³µ\n",
      "   ğŸ’¡ í˜œíƒ ìƒì„¸: ë””ì§€í„¸ ì½˜í…ì¸  ë° ë©¤ë²„ì‹­ ì •ê¸°ê²°ì œ ì‹œ 50% í• ì¸, í†µí•© ì›” í• ì¸í•œë„ 5,000ì›\n",
      "-----------------------------------------------------------------------------\n",
      "[5] ì¹´í…Œê³ ë¦¬: ì—¬í–‰/í”„ë¦¬ë¯¸ì—„ > í•´ì™¸ (í•´ì™¸)\n",
      "   ğŸ“ AI ìš”ì•½: í•´ì™¸ ê°€ë§¹ì  ë° í•´ì™¸ ì§ì ‘êµ¬ë§¤ ì‹œ 2% í• ì¸ í˜œíƒ ì œê³µ\n",
      "   ğŸ¢ ì£¼ìš” ê°€ë§¹ì : í•´ì™¸ ê°€ë§¹ì , í•´ì™¸ ì§ì ‘êµ¬ë§¤\n",
      "   âœ… ìƒì„¸ ì¡°ê±´: ì „ì›” ì‹¤ì ì— ê´€ê³„ì—†ì´\n",
      "   ğŸ’¡ í˜œíƒ ìƒì„¸: í•´ì™¸ ê²°ì œ ì‹œ 2% í• ì¸, í• ì¸ í•œë„ ì—†ìŒ\n",
      "-----------------------------------------------------------------------------\n",
      "[6] ì¹´í…Œê³ ë¦¬: ê¸°íƒ€/ì•ˆë‚´ > ìœ ì˜ì‚¬í•­ (ìœ ì˜ì‚¬í•­)\n",
      "   ğŸ“ AI ìš”ì•½: ì‚¼ì„± iD SELECT ALL ì¹´ë“œëŠ” ë‹¤ì–‘í•œ í• ì¸ í˜œíƒê³¼ í¬ì¸íŠ¸ ì ë¦½ì„ ì œê³µí•˜ëŠ” ì¹´ë“œì…ë‹ˆë‹¤.\n",
      "   ğŸ¢ ì£¼ìš” ê°€ë§¹ì : í†µì‹ , êµìœ¡, ìŒì‹ì , í¸ì˜ì , í• ì¸ì , ì£¼ìœ , ì˜¨ë¼ì¸ì‡¼í•‘ëª°, ì˜ë£Œ, ë°°ë‹¬ì•±\n",
      "   âœ… ìƒì„¸ ì¡°ê±´: ì „ì›” ì‹¤ì  ê¸°ì¤€ìœ¼ë¡œ ë§¤ì›” 1ì¼ë¶€í„° ë§ì¼ê¹Œì§€ ì´ìš©í•œ ì¼ì‹œë¶ˆ ë° í• ë¶€ ì´ìš©ê¸ˆì•¡ì— ë”°ë¼ í˜œíƒ ì œê³µ\n",
      "   ğŸ’¡ í˜œíƒ ìƒì„¸: í†µì‹ , êµìœ¡ 10% í• ì¸, ìŒì‹ì , í¸ì˜ì , í• ì¸ì , ì£¼ìœ , ì˜¨ë¼ì¸ì‡¼í•‘ëª°, ì˜ë£Œ, ë°°ë‹¬ì•± 7% í• ì¸\n",
      "   âš ï¸ ì‹¤ì  ì œì™¸: ['ë‹¨ê¸°ì¹´ë“œëŒ€ì¶œ', 'ì¥ê¸°ì¹´ë“œëŒ€ì¶œ', 'ê°ì¢… ìˆ˜ìˆ˜ë£Œ ë° ì´ì', 'ì—°ì²´ë£Œ', 'ì—°íšŒë¹„ ë‚©ë¶€ê±´', 'ë¶€ë™ì‚° ì„ëŒ€ë£Œ', 'í•™êµë‚©ì…ê¸ˆ', 'êµ­ì„¸', 'ì§€ë°©ì„¸', 'ê³µê³¼ê¸ˆ']\n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def print_all_card_details(target_card_id):\n",
    "    # 1. í•´ë‹¹ IDì— ë§ëŠ” ëª¨ë“  ì¡°ê°(fragments) ì°¾ê¸°\n",
    "    card_fragments = [item for item in master_data if item['metadata']['card_id'] == target_card_id]\n",
    "    \n",
    "    if not card_fragments:\n",
    "        print(f\"âŒ ID {target_card_id}ì— í•´ë‹¹í•˜ëŠ” ì¹´ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "\n",
    "    # 2. ê³µí†µ ì •ë³´ ì¶œë ¥ (ì²« ë²ˆì§¸ ì¡°ê° ê¸°ì¤€)\n",
    "    base_info = card_fragments[0]['metadata']\n",
    "    print(f\"\\n{'='*30} CARD FACT CHECK {'='*30}\")\n",
    "    print(f\"ğŸ’³ ì¹´ë“œëª…: {base_info['card_name']} ({base_info['corp']})\")\n",
    "    print(f\"ğŸ†” Card ID: {base_info['card_id']}\")\n",
    "    print(f\"ğŸ’° ì—°íšŒë¹„: {base_info['annual_fee']}\")\n",
    "    print(f\"ğŸ“‰ ìµœì†Œì‹¤ì : {base_info['min_performance']}ì›\")\n",
    "    print(f\"{'='*77}\\n\")\n",
    "\n",
    "    # 3. ê° í˜œíƒ ì¹´í…Œê³ ë¦¬ë³„ ìƒì„¸ ë‚´ìš© ì¶œë ¥\n",
    "    for i, fragment in enumerate(card_fragments):\n",
    "        meta = fragment['metadata']\n",
    "        ai = fragment['ai_structured']\n",
    "        \n",
    "        print(f\"[{i+1}] ì¹´í…Œê³ ë¦¬: {meta['main_category']} > {meta['sub_category']} ({meta['category']})\")\n",
    "        print(f\"   ğŸ“ AI ìš”ì•½: {ai['summary']}\")\n",
    "        print(f\"   ğŸ¢ ì£¼ìš” ê°€ë§¹ì : {', '.join(ai['merchants'])}\")\n",
    "        print(f\"   âœ… ìƒì„¸ ì¡°ê±´: {ai['condition']}\")\n",
    "        print(f\"   ğŸ’¡ í˜œíƒ ìƒì„¸: {ai['benefit_detail']}\")\n",
    "        \n",
    "        # ì‹¤ì  ì œì™¸ í•­ëª©ì´ë‚˜ ìœ ì˜ì‚¬í•­ì´ ìˆë‹¤ë©´ ì¶”ê°€ ì¶œë ¥\n",
    "        if ai.get('performance_exclusions') and ai['performance_exclusions'][0] != \"ì •ë³´ ì—†ìŒ\":\n",
    "            print(f\"   âš ï¸ ì‹¤ì  ì œì™¸: {ai['performance_exclusions']}\")\n",
    "        \n",
    "        print(\"-\" * 77)\n",
    "\n",
    "print_all_card_details(2885)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sesac-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
