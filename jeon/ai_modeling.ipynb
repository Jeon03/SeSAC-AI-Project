{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ac568a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentence-transformers pandas scikit-learn torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae6c33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "346d7a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2340747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U sentence_transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b86d3a",
   "metadata": {},
   "source": [
    "# 2. ë°ì´í„°ì…‹ ë¡œë“œ ë° ë¶„í•  (Train,Val,Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969a5461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses, evaluation\n",
    "\n",
    "# 1. ëª¨ë¸ ë° ë°ì´í„° ë¡œë“œ (ê²½ë¡œëŠ” ì—¬ìš±ë‹˜ í™˜ê²½ì— ë§ì¶° í™•ì¸í•´ ì£¼ì„¸ìš”)\n",
    "model_id = \"google/embeddinggemma-300m\"\n",
    "model = SentenceTransformer(model_id)\n",
    "\n",
    "def load_json_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# ë°ì´í„° ê²½ë¡œ ë‹¤ì‹œ í•œ ë²ˆ ì²´í¬!\n",
    "train_data = load_json_data('./data/train_dataset.json')\n",
    "val_data = load_json_data('./data/val_dataset.json')\n",
    "\n",
    "# 2. í•™ìŠµìš© ë°ì´í„° ê°ì²´(InputExample) ìƒì„±\n",
    "train_examples = [\n",
    "    InputExample(texts=[item['anchor'], item['positive'], item['negative']])\n",
    "    for item in train_data\n",
    "]\n",
    "\n",
    "# 3. ë°ì´í„° ë¡œë” ë° ì†ì‹¤ í•¨ìˆ˜ ì„¤ì •\n",
    "# Batch SizeëŠ” ì—¬ìš±ë‹˜ PC ì‚¬ì–‘ì— ë§ì¶° 16~32 ì‚¬ì´ë¡œ ì¡°ì ˆí•˜ì„¸ìš”.\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model)\n",
    "\n",
    "# 4. ê²€ì¦ê¸°(Evaluator) ì„¤ì •\n",
    "# í•™ìŠµ ì¤‘ê°„ì— ëª¨ë¸ì˜ ì‹¤ë ¥ì´ ì–¼ë§ˆë‚˜ ëŠ˜ì—ˆëŠ”ì§€ ì²´í¬í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.\n",
    "queries = {str(i): item['anchor'] for i, item in enumerate(val_data)}\n",
    "corpus = {str(i): item['positive'] for i, item in enumerate(val_data)}\n",
    "relevant_docs = {str(i): {str(i)} for i, item in enumerate(val_data)}\n",
    "\n",
    "evaluator = evaluation.InformationRetrievalEvaluator(\n",
    "    queries, corpus, relevant_docs, name=\"card-val-task\"\n",
    ")\n",
    "\n",
    "# 5. í•™ìŠµ ì‹¤í–‰ (model.fit ë°©ì‹ - ëª¨ë“  ë²„ì „ì—ì„œ í˜¸í™˜ë¨)\n",
    "print(\"ğŸš€ [ì•ˆì „ ëª¨ë“œ] Gemma-300M í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    evaluator=evaluator,\n",
    "    epochs=3,                  # ì „ì²´ ë°ì´í„°ë¥¼ 3ë²ˆ í›‘ìŠµë‹ˆë‹¤.\n",
    "    warmup_steps=100,          # ì´ˆê¸° ì•ˆì •í™” ë‹¨ê³„\n",
    "    output_path=\"./models/gemma-300m-finetuned-card\",\n",
    "    evaluation_steps=200,      # 200ë²ˆì˜ ê±¸ìŒë§ˆë‹¤ ì‹œí—˜ì„ ë´…ë‹ˆë‹¤.\n",
    "    save_best_model=True,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "print(\"âœ¨ ëª¨ë“  ê³¼ì •ì´ ëë‚¬ìŠµë‹ˆë‹¤! ./models/gemma-300m-finetuned-card í´ë”ë¥¼ í™•ì¸í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ee5a1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ [Extreme Mode] RTX 4080 Super ê°€ë™! (Batch: 128)\n",
      "ğŸ› ï¸ í™œì„±í™” ê¸°ìˆ : AMP(í˜¼í•©ì •ë°€ë„) + Gradient Checkpointing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e06dae58d3a4107ae13911b7848d035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='490' max='490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [490/490 20:13, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Card-val-task Cosine Accuracy@1</th>\n",
       "      <th>Card-val-task Cosine Accuracy@3</th>\n",
       "      <th>Card-val-task Cosine Accuracy@5</th>\n",
       "      <th>Card-val-task Cosine Accuracy@10</th>\n",
       "      <th>Card-val-task Cosine Precision@1</th>\n",
       "      <th>Card-val-task Cosine Precision@3</th>\n",
       "      <th>Card-val-task Cosine Precision@5</th>\n",
       "      <th>Card-val-task Cosine Precision@10</th>\n",
       "      <th>Card-val-task Cosine Recall@1</th>\n",
       "      <th>Card-val-task Cosine Recall@3</th>\n",
       "      <th>Card-val-task Cosine Recall@5</th>\n",
       "      <th>Card-val-task Cosine Recall@10</th>\n",
       "      <th>Card-val-task Cosine Ndcg@10</th>\n",
       "      <th>Card-val-task Cosine Mrr@10</th>\n",
       "      <th>Card-val-task Cosine Map@100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.603871</td>\n",
       "      <td>0.767742</td>\n",
       "      <td>0.832258</td>\n",
       "      <td>0.913548</td>\n",
       "      <td>0.603871</td>\n",
       "      <td>0.255914</td>\n",
       "      <td>0.166452</td>\n",
       "      <td>0.091355</td>\n",
       "      <td>0.603871</td>\n",
       "      <td>0.767742</td>\n",
       "      <td>0.832258</td>\n",
       "      <td>0.913548</td>\n",
       "      <td>0.752219</td>\n",
       "      <td>0.701285</td>\n",
       "      <td>0.705925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.829677</td>\n",
       "      <td>0.896774</td>\n",
       "      <td>0.958710</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.276559</td>\n",
       "      <td>0.179355</td>\n",
       "      <td>0.095871</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.829677</td>\n",
       "      <td>0.896774</td>\n",
       "      <td>0.958710</td>\n",
       "      <td>0.815290</td>\n",
       "      <td>0.769704</td>\n",
       "      <td>0.772001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.669677</td>\n",
       "      <td>0.833548</td>\n",
       "      <td>0.899355</td>\n",
       "      <td>0.958710</td>\n",
       "      <td>0.669677</td>\n",
       "      <td>0.277849</td>\n",
       "      <td>0.179871</td>\n",
       "      <td>0.095871</td>\n",
       "      <td>0.669677</td>\n",
       "      <td>0.833548</td>\n",
       "      <td>0.899355</td>\n",
       "      <td>0.958710</td>\n",
       "      <td>0.811697</td>\n",
       "      <td>0.764829</td>\n",
       "      <td>0.767191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.668387</td>\n",
       "      <td>0.832258</td>\n",
       "      <td>0.892903</td>\n",
       "      <td>0.962581</td>\n",
       "      <td>0.668387</td>\n",
       "      <td>0.277419</td>\n",
       "      <td>0.178581</td>\n",
       "      <td>0.096258</td>\n",
       "      <td>0.668387</td>\n",
       "      <td>0.832258</td>\n",
       "      <td>0.892903</td>\n",
       "      <td>0.962581</td>\n",
       "      <td>0.813547</td>\n",
       "      <td>0.766013</td>\n",
       "      <td>0.768089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.843871</td>\n",
       "      <td>0.883871</td>\n",
       "      <td>0.958710</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.281290</td>\n",
       "      <td>0.176774</td>\n",
       "      <td>0.095871</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.843871</td>\n",
       "      <td>0.883871</td>\n",
       "      <td>0.958710</td>\n",
       "      <td>0.817749</td>\n",
       "      <td>0.772779</td>\n",
       "      <td>0.775222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.676129</td>\n",
       "      <td>0.849032</td>\n",
       "      <td>0.907097</td>\n",
       "      <td>0.961290</td>\n",
       "      <td>0.676129</td>\n",
       "      <td>0.283011</td>\n",
       "      <td>0.181419</td>\n",
       "      <td>0.096129</td>\n",
       "      <td>0.676129</td>\n",
       "      <td>0.849032</td>\n",
       "      <td>0.907097</td>\n",
       "      <td>0.961290</td>\n",
       "      <td>0.818403</td>\n",
       "      <td>0.772653</td>\n",
       "      <td>0.775015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.681290</td>\n",
       "      <td>0.850323</td>\n",
       "      <td>0.910968</td>\n",
       "      <td>0.966452</td>\n",
       "      <td>0.681290</td>\n",
       "      <td>0.283441</td>\n",
       "      <td>0.182194</td>\n",
       "      <td>0.096645</td>\n",
       "      <td>0.681290</td>\n",
       "      <td>0.850323</td>\n",
       "      <td>0.910968</td>\n",
       "      <td>0.966452</td>\n",
       "      <td>0.823616</td>\n",
       "      <td>0.777909</td>\n",
       "      <td>0.779802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.667097</td>\n",
       "      <td>0.843871</td>\n",
       "      <td>0.904516</td>\n",
       "      <td>0.966452</td>\n",
       "      <td>0.667097</td>\n",
       "      <td>0.281290</td>\n",
       "      <td>0.180903</td>\n",
       "      <td>0.096645</td>\n",
       "      <td>0.667097</td>\n",
       "      <td>0.843871</td>\n",
       "      <td>0.904516</td>\n",
       "      <td>0.966452</td>\n",
       "      <td>0.817409</td>\n",
       "      <td>0.769590</td>\n",
       "      <td>0.771451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.676129</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.899355</td>\n",
       "      <td>0.962581</td>\n",
       "      <td>0.676129</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.179871</td>\n",
       "      <td>0.096258</td>\n",
       "      <td>0.676129</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.899355</td>\n",
       "      <td>0.962581</td>\n",
       "      <td>0.817619</td>\n",
       "      <td>0.771388</td>\n",
       "      <td>0.773507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.669677</td>\n",
       "      <td>0.847742</td>\n",
       "      <td>0.899355</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.669677</td>\n",
       "      <td>0.282581</td>\n",
       "      <td>0.179871</td>\n",
       "      <td>0.096000</td>\n",
       "      <td>0.669677</td>\n",
       "      <td>0.847742</td>\n",
       "      <td>0.899355</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.817036</td>\n",
       "      <td>0.771040</td>\n",
       "      <td>0.773590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.685161</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.895484</td>\n",
       "      <td>0.950968</td>\n",
       "      <td>0.685161</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.179097</td>\n",
       "      <td>0.095097</td>\n",
       "      <td>0.685161</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.895484</td>\n",
       "      <td>0.950968</td>\n",
       "      <td>0.818279</td>\n",
       "      <td>0.775812</td>\n",
       "      <td>0.778683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.690323</td>\n",
       "      <td>0.845161</td>\n",
       "      <td>0.912258</td>\n",
       "      <td>0.970323</td>\n",
       "      <td>0.690323</td>\n",
       "      <td>0.281720</td>\n",
       "      <td>0.182452</td>\n",
       "      <td>0.097032</td>\n",
       "      <td>0.690323</td>\n",
       "      <td>0.845161</td>\n",
       "      <td>0.912258</td>\n",
       "      <td>0.970323</td>\n",
       "      <td>0.829791</td>\n",
       "      <td>0.784917</td>\n",
       "      <td>0.786583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.696774</td>\n",
       "      <td>0.849032</td>\n",
       "      <td>0.908387</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.696774</td>\n",
       "      <td>0.283011</td>\n",
       "      <td>0.181677</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.696774</td>\n",
       "      <td>0.849032</td>\n",
       "      <td>0.908387</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.831281</td>\n",
       "      <td>0.787729</td>\n",
       "      <td>0.789521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.701935</td>\n",
       "      <td>0.850323</td>\n",
       "      <td>0.913548</td>\n",
       "      <td>0.963871</td>\n",
       "      <td>0.701935</td>\n",
       "      <td>0.283441</td>\n",
       "      <td>0.182710</td>\n",
       "      <td>0.096387</td>\n",
       "      <td>0.701935</td>\n",
       "      <td>0.850323</td>\n",
       "      <td>0.913548</td>\n",
       "      <td>0.963871</td>\n",
       "      <td>0.832307</td>\n",
       "      <td>0.790119</td>\n",
       "      <td>0.792181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.700645</td>\n",
       "      <td>0.859355</td>\n",
       "      <td>0.908387</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.700645</td>\n",
       "      <td>0.286452</td>\n",
       "      <td>0.181677</td>\n",
       "      <td>0.096000</td>\n",
       "      <td>0.700645</td>\n",
       "      <td>0.859355</td>\n",
       "      <td>0.908387</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.830609</td>\n",
       "      <td>0.789134</td>\n",
       "      <td>0.791403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.708387</td>\n",
       "      <td>0.864516</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.963871</td>\n",
       "      <td>0.708387</td>\n",
       "      <td>0.288172</td>\n",
       "      <td>0.184000</td>\n",
       "      <td>0.096387</td>\n",
       "      <td>0.708387</td>\n",
       "      <td>0.864516</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.963871</td>\n",
       "      <td>0.838111</td>\n",
       "      <td>0.797484</td>\n",
       "      <td>0.799747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>245</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.701935</td>\n",
       "      <td>0.865806</td>\n",
       "      <td>0.916129</td>\n",
       "      <td>0.957419</td>\n",
       "      <td>0.701935</td>\n",
       "      <td>0.288602</td>\n",
       "      <td>0.183226</td>\n",
       "      <td>0.095742</td>\n",
       "      <td>0.701935</td>\n",
       "      <td>0.865806</td>\n",
       "      <td>0.916129</td>\n",
       "      <td>0.957419</td>\n",
       "      <td>0.832854</td>\n",
       "      <td>0.792566</td>\n",
       "      <td>0.795245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.717419</td>\n",
       "      <td>0.861935</td>\n",
       "      <td>0.907097</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.717419</td>\n",
       "      <td>0.287312</td>\n",
       "      <td>0.181419</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.717419</td>\n",
       "      <td>0.861935</td>\n",
       "      <td>0.907097</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.839469</td>\n",
       "      <td>0.798764</td>\n",
       "      <td>0.800650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.701935</td>\n",
       "      <td>0.859355</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.972903</td>\n",
       "      <td>0.701935</td>\n",
       "      <td>0.286452</td>\n",
       "      <td>0.184000</td>\n",
       "      <td>0.097290</td>\n",
       "      <td>0.701935</td>\n",
       "      <td>0.859355</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.972903</td>\n",
       "      <td>0.838182</td>\n",
       "      <td>0.794776</td>\n",
       "      <td>0.796393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>294</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.707097</td>\n",
       "      <td>0.867097</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.971613</td>\n",
       "      <td>0.707097</td>\n",
       "      <td>0.289032</td>\n",
       "      <td>0.184000</td>\n",
       "      <td>0.097161</td>\n",
       "      <td>0.707097</td>\n",
       "      <td>0.867097</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.971613</td>\n",
       "      <td>0.841360</td>\n",
       "      <td>0.799336</td>\n",
       "      <td>0.800853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.707097</td>\n",
       "      <td>0.867097</td>\n",
       "      <td>0.917419</td>\n",
       "      <td>0.966452</td>\n",
       "      <td>0.707097</td>\n",
       "      <td>0.289032</td>\n",
       "      <td>0.183484</td>\n",
       "      <td>0.096645</td>\n",
       "      <td>0.707097</td>\n",
       "      <td>0.867097</td>\n",
       "      <td>0.917419</td>\n",
       "      <td>0.966452</td>\n",
       "      <td>0.838074</td>\n",
       "      <td>0.796670</td>\n",
       "      <td>0.798422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.716129</td>\n",
       "      <td>0.864516</td>\n",
       "      <td>0.914839</td>\n",
       "      <td>0.962581</td>\n",
       "      <td>0.716129</td>\n",
       "      <td>0.288172</td>\n",
       "      <td>0.182968</td>\n",
       "      <td>0.096258</td>\n",
       "      <td>0.716129</td>\n",
       "      <td>0.864516</td>\n",
       "      <td>0.914839</td>\n",
       "      <td>0.962581</td>\n",
       "      <td>0.838357</td>\n",
       "      <td>0.798684</td>\n",
       "      <td>0.800517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.712258</td>\n",
       "      <td>0.865806</td>\n",
       "      <td>0.916129</td>\n",
       "      <td>0.966452</td>\n",
       "      <td>0.712258</td>\n",
       "      <td>0.288602</td>\n",
       "      <td>0.183226</td>\n",
       "      <td>0.096645</td>\n",
       "      <td>0.712258</td>\n",
       "      <td>0.865806</td>\n",
       "      <td>0.916129</td>\n",
       "      <td>0.966452</td>\n",
       "      <td>0.839544</td>\n",
       "      <td>0.798842</td>\n",
       "      <td>0.800732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>343</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.713548</td>\n",
       "      <td>0.861935</td>\n",
       "      <td>0.916129</td>\n",
       "      <td>0.970323</td>\n",
       "      <td>0.713548</td>\n",
       "      <td>0.287312</td>\n",
       "      <td>0.183226</td>\n",
       "      <td>0.097032</td>\n",
       "      <td>0.713548</td>\n",
       "      <td>0.861935</td>\n",
       "      <td>0.916129</td>\n",
       "      <td>0.970323</td>\n",
       "      <td>0.842013</td>\n",
       "      <td>0.800934</td>\n",
       "      <td>0.802610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.704516</td>\n",
       "      <td>0.869677</td>\n",
       "      <td>0.922581</td>\n",
       "      <td>0.965161</td>\n",
       "      <td>0.704516</td>\n",
       "      <td>0.289892</td>\n",
       "      <td>0.184516</td>\n",
       "      <td>0.096516</td>\n",
       "      <td>0.704516</td>\n",
       "      <td>0.869677</td>\n",
       "      <td>0.922581</td>\n",
       "      <td>0.965161</td>\n",
       "      <td>0.838062</td>\n",
       "      <td>0.797009</td>\n",
       "      <td>0.798959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.703226</td>\n",
       "      <td>0.860645</td>\n",
       "      <td>0.916129</td>\n",
       "      <td>0.965161</td>\n",
       "      <td>0.703226</td>\n",
       "      <td>0.286882</td>\n",
       "      <td>0.183226</td>\n",
       "      <td>0.096516</td>\n",
       "      <td>0.703226</td>\n",
       "      <td>0.860645</td>\n",
       "      <td>0.916129</td>\n",
       "      <td>0.965161</td>\n",
       "      <td>0.835630</td>\n",
       "      <td>0.793908</td>\n",
       "      <td>0.795843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>392</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.699355</td>\n",
       "      <td>0.865806</td>\n",
       "      <td>0.914839</td>\n",
       "      <td>0.965161</td>\n",
       "      <td>0.699355</td>\n",
       "      <td>0.288602</td>\n",
       "      <td>0.182968</td>\n",
       "      <td>0.096516</td>\n",
       "      <td>0.699355</td>\n",
       "      <td>0.865806</td>\n",
       "      <td>0.914839</td>\n",
       "      <td>0.965161</td>\n",
       "      <td>0.834620</td>\n",
       "      <td>0.792575</td>\n",
       "      <td>0.794671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.705806</td>\n",
       "      <td>0.865806</td>\n",
       "      <td>0.914839</td>\n",
       "      <td>0.965161</td>\n",
       "      <td>0.705806</td>\n",
       "      <td>0.288602</td>\n",
       "      <td>0.182968</td>\n",
       "      <td>0.096516</td>\n",
       "      <td>0.705806</td>\n",
       "      <td>0.865806</td>\n",
       "      <td>0.914839</td>\n",
       "      <td>0.965161</td>\n",
       "      <td>0.836892</td>\n",
       "      <td>0.795642</td>\n",
       "      <td>0.797683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.714839</td>\n",
       "      <td>0.868387</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.714839</td>\n",
       "      <td>0.289462</td>\n",
       "      <td>0.184000</td>\n",
       "      <td>0.096000</td>\n",
       "      <td>0.714839</td>\n",
       "      <td>0.868387</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.839677</td>\n",
       "      <td>0.800734</td>\n",
       "      <td>0.803017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.717419</td>\n",
       "      <td>0.863226</td>\n",
       "      <td>0.918710</td>\n",
       "      <td>0.962581</td>\n",
       "      <td>0.717419</td>\n",
       "      <td>0.287742</td>\n",
       "      <td>0.183742</td>\n",
       "      <td>0.096258</td>\n",
       "      <td>0.717419</td>\n",
       "      <td>0.863226</td>\n",
       "      <td>0.918710</td>\n",
       "      <td>0.962581</td>\n",
       "      <td>0.841337</td>\n",
       "      <td>0.802176</td>\n",
       "      <td>0.804069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>441</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.716129</td>\n",
       "      <td>0.861935</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.962581</td>\n",
       "      <td>0.716129</td>\n",
       "      <td>0.287312</td>\n",
       "      <td>0.184000</td>\n",
       "      <td>0.096258</td>\n",
       "      <td>0.716129</td>\n",
       "      <td>0.861935</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.962581</td>\n",
       "      <td>0.840754</td>\n",
       "      <td>0.801402</td>\n",
       "      <td>0.803311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.712258</td>\n",
       "      <td>0.863226</td>\n",
       "      <td>0.918710</td>\n",
       "      <td>0.963871</td>\n",
       "      <td>0.712258</td>\n",
       "      <td>0.287742</td>\n",
       "      <td>0.183742</td>\n",
       "      <td>0.096387</td>\n",
       "      <td>0.712258</td>\n",
       "      <td>0.863226</td>\n",
       "      <td>0.918710</td>\n",
       "      <td>0.963871</td>\n",
       "      <td>0.839723</td>\n",
       "      <td>0.799639</td>\n",
       "      <td>0.801446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.716129</td>\n",
       "      <td>0.867097</td>\n",
       "      <td>0.921290</td>\n",
       "      <td>0.966452</td>\n",
       "      <td>0.716129</td>\n",
       "      <td>0.289032</td>\n",
       "      <td>0.184258</td>\n",
       "      <td>0.096645</td>\n",
       "      <td>0.716129</td>\n",
       "      <td>0.867097</td>\n",
       "      <td>0.921290</td>\n",
       "      <td>0.966452</td>\n",
       "      <td>0.842792</td>\n",
       "      <td>0.802967</td>\n",
       "      <td>0.804561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.716129</td>\n",
       "      <td>0.867097</td>\n",
       "      <td>0.921290</td>\n",
       "      <td>0.966452</td>\n",
       "      <td>0.716129</td>\n",
       "      <td>0.289032</td>\n",
       "      <td>0.184258</td>\n",
       "      <td>0.096645</td>\n",
       "      <td>0.716129</td>\n",
       "      <td>0.867097</td>\n",
       "      <td>0.921290</td>\n",
       "      <td>0.966452</td>\n",
       "      <td>0.842961</td>\n",
       "      <td>0.803182</td>\n",
       "      <td>0.804776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š [REPORT] Step: 20 | Epoch: 0.40816326530612246 | Accuracy@1: 0.7522\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 40 | Epoch: 0.8163265306122449 | Accuracy@1: 0.8153\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 49 | Epoch: 1.0 | Accuracy@1: 0.8117\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 60 | Epoch: 1.2244897959183674 | Accuracy@1: 0.8135\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 80 | Epoch: 1.6326530612244898 | Accuracy@1: 0.8177\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 98 | Epoch: 2.0 | Accuracy@1: 0.8184\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 100 | Epoch: 2.0408163265306123 | Accuracy@1: 0.8236\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 120 | Epoch: 2.4489795918367347 | Accuracy@1: 0.8174\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 140 | Epoch: 2.857142857142857 | Accuracy@1: 0.8176\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 147 | Epoch: 3.0 | Accuracy@1: 0.8170\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 160 | Epoch: 3.2653061224489797 | Accuracy@1: 0.8183\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 180 | Epoch: 3.673469387755102 | Accuracy@1: 0.8298\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 196 | Epoch: 4.0 | Accuracy@1: 0.8313\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 200 | Epoch: 4.081632653061225 | Accuracy@1: 0.8323\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 220 | Epoch: 4.489795918367347 | Accuracy@1: 0.8306\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 240 | Epoch: 4.8979591836734695 | Accuracy@1: 0.8381\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 245 | Epoch: 5.0 | Accuracy@1: 0.8329\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 260 | Epoch: 5.3061224489795915 | Accuracy@1: 0.8395\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 280 | Epoch: 5.714285714285714 | Accuracy@1: 0.8382\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 294 | Epoch: 6.0 | Accuracy@1: 0.8414\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 300 | Epoch: 6.122448979591836 | Accuracy@1: 0.8381\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 320 | Epoch: 6.530612244897959 | Accuracy@1: 0.8384\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 340 | Epoch: 6.938775510204081 | Accuracy@1: 0.8395\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 343 | Epoch: 7.0 | Accuracy@1: 0.8420\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 360 | Epoch: 7.346938775510204 | Accuracy@1: 0.8381\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 380 | Epoch: 7.755102040816326 | Accuracy@1: 0.8356\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 392 | Epoch: 8.0 | Accuracy@1: 0.8346\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 400 | Epoch: 8.16326530612245 | Accuracy@1: 0.8369\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 420 | Epoch: 8.571428571428571 | Accuracy@1: 0.8397\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 440 | Epoch: 8.979591836734693 | Accuracy@1: 0.8413\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 441 | Epoch: 9.0 | Accuracy@1: 0.8408\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 460 | Epoch: 9.387755102040817 | Accuracy@1: 0.8397\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 480 | Epoch: 9.795918367346939 | Accuracy@1: 0.8428\n",
      "\n",
      "ğŸ“Š [REPORT] Step: 490 | Epoch: 10.0 | Accuracy@1: 0.8430\n",
      "âœ¨ ëª¨ë“  ê³¼ì • ì™„ë£Œ! ìµœì ì˜ ëª¨ë¸ì€ ./models/gemma-300m-4080super-extremeì— ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import os\n",
    "import gc\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses, evaluation\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "# 1. GPU ë©”ëª¨ë¦¬ ì´ˆê¸°í™” (ì´ì „ ì‘ì—… ì°Œêº¼ê¸° ì œê±°)\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 2. ëª¨ë¸ ë¡œë“œ ë° ê·¸ë˜ë””ì–¸íŠ¸ ì²´í¬í¬ì¸íŒ… í™œì„±í™”\n",
    "# ì´ ê¸°ëŠ¥ì€ ì—°ì‚° ì†ë„ë¥¼ ì•½ê°„ í¬ìƒí•˜ëŠ” ëŒ€ì‹  VRAM ì‚¬ìš©ëŸ‰ì„ ëŒ€í­ ì¤„ì—¬ì¤ë‹ˆë‹¤.\n",
    "MODEL_ID = \"google/embeddinggemma-300m\"\n",
    "OUTPUT_PATH = \"./models/gemma-300m-4080super-extreme\"\n",
    "model = SentenceTransformer(MODEL_ID)\n",
    "model[0].auto_model.gradient_checkpointing_enable()\n",
    "\n",
    "# 3. Gemma ê³µì‹ ì§€ì‹œì–´ í¬ë§· í•¨ìˆ˜\n",
    "def format_query(text):\n",
    "    return f\"task: search result | query: {text}\"\n",
    "\n",
    "def format_doc(content, title=\"none\"):\n",
    "    return f\"title: {title} | text: {content}\"\n",
    "\n",
    "def load_json_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# ë°ì´í„° ë¡œë“œ\n",
    "train_data = load_json_data('./data/train_dataset.json')\n",
    "val_data = load_json_data('./data/val_dataset.json')\n",
    "\n",
    "# 4. í•™ìŠµ ë°ì´í„°ì…‹ êµ¬ì„± (Prefix ì ìš©)\n",
    "train_examples = []\n",
    "for item in train_data:\n",
    "    card_title = item.get('metadata', {}).get('card_name', 'ì¹´ë“œí˜œíƒ')\n",
    "    train_examples.append(InputExample(texts=[\n",
    "        format_query(item['anchor']), \n",
    "        format_doc(item['positive'], title=card_title),\n",
    "        format_doc(item['negative'], title=card_title)\n",
    "    ]))\n",
    "\n",
    "# 5. 4080 Super ìµìŠ¤íŠ¸ë¦¼ ë°°ì¹˜ ì„¤ì •\n",
    "# AMP + Gradient Checkpointing ì¡°í•©ìœ¼ë¡œ 256 ë„ì „ì— ë‚˜ì„­ë‹ˆë‹¤.\n",
    "BATCH_SIZE = 128 \n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=BATCH_SIZE)\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model)\n",
    "\n",
    "# 6. ê²€ì¦ê¸° ì„¤ì •\n",
    "val_queries = {str(i): format_query(item['anchor']) for i, item in enumerate(val_data)}\n",
    "val_corpus = {str(i): format_doc(item['positive']) for i, item in enumerate(val_data)}\n",
    "val_relevant_docs = {str(i): {str(i)} for i, item in enumerate(val_data)}\n",
    "\n",
    "evaluator = evaluation.InformationRetrievalEvaluator(\n",
    "    val_queries, val_corpus, val_relevant_docs, name=\"card-val-task\"\n",
    ")\n",
    "\n",
    "# 7. ì§„í–‰ ìƒí™© ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì½œë°±\n",
    "def training_callback(score, epoch, steps):\n",
    "    print(f\"\\nğŸ“Š [REPORT] Step: {steps} | Epoch: {epoch} | Accuracy@1: {score:.4f}\")\n",
    "\n",
    "# 8. ìµœì í™” í•™ìŠµ ì‹¤í–‰\n",
    "print(f\"ğŸ”¥ [Extreme Mode] RTX 4080 Super ê°€ë™! (Batch: {BATCH_SIZE})\")\n",
    "print(f\"ğŸ› ï¸ í™œì„±í™” ê¸°ìˆ : AMP(í˜¼í•©ì •ë°€ë„) + Gradient Checkpointing\")\n",
    "\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    evaluator=evaluator,\n",
    "    epochs=10,\n",
    "    warmup_steps=100,\n",
    "    optimizer_params={'lr': 2e-5},\n",
    "    output_path=OUTPUT_PATH,\n",
    "    evaluation_steps=20,     # ë°°ì¹˜ê°€ í¬ë¯€ë¡œ 20ìŠ¤í…ë§ˆë‹¤ ì ìˆ˜ í™•ì¸ (ì§„í–‰ ìƒí™© ì²´í¬)\n",
    "    save_best_model=True,\n",
    "    show_progress_bar=True,\n",
    "    use_amp=True,            # í˜¼í•© ì •ë°€ë„ í™œì„±í™”\n",
    "    callback=training_callback # ì‹¤ì‹œê°„ ì ìˆ˜ ì¶œë ¥\n",
    ")\n",
    "\n",
    "print(f\"âœ¨ ëª¨ë“  ê³¼ì • ì™„ë£Œ! ìµœì ì˜ ëª¨ë¸ì€ {OUTPUT_PATH}ì— ìˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d9cf2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer you are loading from './models/gemma-300m-4080super-extreme' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì´ìš©í•œ ì‹¬ì¸µ ì„±ëŠ¥ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...\n",
      "\n",
      "========================= [Gemma-300M ìµœì¢… ê²€ìƒ‰ ì„±ì í‘œ] =========================\n",
      "âœ… Accuracy@1 (Hit Rate)          : 0.7384\n",
      "âœ… Accuracy@10 (Hit Rate)         : 0.9613\n",
      "âœ… MRR@10                         : 0.8191\n",
      "âœ… NDCG@10                        : 0.8540\n",
      "âœ… Precision@10                   : 0.0961\n",
      "âœ… Recall@10                      : 0.9613\n",
      "==============================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer, evaluation\n",
    "\n",
    "# 1. ëª¨ë¸ ë¡œë“œ\n",
    "FINAL_MODEL_PATH = \"./models/gemma-300m-4080super-extreme\"\n",
    "final_model = SentenceTransformer(FINAL_MODEL_PATH)\n",
    "\n",
    "# 2. ë°ì´í„° ë¡œë“œ\n",
    "def load_json_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "test_data = load_json_data('./data/test_dataset.json')\n",
    "\n",
    "# 3. Evaluator ì„¤ì •\n",
    "test_queries = {str(i): item['anchor'] for i, item in enumerate(test_data)}\n",
    "test_corpus = {str(i): item['positive'] for i, item in enumerate(test_data)}\n",
    "test_relevant_docs = {str(i): {str(i)} for i, item in enumerate(test_data)}\n",
    "\n",
    "# í‰ê°€ ì´ë¦„(name)ì„ ê¸°ì¤€ìœ¼ë¡œ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ì˜ í‚¤ ê°’ì´ ìƒì„±ë©ë‹ˆë‹¤.\n",
    "TASK_NAME = \"card-test-task\"\n",
    "test_evaluator = evaluation.InformationRetrievalEvaluator(\n",
    "    test_queries, test_corpus, test_relevant_docs, name=TASK_NAME\n",
    ")\n",
    "\n",
    "# 4. ìµœì¢… í‰ê°€ ì‹¤í–‰\n",
    "print(\"ğŸ” í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì´ìš©í•œ ì‹¬ì¸µ ì„±ëŠ¥ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "results = test_evaluator(final_model)\n",
    "\n",
    "# 5. [ìˆ˜ì •] ëª¨ë“  ìƒì„¸ ì§€í‘œ ì¶œë ¥ ë¡œì§\n",
    "def print_detailed_report(res, name):\n",
    "    # ìš°ë¦¬ê°€ ë³´ê³  ì‹¶ì€ ì§€í‘œ ë¦¬ìŠ¤íŠ¸ (ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ì¤€)\n",
    "    metrics = [\n",
    "        (\"Accuracy@1 (Hit Rate)\", f\"{name}_cosine_accuracy@1\"),\n",
    "        (\"Accuracy@10 (Hit Rate)\", f\"{name}_cosine_accuracy@10\"),\n",
    "        (\"MRR@10\", f\"{name}_cosine_mrr@10\"),\n",
    "        (\"NDCG@10\", f\"{name}_cosine_ndcg@10\"),\n",
    "        (\"Precision@10\", f\"{name}_cosine_precision@10\"),\n",
    "        (\"Recall@10\", f\"{name}_cosine_recall@10\"),\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\n{'='*25} [Gemma-300M ìµœì¢… ê²€ìƒ‰ ì„±ì í‘œ] {'='*25}\")\n",
    "    for label, key in metrics:\n",
    "        val = res.get(key, 0)\n",
    "        print(f\"âœ… {label:<30} : {val:.4f}\")\n",
    "    print(f\"{'='*78}\\n\")\n",
    "\n",
    "print_detailed_report(results, TASK_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c11aaf6",
   "metadata": {},
   "source": [
    "# 3. ëª¨ë¸ ì •ì˜ ë° ì†ì‹¤í•¨ìˆ˜ ì„¤ì •\n",
    "\n",
    "- Googleì˜ ìµœì‹  embeddinggemma-300m ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "- ì§ˆë¬¸(Anchor)ê³¼ ì •ë‹µ(Positive)ì€ ê°€ê¹ê²Œ, ì˜¤ë‹µ(Negative)ì€ ë©€ê²Œ ë§Œë“œëŠ” Triplet Lossë¥¼ ì‚¬ìš©í•˜ë©°, ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ì¤€ ë§ˆì§„ì„ 0.5ë¡œ ì„¤ì •í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce652e1e",
   "metadata": {},
   "source": [
    "# 4. ëª¨ë¸ íŒŒì¸íŠœë‹ (Fine-tuning) ì‹¤í–‰\n",
    "\n",
    "- ë³¸ê²©ì ì¸ í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤. í•™ìŠµ ì†ë„ í–¥ìƒì„ ìœ„í•´ use_amp=Trueë¥¼ ì‚¬ìš©í•˜ë©°, 5 ì—í¬í¬ ë™ì•ˆ ê²€ì¦ ì ìˆ˜ê°€ ê°€ì¥ ë†’ì€ ëª¨ë¸ì„ ìë™ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e1903c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "754ba8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ ëª¨ë¸ì„ ë¡œë“œ ì¤‘ì…ë‹ˆë‹¤... (Device: cuda)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer you are loading from './models/gemma-300m-4080super-extreme' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n",
      "C:\\Users\\Jeon\\AppData\\Local\\Temp\\ipykernel_21324\\2110197300.py:39: DeprecationWarning: The class GemmaEmbeddingFunction does not implement __init__. This will be required in a future version.\n",
      "  embedding_fn = GemmaEmbeddingFunction()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ ê¸°ì¡´ ChromaDBë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤. (ì €ì¥ëœ ë°ì´í„°: 7757ê±´)\n",
      "\n",
      "ğŸ” ë¶„ì„ëœ ì˜ë„: ['ë°°ë‹¬ì˜ë¯¼ì¡± ìš”ê¸°ìš” ì¿ íŒ¡ì´ì¸  ë°°ë‹¬ ìŒì‹ í• ì¸ í˜œíƒ', 'ë²„ìŠ¤ ì§€í•˜ì²  íƒì‹œ ëŒ€ì¤‘êµí†µ êµí†µë¹„ í• ì¸ í˜œíƒ']\n",
      "âœ… êµì§‘í•© í•„í„°ë§ ê²°ê³¼: 6ê±´ ë°œê²¬\n",
      "=====================================================================================\n",
      "1. [ë¡¯ë°ì¹´ë“œ] LOCA for Coffee (ì¢…í•© ì ìˆ˜: 0.8735)\n",
      "     - ë°°ë‹¬ì˜ë¯¼ì¡±ê³¼ ìš”ê¸°ìš”ì—ì„œ 10% í• ì¸ í˜œíƒì„ ì œê³µí•©ë‹ˆë‹¤.\n",
      "     - ë²„ìŠ¤, ì§€í•˜ì² , íƒì‹œ ì´ìš© ì‹œ 10% í• ì¸ í˜œíƒ ì œê³µ.\n",
      "-------------------------------------------------------------------------------------\n",
      "2. [í•˜ë‚˜ì¹´ë“œ] ì›ë”ì¹´ë“œ 2.0 DAILY (ì¢…í•© ì ìˆ˜: 0.8692)\n",
      "     - ëŒ€ì¤‘êµí†µ ì´ìš© ì‹œ 10% í• ì¸ í˜œíƒ ì œê³µ\n",
      "     - ë”œë¦¬ë²„ë¦¬ ì„œë¹„ìŠ¤ì—ì„œ 10% í• ì¸ì„ ì œê³µí•˜ëŠ” ì¹´ë“œ í˜œíƒì…ë‹ˆë‹¤.\n",
      "-------------------------------------------------------------------------------------\n",
      "3. [ìš°ë¦¬ì¹´ë“œ] NU Uniq (ì¢…í•© ì ìˆ˜: 0.8655)\n",
      "     - ëŒ€ì¤‘êµí†µ, íƒì‹œ, ì „ê¸°ì°¨, ì£¼ìœ ì—ì„œ 1.5% í• ì¸ í˜œíƒ ì œê³µ\n",
      "     - ë°°ë‹¬ì˜ë¯¼ì¡±, Bë§ˆíŠ¸, ì¿ íŒ¡ì´ì¸ ì—ì„œ 1.5% í• ì¸ í˜œíƒ ì œê³µ\n",
      "-------------------------------------------------------------------------------------\n",
      "4. [ì‚¼ì„±ì¹´ë“œ] CUÂ·ë°°ë‹¬ì˜ë¯¼ì¡± ì‚¼ì„±ì¹´ë“œ taptap (ì¢…í•© ì ìˆ˜: 0.8454)\n",
      "     - CUì—ì„œ 1,500ì›ë‹¹ 200ì› ê²°ì œì¼ í• ì¸ í˜œíƒ ì œê³µ.\n",
      "     - ëŒ€ì¤‘êµí†µ ì´ìš© ì‹œ 1,000ì›ë‹¹ 100ì› ê²°ì œì¼ í• ì¸ í˜œíƒ ì œê³µ.\n",
      "-------------------------------------------------------------------------------------\n",
      "5. [KBêµ­ë¯¼ì¹´ë“œ] í† ìŠ¤ USS NEXT ì²´í¬ì¹´ë“œ (ì¢…í•© ì ìˆ˜: 0.8416)\n",
      "     - ëŒ€ì¤‘êµí†µ ì´ìš© ì‹œ 1,000ì› í• ì¸ í˜œíƒ ì œê³µ\n",
      "     - ë°°ë‹¬ìŒì‹ 500ì› í• ì¸ í˜œíƒ ì œê³µ\n",
      "-------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# ==========================================\n",
    "# 1. í™˜ê²½ ì„¤ì • ë° ëª¨ë¸ ë¡œë“œ\n",
    "# ==========================================\n",
    "# ë°ì´í„° ê²½ë¡œ ë° ëª¨ë¸ ê²½ë¡œ ì„¤ì •\n",
    "INPUT_FILE = './data/FINAL_MASTER_DATA_FIXED_7757.json'      # 7,757ê±´ì˜ ì¹´ë“œ ì›ë³¸ ë°ì´í„°\n",
    "MODEL_PATH = './models/gemma-300m-4080super-extreme'          # ì—¬ìš±ë‹˜ì´ í•™ìŠµì‹œí‚¨ Gemma ì„ë² ë”© ëª¨ë¸\n",
    "CHROMA_DB_PATH = './data/chroma_db'                         # ë²¡í„° ë°ì´í„°ê°€ ì €ì¥ë  í´ë” ê²½ë¡œ\n",
    "\n",
    "# GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸ (ì†ë„ í–¥ìƒì„ ìœ„í•´ GPU ê¶Œì¥)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"ğŸ“¦ ëª¨ë¸ì„ ë¡œë“œ ì¤‘ì…ë‹ˆë‹¤... (Device: {device})\")\n",
    "\n",
    "# SentenceTransformerë¥¼ í†µí•´ Gemma ëª¨ë¸ì„ ë©”ëª¨ë¦¬ì— ì˜¬ë¦½ë‹ˆë‹¤.\n",
    "model = SentenceTransformer(MODEL_PATH, device=device)\n",
    "\n",
    "# ==========================================\n",
    "# 2. ChromaDB ì»¤ìŠ¤í…€ ì„ë² ë”© í•¨ìˆ˜ ì •ì˜\n",
    "# ==========================================\n",
    "# ChromaDBê°€ ìŠ¤ìŠ¤ë¡œ ì„ë² ë”©ì„ í•˜ì§€ ì•Šê³ , ìš°ë¦¬ê°€ ë§Œë“  Gemma ëª¨ë¸ì„ ì‚¬ìš©í•˜ë„ë¡ ë‹¤ë¦¬ë¥¼ ë†“ì•„ì£¼ëŠ” í´ë˜ìŠ¤ì…ë‹ˆë‹¤.\n",
    "class GemmaEmbeddingFunction(embedding_functions.EmbeddingFunction):\n",
    "    def __call__(self, input_texts):\n",
    "        # [ì¤‘ìš”] ì¸ë±ì‹±(ì €ì¥)í•  ë•ŒëŠ” ëª¨ë¸ í•™ìŠµ ì‹œ ì‚¬ìš©í•œ 'title: none | text: ' í˜•ì‹ì„ ì§€ì¼œì•¼ ê²€ìƒ‰ ì„±ëŠ¥ì´ ë‚˜ì˜µë‹ˆë‹¤.\n",
    "        passages = [f\"title: none | text: {text}\" for text in input_texts]\n",
    "        embeddings = model.encode(passages, convert_to_tensor=False)\n",
    "        return embeddings.tolist()  # DB ì €ì¥ì„ ìœ„í•´ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë°˜í™˜\n",
    "\n",
    "# ==========================================\n",
    "# 3. ChromaDB ì´ˆê¸°í™” ë° ë°ì´í„° ì¸ë±ì‹±\n",
    "# ==========================================\n",
    "# ë°ì´í„°ë¥¼ í•˜ë“œë””ìŠ¤í¬ì— ì˜êµ¬ ì €ì¥í•˜ëŠ” í´ë¼ì´ì–¸íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "client = chromadb.PersistentClient(path=CHROMA_DB_PATH)\n",
    "embedding_fn = GemmaEmbeddingFunction()\n",
    "\n",
    "# 'card_benefits'ë¼ëŠ” ì´ë¦„ì˜ ë°ì´í„° ì €ì¥ ê³µê°„(ì»¬ë ‰ì…˜)ì„ ë§Œë“­ë‹ˆë‹¤.\n",
    "# metadata={\"hnsw:space\": \"cosine\"}ëŠ” ë²¡í„° ê°„ì˜ ê±°ë¦¬ë¥¼ 'ì½”ì‚¬ì¸ ìœ ì‚¬ë„'ë¡œ ê³„ì‚°í•˜ê² ë‹¤ëŠ” ì„¤ì •ì…ë‹ˆë‹¤.\n",
    "collection = client.get_or_create_collection(\n",
    "    name=\"card_benefits\",\n",
    "    embedding_function=embedding_fn,\n",
    "    metadata={\"hnsw:space\": \"cosine\"} \n",
    ")\n",
    "\n",
    "# DBì— ë°ì´í„°ê°€ í•˜ë‚˜ë„ ì—†ë‹¤ë©´ ìµœì´ˆ 1íšŒ ì¸ë±ì‹±ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "if collection.count() == 0:\n",
    "    print(\"ğŸš€ ChromaDBì— ìµœì´ˆ ë°ì´í„° ì¸ë±ì‹±ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "    with open(INPUT_FILE, 'r', encoding='utf-8') as f:\n",
    "        master_data = json.load(f)\n",
    "    \n",
    "    # 7,757ê±´ì˜ ë°ì´í„°ë¥¼ DB í˜•ì‹ì— ë§ê²Œ ë¶„ë¦¬í•©ë‹ˆë‹¤.\n",
    "    documents = [item['embedding_input'] for item in master_data]   # ê²€ìƒ‰ ëŒ€ìƒ í…ìŠ¤íŠ¸\n",
    "    metadatas = [item['metadata'] for item in master_data]          # ì¹´ë“œ ì´ë¦„, íšŒì‚¬ ë“± ë¶€ê°€ ì •ë³´\n",
    "    \n",
    "    # ë‚˜ì¤‘ì— ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ë°”ë¡œ ìš”ì•½ì„ ë³´ì—¬ì£¼ê¸° ìœ„í•´ ë©”íƒ€ë°ì´í„°ì— ë¯¸ë¦¬ ë„£ì–´ë‘¡ë‹ˆë‹¤.\n",
    "    for i, m in enumerate(metadatas):\n",
    "        m['summary'] = master_data[i]['ai_structured']['summary']\n",
    "    \n",
    "    # ê° ë°ì´í„°ì˜ ê³ ìœ  ID ìƒì„± (card_0, card_1...)\n",
    "    ids = [f\"card_{i}\" for i in range(len(master_data))]\n",
    "\n",
    "    # [ì¤‘ìš”] í•œêº¼ë²ˆì— ë„£ìœ¼ë©´ ë©”ëª¨ë¦¬ê°€ í„°ì§ˆ ìˆ˜ ìˆìœ¼ë¯€ë¡œ 500ê°œì”© ë‚˜ëˆ ì„œ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "    batch_size = 500\n",
    "    for i in range(0, len(documents), batch_size):\n",
    "        collection.add(\n",
    "            documents=documents[i:i+batch_size],\n",
    "            metadatas=metadatas[i:i+batch_size],\n",
    "            ids=ids[i:i+batch_size]\n",
    "        )\n",
    "    print(f\"âœ… ì´ {collection.count()}ê±´ì˜ ë°ì´í„° ì €ì¥ ì™„ë£Œ!\")\n",
    "else:\n",
    "    print(f\"ğŸ”„ ê¸°ì¡´ ChromaDBë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤. (ì €ì¥ëœ ë°ì´í„°: {collection.count()}ê±´)\")\n",
    "\n",
    "# ==========================================\n",
    "# 4. í•µì‹¬ í•¨ìˆ˜: ë‹¤ì¤‘ ì˜ë„ êµì°¨ ê²€ìƒ‰ (AND ë¡œì§)\n",
    "# ==========================================\n",
    "def find_combined_card_chroma(query_list, top_k=5, search_depth=100):\n",
    "    \"\"\"\n",
    "    query_list: ['ì˜ë„1', 'ì˜ë„2'] ê²€ìƒ‰ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸\n",
    "    top_k: ìµœì¢…ì ìœ¼ë¡œ ëª‡ ê°œë¥¼ ë³´ì—¬ì¤„ ê²ƒì¸ê°€\n",
    "    search_depth: ê° ì˜ë„ë³„ë¡œ ìƒìœ„ ëª‡ ê°œê¹Œì§€ í›‘ì–´ë³¼ ê²ƒì¸ê°€ (ê¹Šì„ìˆ˜ë¡ ì •í™•í•¨)\n",
    "    \"\"\"\n",
    "    intent_hits = []\n",
    "\n",
    "    # --- 1ë‹¨ê³„: ê° ì˜ë„ë³„ ê°œë³„ ê²€ìƒ‰ ---\n",
    "    for sub_query in query_list:\n",
    "        # ì§ˆë¬¸ìš© ê³µì‹ í”„ë¡¬í”„íŠ¸ ì ìš© (í•™ìŠµ ì‹œ instructionê³¼ ì¼ì¹˜ì‹œì¼œì•¼ í•¨)\n",
    "        query_text = f\"task: search result | query: {sub_query}\"\n",
    "        \n",
    "        # DBì—ì„œ ìœ ì‚¬í•œ ì¹´ë“œ search_depthë§Œí¼ ì¶”ì¶œ\n",
    "        results = collection.query(\n",
    "            query_texts=[query_text],\n",
    "            n_results=search_depth,\n",
    "            include=['metadatas', 'distances']\n",
    "        )\n",
    "        \n",
    "        current_hits = {}\n",
    "        for i in range(len(results['ids'][0])):\n",
    "            meta = results['metadatas'][0][i]\n",
    "            name = meta['card_name']\n",
    "            \n",
    "            # [ìœ ì‚¬ë„ ê³„ì‚°] ê±°ë¦¬ê°€ 0ì´ë©´ ì ìˆ˜ëŠ” 1ì (ë§Œì ), ê±°ë¦¬ê°€ 1ì´ë©´ ì ìˆ˜ëŠ” 0ì \n",
    "            score = 1 - results['distances'][0][i]\n",
    "            \n",
    "            # ê°™ì€ ì¹´ë“œê°€ ì¤‘ë³µ ê²€ìƒ‰ë  ê²½ìš° ê°€ì¥ ì ìˆ˜ê°€ ë†’ì€ ê²ƒë§Œ ê¸°ë¡\n",
    "            if name not in current_hits:\n",
    "                current_hits[name] = {\n",
    "                    \"score\": score,\n",
    "                    \"benefit\": meta.get('summary', 'í˜œíƒ ì •ë³´ ì—†ìŒ'),\n",
    "                    \"corp\": meta['corp']\n",
    "                }\n",
    "        intent_hits.append(current_hits)\n",
    "\n",
    "    # --- 2ë‹¨ê³„: êµì§‘í•©(Intersection) ì°¾ê¸° ---\n",
    "    # ëª¨ë“  ì˜ë„ ë¦¬ìŠ¤íŠ¸ì— ì´ë¦„ì´ ê³µí†µì ìœ¼ë¡œ ì¡´ì¬í•˜ëŠ” ì¹´ë“œë§Œ ê³¨ë¼ëƒ…ë‹ˆë‹¤.\n",
    "    common_names = set(intent_hits[0].keys()) # ì²« ë²ˆì§¸ ì˜ë„ ê²°ê³¼ë“¤\n",
    "    for hits in intent_hits[1:]:\n",
    "        common_names &= set(hits.keys())      # ì´í›„ ì˜ë„ë“¤ê³¼ ê³„ì† ê²¹ì¹˜ëŠ” ê²ƒë§Œ ë‚¨ê¹€\n",
    "\n",
    "    # --- 3ë‹¨ê³„: ê²°ê³¼ ë³‘í•© ë° ì ìˆ˜ í•©ì‚° ---\n",
    "    final_recommendations = []\n",
    "    for name in common_names:\n",
    "        # ê° ì˜ë„ì—ì„œ ë°›ì€ ìœ ì‚¬ë„ ì ìˆ˜ë¥¼ ëª¨ë‘ ë”í•©ë‹ˆë‹¤ (ì¢…í•© ì ìˆ˜)\n",
    "        total_score = sum(hits[name]['score'] for hits in intent_hits)\n",
    "        # ê° ì˜ë„ ê²€ìƒ‰ ì‹œ ë°œê²¬ëœ í˜œíƒ ìš”ì•½ë“¤ì„ ì¤‘ë³µ ì—†ì´ ìˆ˜ì§‘í•©ë‹ˆë‹¤.\n",
    "        all_benefits = list(set([hits[name]['benefit'] for hits in intent_hits]))\n",
    "        corp = intent_hits[0][name]['corp']\n",
    "        \n",
    "        final_recommendations.append({\n",
    "            \"name\": name,\n",
    "            \"corp\": corp,\n",
    "            \"score\": total_score,\n",
    "            \"benefits\": all_benefits\n",
    "        })\n",
    "\n",
    "    # --- 4ë‹¨ê³„: ìµœì¢… ì •ë ¬ ë° ì¶œë ¥ ---\n",
    "    # ì¢…í•© ì ìˆ˜(score)ê°€ ë†’ì€ ìˆœì„œëŒ€ë¡œ ìƒìœ„ top_kê°œ ì„ ì •\n",
    "    final_recommendations = sorted(final_recommendations, key=lambda x: x['score'], reverse=True)[:top_k]\n",
    "\n",
    "    print(f\"\\nğŸ” ë¶„ì„ëœ ì˜ë„: {query_list}\")\n",
    "    print(f\"âœ… êµì§‘í•© í•„í„°ë§ ê²°ê³¼: {len(common_names)}ê±´ ë°œê²¬\")\n",
    "    print(\"=\"*85)\n",
    "    \n",
    "    for i, res in enumerate(final_recommendations):\n",
    "        # ìµœì¢… ê²°ê³¼ ì¶œë ¥\n",
    "        print(f\"{i+1}. [{res['corp']}] {res['name']} (ì¢…í•© ì ìˆ˜: {res['score']:.4f})\")\n",
    "        for b in res['benefits']:\n",
    "            print(f\"     - {b}\")\n",
    "        print(\"-\" * 85)\n",
    "\n",
    "# ==========================================\n",
    "# 5. ì‹¤í–‰ í…ŒìŠ¤íŠ¸\n",
    "# ==========================================\n",
    "# ì‚¬ìš©ìì˜ ë³µí•©ì ì¸ ì§ˆë¬¸ì„ ë‘ ê°œì˜ í•µì‹¬ ì˜ë„ë¡œ ë‚˜ëˆ„ì–´ ì…ë ¥í•©ë‹ˆë‹¤.\n",
    "intents = [\n",
    "    \"ë°°ë‹¬ì˜ë¯¼ì¡± ìš”ê¸°ìš” ì¿ íŒ¡ì´ì¸  ë°°ë‹¬ ìŒì‹ í• ì¸ í˜œíƒ\", \n",
    "    \"ë²„ìŠ¤ ì§€í•˜ì²  íƒì‹œ ëŒ€ì¤‘êµí†µ êµí†µë¹„ í• ì¸ í˜œíƒ\"\n",
    "]\n",
    "\n",
    "# í•¨ìˆ˜ í˜¸ì¶œ\n",
    "find_combined_card_chroma(intents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39982aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -qU cohere langchain_cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652d7a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer you are loading from './models/gemma-300m-4080super-extreme' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n",
      "C:\\Users\\Jeon\\AppData\\Local\\Temp\\ipykernel_21324\\2386220240.py:53: DeprecationWarning: The class GemmaEmbeddingFunction does not implement __init__. This will be required in a future version.\n",
      "  embedding_function=GemmaEmbeddingFunction()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ì§ˆë¬¸ ë¶„ì„ ë° ì˜ë„ ì¶”ì¶œ ì¤‘...\n",
      "ğŸ¯ ì¶”ì¶œëœ í‚¤ì›Œë“œ: ['ë°°ë‹¬', 'êµí†µë¹„']\n",
      "ğŸ¯ Cohere v3.5 ë¦¬ë­í‚¹ ì¤‘... (í›„ë³´: 16ê°œ)\n",
      "\n",
      "âœ¨ [ê¸ˆìœµ ë¹„ì„œ Gemma-Bot ë‹µë³€]:\n",
      "\n",
      "ì•ˆë…•í•˜ì„¸ìš”! ì‚¬íšŒì´ˆë…„ìƒìœ¼ë¡œ ë°°ë‹¬ ìŒì‹ ìì£¼ ì‹œí‚¤ì‹œê³  êµí†µë¹„ í˜œíƒê¹Œì§€ ìƒê°í•˜ì‹ ë‹¤ë‹ˆ, Gemma-Botì´ í˜„ëª…í•˜ê²Œ ë„ì™€ë“œë¦´ê²Œìš”.\n",
      "\n",
      "ìƒìœ„ 3ê°œ ì¹´ë“œ ì¶”ì²œ\n",
      "1) ë‰´íƒ€ì„ì¹´ë“œ (SCì œì¼ì€í–‰)\n",
      "2) í† ìŠ¤ USS NEXT ì²´í¬ì¹´ë“œ (KBêµ­ë¯¼ì¹´ë“œ)\n",
      "3) ë¼ì´ì–¸ ì¹˜ì¦ˆ ì²´í¬ì¹´ë“œ (NHë†í˜‘ì¹´ë“œ)\n",
      "\n",
      "Top 1 ì§‘ì¤‘ ë¶„ì„: ë‰´íƒ€ì„ì¹´ë“œê°€ ì™œ ë‹¹ì‹ ì—ê²Œ ì˜ ë§ë‚˜\n",
      "- ë°°ë‹¬ì•± í˜œíƒ: ë°°ë‹¬ì˜ë¯¼ì¡±, ìš”ê¸°ìš”, ë°°ë‹¬í†µì—ì„œ 5% í• ì¸. ê±´ë‹¹ ìµœì†Œ 5,000ì› ì´ìƒ ê²°ì œ ì‹œ, 22:00~00:00ì— í•´ë‹¹ ê¸ˆì•¡ì— ì ìš©ë˜ë©° 1ì¼ 1íšŒ í• ì¸. ë‹¨, ì›”ê°„ í• ì¸ í•œë„ëŠ” ì „ì›” ì‹¤ì ì— ë”°ë¼ ë‹¬ë¼ì§‘ë‹ˆë‹¤.\n",
      "- ì „ì›” ì‹¤ì ì— ë”°ë¥¸ ì›”ê°„ í•œë„: 30ë§Œì› ì´ìƒ 50ë§Œì› ë¯¸ë§Œ ì‹œ 1ë§Œì›, 50ë§Œì› ì´ìƒ 70ë§Œì› ë¯¸ë§Œ ì‹œ 2ë§Œì›, 70ë§Œì› ì´ìƒ ì‹œ 3ë§Œì›ê¹Œì§€ í•œë„ê°€ ì ìš©ë©ë‹ˆë‹¤. ì¦‰, ì›” ì‹¤ì ì´ ë†’ì„ìˆ˜ë¡ ë” ë§ì€ í• ì¸ í˜œíƒì„ ë°›ê²Œ ë©ë‹ˆë‹¤.\n",
      "- êµí†µ í˜œíƒ(ëŒ€ì¤‘êµí†µ): All day ì„œë¹„ìŠ¤ë¡œ ì§€í•˜ì² Â·ë²„ìŠ¤ ì´ìš©ê¸ˆì•¡ì— 5% í• ì¸. í›„ë¶ˆêµí†µ ê¸°ëŠ¥ì„ í†µí•´ ë‚©ë¶€í•˜ëŠ” ê²½ìš°ì— ì ìš©ë˜ë©°, ì „ì›” ì‹¤ì  í•œë„ ì´ë‚´ì—ì„œ í• ì¸ë©ë‹ˆë‹¤.\n",
      "- ì ì‹¬/ì €ë… í˜œíƒ: ì ì‹¬(12:00~14:00)ê³¼ ì €ë…(19:00~21:00) ì‹œê°„ëŒ€ì— ìŒì‹ì  5% í• ì¸. 1ì¼ 1íšŒ, ê²°ì œ ê¸ˆì•¡ì´ ìµœì†Œ 5,000ì› ì´ìƒì¼ ë•Œ ì ìš©ë©ë‹ˆë‹¤.\n",
      "- í¸ì˜ì /ì œê³¼ì  Time í• ì¸: 07:00~09:00ì— í¸ì˜ì  ë° ì œê³¼ì  5% í• ì¸(ì¼ 1íšŒ). ëŒ€ìƒì€ BCì¹´ë“œ ë“±ë¡ ì—…ì¢… ë¶„ë¥˜ì— ë”°ë¼ ì ìš©ë©ë‹ˆë‹¤.\n",
      "- ê¸°íƒ€: í•´ì™¸ ì´ìš© 5% ë“± ë‹¤ì–‘í•œ ë¶€ê°€ í˜œíƒì´ ìˆì§€ë§Œ, ëª¨ë‘ ì „ì›” ì‹¤ì  ê¸°ë°˜ì˜ ì›” í•œë„ ë‚´ì—ì„œ ì ìš©ë©ë‹ˆë‹¤.\n",
      "\n",
      "ì‹¤ì „ íŒ: 1ìœ„ ì¹´ë“œë¥¼ ì“¸ ë•Œ ê¼­ ì•Œì•„ë‘ë©´ ì¢‹ì€ ì \n",
      "- ì „ì›” ì‹¤ì  ê´€ë¦¬ê°€ í•µì‹¬: ì›” í• ì¸ í•œë„ëŠ” ì „ì›” ì‹¤ì ì— ë”°ë¼ ë‹¬ë¼ì§€ë¯€ë¡œ, ë°°ë‹¬Â·êµí†µ ì§€ì¶œì„ í•œ ë‹¬ì— ì–´ëŠ ì •ë„ ëª°ì•„ì¹˜ë©´ ë” í° í˜œíƒì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ 70ë§Œì› ì´ìƒ ì‹¤ì  ë‹¬ì„± ì‹œ ìµœëŒ€ 3ë§Œì›ì˜ í•œë„ê°€ ì£¼ì–´ì§€ë‹ˆ, ì›” ì˜ˆì‚°ì„ ì—¼ë‘ì— ë‘ê³  ì§€ì¶œì„ ë¶„ë°°í•´ ë³´ì„¸ìš”.\n",
      "- ì œì™¸ ë° ì£¼ì˜ì‚¬í•­ ì²´í¬: í• ì¸ì€ ì²­êµ¬í• ì¸ìœ¼ë¡œ ì ìš©ë˜ë©°, ë¬´ì´ì/ìœ ì´ì í• ë¶€, ì¼ë¶€ ìˆ˜ìˆ˜ë£Œ, í•´ì™¸ ë§¤ì¶œ, ìƒí’ˆê¶Œ/ì¶©ì „êµ¬ë§¤ ë“±ì€ í• ì¸ ëŒ€ìƒì—ì„œ ì œì™¸ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ ë§¤ì›” í•œë„ëŠ” ì¹´ë“œì˜ ì „ì›” ì‹¤ì ì— ì¢Œìš°ë˜ë¯€ë¡œ ì‹¤ì  ì‚°ì •ì—ì„œ ì œì™¸ë˜ëŠ” í•­ëª©ë„ ë¯¸ë¦¬ íŒŒì•…í•´ ë‘ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.\n",
      "- ê°€ë§¹ì  í™•ì¸: í• ì¸ì€ BCì¹´ë“œì— ë“±ë¡ëœ ì—…ì¢… ê¸°ì¤€ìœ¼ë¡œ ì ìš©ë©ë‹ˆë‹¤. ê°€ë§¹ì ì´ ì—…ì¢… ì½”ë“œ ë³€ê²½ ë“±ìœ¼ë¡œ ì œì™¸ë  ìˆ˜ ìˆìœ¼ë‹ˆ ìì£¼ ì´ìš©í•˜ëŠ” ë§¤ì¥ì—ì„œëŠ” ì‚¬ì „ì— í™•ì¸í•´ ë‘ë©´ ì¢‹ìŠµë‹ˆë‹¤.\n",
      "- ì‹œê°„ëŒ€ í™œìš© ì „ëµ: ë°°ë‹¬ì•± í• ì¸ì€ 22:00~00:00, í¸ì˜ì /ì œê³¼ì ì€ 07:00~09:00, ì‹ë‹¹ í• ì¸ì€ ì ì‹¬/ì €ë… ì‹œê°„ëŒ€ì— ì§‘ì¤‘ë©ë‹ˆë‹¤. í•˜ë£¨ì— ì—¬ëŸ¬ ë²ˆ ë¨¹ë”ë¼ë„ í• ì¸ì€ 1ì¼ 1íšŒ í•œë„ ë“±ìœ¼ë¡œ ì œí•œë  ìˆ˜ ìˆìœ¼ë‹ˆ ì‹œê°„ëŒ€ë³„ë¡œ ê³„íšì ìœ¼ë¡œ ì´ìš©í•´ë³´ì„¸ìš”.\n",
      "- ì´ˆê¸° ì ì‘ ì‹œë‚˜ë¦¬ì˜¤: ì²˜ìŒ ëª‡ ë‹¬ì€ ì „ì›” ì‹¤ì ì´ ë‚®ì•„ í• ì¸ í•œë„ê°€ ì‘ê±°ë‚˜ ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ì›” ì´ˆì— ì˜ˆìƒ ì§€ì¶œì„ ì •í•˜ê³ , í•„ìš” ì‹œ ë‹¤ë¥¸ ì¹´ë“œì™€ í•¨ê»˜ ì‚¬ìš©í• ì§€ íŒë‹¨í•˜ëŠ” ê²ƒë„ ì¢‹ì€ ë°©ë²•ì…ë‹ˆë‹¤.\n",
      "\n",
      "í•„ìš”í•˜ì‹  ê²½ìš°, ì›”í‰ê·  ë°°ë‹¬ ì£¼ë¬¸ íšŸìˆ˜ì™€ ì£¼ë¡œ ì´ìš©í•˜ëŠ” ë§¤ì¥(ë°°ë‹¬ ì•± ì¢…ë¥˜, êµí†µ ìˆ˜ë‹¨)ì„ ì•Œë ¤ì£¼ì‹œë©´, ë‹¹ì‹ ì˜ ì‹¤ì œ ì§€ì¶œ íŒ¨í„´ì— ë§ì¶° ì–´ëŠ ì¹´ë“œë¥¼ ì“¸ì§€ ë” êµ¬ì²´ì ìœ¼ë¡œ ë¹„êµí•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "import chromadb\n",
    "import cohere\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "# 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (API í‚¤)\n",
    "load_dotenv()\n",
    "OPENAI_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "COHERE_KEY = os.getenv(\"COHERE_API_KEY\")\n",
    "\n",
    "# 2. ë¡œì»¬ ê²½ë¡œ ë° ì„¤ì •\n",
    "INPUT_FILE = './data/FINAL_MASTER_DATA_FIXED_7757.json'\n",
    "MODEL_PATH = './models/gemma-300m-4080super-extreme'    \n",
    "CHROMA_DB_PATH = './data/chroma_db'\n",
    "\n",
    "# 3. ëª¨ë¸ ë° í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "bi_encoder = SentenceTransformer(MODEL_PATH, device=device)\n",
    "openai_client = OpenAI(api_key=OPENAI_KEY)\n",
    "co = cohere.ClientV2(api_key=COHERE_KEY)\n",
    "\n",
    "# 4. ë°ì´í„° ë¦¬í•˜ì´ë“œë ˆì´ì…˜ ë§µ ìƒì„± (ID ê¸°ë°˜ ë³µì›)\n",
    "with open(INPUT_FILE, 'r', encoding='utf-8') as f:\n",
    "    master_data = json.load(f)\n",
    "\n",
    "card_master_map = {}\n",
    "for item in master_data:\n",
    "    c_id = item['metadata']['card_id']\n",
    "    if c_id not in card_master_map:\n",
    "        card_master_map[c_id] = {\n",
    "            \"name\": item['metadata']['card_name'],\n",
    "            \"corp\": item['metadata']['corp'],\n",
    "            \"full_details\": [item['content']], \n",
    "            \"structured\": item['ai_structured']\n",
    "        }\n",
    "    else:\n",
    "        card_master_map[c_id][\"full_details\"].append(item['content'])\n",
    "\n",
    "# 5. ChromaDB ì—°ê²° ë° ì„ë² ë”© í•¨ìˆ˜ ì„¤ì •\n",
    "class GemmaEmbeddingFunction(embedding_functions.EmbeddingFunction):\n",
    "    def __call__(self, input_texts):\n",
    "        passages = [f\"title: none | text: {text}\" for text in input_texts]\n",
    "        return bi_encoder.encode(passages, convert_to_tensor=False).tolist()\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path=CHROMA_DB_PATH)\n",
    "collection = chroma_client.get_collection(\n",
    "    name=\"card_benefits\", \n",
    "    embedding_function=GemmaEmbeddingFunction()\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# [HELPER] ë™ì  ì˜ë„ ì¶”ì¶œ í•¨ìˆ˜\n",
    "# ==========================================\n",
    "def extract_search_intents(user_query):\n",
    "    \"\"\"ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ê²€ìƒ‰ìš© í•µì‹¬ í‚¤ì›Œë“œë¥¼ ë™ì ìœ¼ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤.\"\"\"\n",
    "\n",
    "    \n",
    "    prompt = f\"\"\"ì‚¬ìš©ìì˜ ì§ˆë¬¸ì—ì„œ ì¹´ë“œ í˜œíƒ ê²€ìƒ‰ì„ ìœ„í•œ í•µì‹¬ í‚¤ì›Œë“œ 1~3ê°œë¥¼ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ì¶”ì¶œí•´ì¤˜.\n",
    "ì˜ˆ: \"ì»¤í”¼ í• ì¸ë˜ê³  ê³µê³¼ê¸ˆ ì•„ë¼ëŠ” ì¹´ë“œ\" -> [\"ì»¤í”¼\", \"ê³µê³¼ê¸ˆ\"]\n",
    "ì§ˆë¬¸: {user_query}\n",
    "í˜•ì‹: [\"í‚¤ì›Œë“œ1\", \"í‚¤ì›Œë“œ2\"] (JSON ë¦¬ìŠ¤íŠ¸ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”)\"\"\"\n",
    "    \n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    try:\n",
    "        return json.loads(response.choices[0].message.content)\n",
    "    except:\n",
    "        return [user_query]\n",
    "\n",
    "# ==========================================\n",
    "# [CORE] í†µí•© RAG í•¨ìˆ˜\n",
    "# ==========================================\n",
    "def card_concierge_rag(user_query, top_n=3):\n",
    "    print(f\"ğŸ” ì§ˆë¬¸ ë¶„ì„ ë° ì˜ë„ ì¶”ì¶œ ì¤‘...\")\n",
    "    \n",
    "    # [Step 1] ë™ì  ì˜ë„ ì¶”ì¶œ\n",
    "    search_intents = extract_search_intents(user_query)\n",
    "    print(f\"ğŸ¯ ì¶”ì¶œëœ í‚¤ì›Œë“œ: {search_intents}\")\n",
    "\n",
    "    # [Step 2] ChromaDB êµì°¨ ê²€ìƒ‰ (AND ë¡œì§)\n",
    "    intent_hits = []\n",
    "    for intent in search_intents:\n",
    "        query_text = f\"task: search result | query: {intent}\"\n",
    "        results = collection.query(\n",
    "            query_texts=[query_text],\n",
    "            n_results=100,\n",
    "            include=['metadatas']\n",
    "        )\n",
    "        ids = {m['card_id'] for m in results['metadatas'][0]}\n",
    "        intent_hits.append(ids)\n",
    "\n",
    "    # êµì§‘í•© í•„í„°ë§\n",
    "    common_ids = intent_hits[0]\n",
    "    for h in intent_hits[1:]:\n",
    "        common_ids &= h\n",
    "\n",
    "    if not common_ids:\n",
    "        print(\"âš ï¸ êµì§‘í•© ê²°ê³¼ê°€ ì—†ì–´ ë‹¨ì¼ ì˜ë„ ê²°ê³¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.\")\n",
    "        common_ids = intent_hits[0]\n",
    "\n",
    "    # [Step 3] Cohere v3.5 ë¦¬ë­í‚¹\n",
    "    candidate_ids = list(common_ids)\n",
    "    rerank_docs = []\n",
    "    for c_id in candidate_ids:\n",
    "        card = card_master_map[c_id]\n",
    "        context = f\"ì¹´ë“œëª…: {card['name']} | ìƒì„¸í˜œíƒ: {' '.join(card['full_details'])}\"\n",
    "        rerank_docs.append(context)\n",
    "\n",
    "    print(f\"ğŸ¯ Cohere v3.5 ë¦¬ë­í‚¹ ì¤‘... (í›„ë³´: {len(rerank_docs)}ê°œ)\")\n",
    "    rerank_response = co.rerank(\n",
    "        model=\"rerank-v3.5\",\n",
    "        query=user_query,\n",
    "        documents=rerank_docs,\n",
    "        top_n=top_n\n",
    "    )\n",
    "\n",
    "# [Step 4] ë°ì´í„° ë³µì› ë° LLM ë‹µë³€ ìƒì„± (GPT-5-Nano)\n",
    "    final_context = \"\"\n",
    "    for i, hit in enumerate(rerank_response.results):\n",
    "        best_id = candidate_ids[hit.index]\n",
    "        card = card_master_map[best_id]\n",
    "        # ìˆœìœ„ ì •ë³´ì™€ í•¨ê»˜ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±\n",
    "        final_context += f\"### [Top {i+1}] {card['name']} ({card['corp']})\\n\"\n",
    "        final_context += f\"- ì‹¤ì ì¡°ê±´: {card['structured']['condition']}\\n\"\n",
    "        final_context += f\"- ìƒì„¸ ë°ì´í„°: {' / '.join(card['full_details'])}\\n\\n\"\n",
    "\n",
    "    # â­ ì¹œì ˆí•œ ì±—ë´‡ ìŠ¤íƒ€ì¼ì˜ ë²”ìš© í”„ë¡¬í”„íŠ¸\n",
    "    prompt = f\"\"\"ë‹¹ì‹ ì€ ì „ì—¬ìš±ë‹˜ì˜ ë“ ë“ í•œ 'ê¸ˆìœµ ë¹„ì„œ Gemma-Bot'ì…ë‹ˆë‹¤. \n",
    "ì œê³µëœ [ì¹´ë“œ ë°ì´í„°]ë¥¼ ë¶„ì„í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹¤ì •í•˜ê³  ëª…í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.\n",
    "\n",
    "ì‚¬ìš©ì ì§ˆë¬¸: {user_query}\n",
    "\n",
    "[ì¹´ë“œ ë°ì´í„°]\n",
    "{final_context}\n",
    "\n",
    "[ë‹µë³€ ì‘ì„± ê°€ì´ë“œ]\n",
    "1. **ì¹œì ˆí•œ ì¸ì‚¬**: ì‚¬ìš©ìì˜ ë‹ˆì¦ˆë¥¼ ì–¸ê¸‰í•˜ë©° ë‹¤ì •í•˜ê²Œ ëŒ€í™”ë¥¼ ì‹œì‘í•˜ì„¸ìš”.\n",
    "2. **Top 3 ëª©ë¡**: ì¶”ì²œí•˜ëŠ” ìƒìœ„ 3ê°œ ì¹´ë“œì˜ ì´ë¦„ê³¼ ì¹´ë“œì‚¬ë¥¼ ìˆœì„œëŒ€ë¡œ ë‚˜ì—´í•˜ì„¸ìš”.\n",
    "3. **Top 1 ì§‘ì¤‘ ë¶„ì„**: 1ìœ„ë¡œ ì„ ì •ëœ ì¹´ë“œê°€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ í˜œíƒì„ êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–»ê²Œ ì œê³µí•˜ëŠ”ì§€(ìˆ˜ì¹˜, í•œë„ ë“±) ìƒì„¸íˆ ì„¤ëª…í•˜ì„¸ìš”.\n",
    "4. **ì‹¤ì „ íŒ**: 1ìœ„ ì¹´ë“œë¥¼ ì“¸ ë•Œ ì£¼ì˜í•´ì•¼ í•  ì „ì›” ì‹¤ì ì´ë‚˜ ì œì™¸ í•­ëª©ì„ 'ë¹„ì„œì²˜ëŸ¼' ì¡°ì–¸í•´ ì£¼ì„¸ìš”.\n",
    "5. **í†¤ì•¤ë§¤ë„ˆ**: í‘œëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”. ì½ê¸° í¸í•œ ë¬¸ì¥ê³¼ ë¶ˆë › í¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ê³  ì „ì²´ ë¶„ëŸ‰ì€ ì ì ˆíˆ ì¡°ì ˆí•˜ì„¸ìš”.\"\"\"\n",
    "\n",
    "    # gpt-5-nano ì—ëŸ¬ ë°©ì§€: temperature íŒŒë¼ë¯¸í„° ì œì™¸\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-5-nano\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"ì‚¬ìš©ìì˜ ìƒí™©ì„ ê³µê°í•˜ê³  ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìµœì ì˜ ì†”ë£¨ì…˜ì„ ì œì•ˆí•˜ëŠ” ë‹¤ì •í•œ ê¸ˆìœµ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# ==========================================\n",
    "# ì‹¤í–‰ë¶€\n",
    "# ==========================================\n",
    "if __name__ == \"__main__\":\n",
    "    user_q = \"ì‚¬íšŒì´ˆë…„ìƒì¸ë° ë°°ë‹¬ ìŒì‹ì„ ìì£¼ ì‹œì¼œ ë¨¹ê³  êµí†µë¹„ í˜œíƒì´ ì¢‹ì€ ì¹´ë“œê°€ ìˆì„ê¹Œ?\"\n",
    "    \n",
    "    result = card_concierge_rag(user_q)\n",
    "    print(\"\\nâœ¨ [ê¸ˆìœµ ë¹„ì„œ Gemma-Bot ë‹µë³€]:\\n\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be146508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== CARD FACT CHECK ==============================\n",
      "ğŸ’³ ì¹´ë“œëª…: ë‰´íƒ€ì„ì¹´ë“œ (SCì œì¼ì€í–‰)\n",
      "ğŸ†” Card ID: 483\n",
      "ğŸ’° ì—°íšŒë¹„: êµ­ë‚´ì „ìš© [8,000]ì› / í•´ì™¸ê²¸ìš© [10,000]ì›\n",
      "ğŸ“‰ ìµœì†Œì‹¤ì : 300000ì›\n",
      "=============================================================================\n",
      "\n",
      "[1] ì¹´í…Œê³ ë¦¬: ì‡¼í•‘/ìƒí™œ > í¸ì˜ì  (í¸ì˜ì )\n",
      "   ğŸ“ AI ìš”ì•½: ë‰´íƒ€ì„ì¹´ë“œëŠ” ì£¼ìš” í¸ì˜ì  ë° ì œê³¼ì ì—ì„œ 5% í• ì¸ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
      "   ğŸ¢ ì£¼ìš” ê°€ë§¹ì : GS25, CU, ì„¸ë¸ì¼ë ˆë¸, ë¯¸ë‹ˆìŠ¤í†±, ì´ë§ˆíŠ¸24, íŒŒë¦¬ë°”ê²ŒíŠ¸, ëšœë ˆì¥¬ë¥´\n",
      "   âœ… ìƒì„¸ ì¡°ê±´: ì „ì›” ì‹¤ì ì— ë”°ë¥¸ ì›”ê°„ í†µí•© í• ì¸ í•œë„ ì´ë‚´ì—ì„œ ì ìš©\n",
      "   ğŸ’¡ í˜œíƒ ìƒì„¸: 5% í• ì¸\n",
      "-----------------------------------------------------------------------------\n",
      "[2] ì¹´í…Œê³ ë¦¬: í‘¸ë“œ/ì¹´í˜ > í‘¸ë“œ (í‘¸ë“œ)\n",
      "   ğŸ“ AI ìš”ì•½: ë‰´íƒ€ì„ì¹´ë“œëŠ” ì ì‹¬ê³¼ ì €ë… ì‹œê°„ëŒ€ì— ìŒì‹ì ì—ì„œ 5% í• ì¸ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
      "   ğŸ¢ ì£¼ìš” ê°€ë§¹ì : ì¼ë°˜í•œì‹, ê°ˆë¹„ì „ë¬¸ì , í•œì •ì‹, ìŠ¤ë‚µ, ì¼ì‹íšŒì§‘, ì¤‘êµ­ìŒì‹, ì„œì–‘ìŒì‹, ìœ„íƒê¸‰ì‹ì—…\n",
      "   âœ… ìƒì„¸ ì¡°ê±´: ì „ì›” ì‹¤ì ì— ë”°ë¥¸ ì›”ê°„ í†µí•© í• ì¸ í•œë„ ì´ë‚´ì—ì„œ ì ìš©\n",
      "   ğŸ’¡ í˜œíƒ ìƒì„¸: ìŒì‹ì  5% í• ì¸, 1ì¼ 1íšŒ, ìµœì†Œ 5ì²œì› ì´ìƒ ê²°ì œ ì‹œ ì œê³µ\n",
      "-----------------------------------------------------------------------------\n",
      "[3] ì¹´í…Œê³ ë¦¬: ì‡¼í•‘/ìƒí™œ > ì˜¨ë¼ì¸ì‡¼í•‘ (ì˜¨ë¼ì¸ì‡¼í•‘)\n",
      "   ğŸ“ AI ìš”ì•½: ë‰´íƒ€ì„ì¹´ë“œëŠ” ì£¼ìš” ì¸í„°ë„· ì‡¼í•‘ì—ì„œ 5% í• ì¸ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
      "   ğŸ¢ ì£¼ìš” ê°€ë§¹ì : Gë§ˆì¼“, 11ë²ˆê°€, ì˜¥ì…˜\n",
      "   âœ… ìƒì„¸ ì¡°ê±´: ì „ì›” ì‹¤ì ì— ë”°ë¥¸ ì›”ê°„ í†µí•© í• ì¸ í•œë„ ì´ë‚´ì—ì„œ ì ìš©\n",
      "   ğŸ’¡ í˜œíƒ ìƒì„¸: 5% í• ì¸\n",
      "-----------------------------------------------------------------------------\n",
      "[4] ì¹´í…Œê³ ë¦¬: ì‡¼í•‘/ìƒí™œ > ë“œëŸ­ìŠ¤í† ì–´ (ë“œëŸ­ìŠ¤í† ì–´)\n",
      "   ğŸ“ AI ìš”ì•½: ë‰´íƒ€ì„ì¹´ë“œëŠ” ë“œëŸ¬ê·¸ìŠ¤í† ì–´ì—ì„œ 5% í• ì¸ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
      "   ğŸ¢ ì£¼ìš” ê°€ë§¹ì : LOHBâ€™s, ë„ë¼ë¸”ë¼, ë¶€ì¸ \n",
      "   âœ… ìƒì„¸ ì¡°ê±´: ì „ì›” ì‹¤ì ì— ë”°ë¥¸ ì›”ê°„ í†µí•© í• ì¸ í•œë„ ì´ë‚´ì—ì„œ ì ìš©\n",
      "   ğŸ’¡ í˜œíƒ ìƒì„¸: 5% í• ì¸\n",
      "-----------------------------------------------------------------------------\n",
      "[5] ì¹´í…Œê³ ë¦¬: êµí†µ/ìë™ì°¨ > ëŒ€ì¤‘êµí†µ (ëŒ€ì¤‘êµí†µ)\n",
      "   ğŸ“ AI ìš”ì•½: ì§€í•˜ì²  ë° ë²„ìŠ¤ ì´ìš© ì‹œ 5% í• ì¸ ì œê³µ\n",
      "   ğŸ¢ ì£¼ìš” ê°€ë§¹ì : ì§€í•˜ì² , ë²„ìŠ¤\n",
      "   âœ… ìƒì„¸ ì¡°ê±´: ì „ì›” ì‹¤ì ì— ë”°ë¥¸ ì›”ê°„ í†µí•© í• ì¸ í•œë„ ì´ë‚´ì—ì„œ ì ìš©\n",
      "   ğŸ’¡ í˜œíƒ ìƒì„¸: ì§€í•˜ì²  ë° ë²„ìŠ¤ ì´ìš©ëŒ€ê¸ˆì˜ 5% í• ì¸ ì ìš©\n",
      "-----------------------------------------------------------------------------\n",
      "[6] ì¹´í…Œê³ ë¦¬: ì‡¼í•‘/ìƒí™œ > ë°°ë‹¬ì•± (ë°°ë‹¬ì•±)\n",
      "   ğŸ“ AI ìš”ì•½: ë‰´íƒ€ì„ì¹´ë“œëŠ” ë°°ë‹¬ì•±ì—ì„œ 5% í• ì¸ì„ ì œê³µí•˜ëŠ” ì¹´ë“œì…ë‹ˆë‹¤.\n",
      "   ğŸ¢ ì£¼ìš” ê°€ë§¹ì : ë°°ë‹¬ì˜ë¯¼ì¡±, ìš”ê¸°ìš”, ë°°ë‹¬í†µ\n",
      "   âœ… ìƒì„¸ ì¡°ê±´: ì „ì›” ì‹¤ì ì— ë”°ë¥¸ ì›”ê°„ í†µí•© í• ì¸ í•œë„ ì´ë‚´ì—ì„œ ì ìš©\n",
      "   ğŸ’¡ í˜œíƒ ìƒì„¸: 5% í• ì¸, 1ì¼ 1íšŒ, ìµœì†Œ 5ì²œì› ì´ìƒ ê²°ì œ ì‹œ ì œê³µ\n",
      "-----------------------------------------------------------------------------\n",
      "[7] ì¹´í…Œê³ ë¦¬: í‘¸ë“œ/ì¹´í˜ > ì¹´í˜ (ì¹´í˜)\n",
      "   ğŸ“ AI ìš”ì•½: ë‰´íƒ€ì„ì¹´ë“œëŠ” ì»¤í”¼ì „ë¬¸ì ì—ì„œ 5% í• ì¸ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
      "   ğŸ¢ ì£¼ìš” ê°€ë§¹ì : ìŠ¤íƒ€ë²…ìŠ¤, íˆ¬ì¸í”Œë ˆì´ìŠ¤, íƒì•¤íƒìŠ¤, ì»¤í”¼ë¹ˆ, ì—”ì œë¦¬ë„ˆìŠ¤, í• ë¦¬ìŠ¤, ì•„í‹°ì œ, í´ ë°”ì…‹, ì´ë””ì•¼, ì¹´í˜ë² ë„¤\n",
      "   âœ… ìƒì„¸ ì¡°ê±´: ì „ì›” ì‹¤ì ì— ë”°ë¥¸ ì›”ê°„ í†µí•© í• ì¸ í•œë„ ì´ë‚´ì—ì„œ ì ìš©\n",
      "   ğŸ’¡ í˜œíƒ ìƒì„¸: 5% í• ì¸, 1ì¼ 1íšŒ ì œê³µ\n",
      "-----------------------------------------------------------------------------\n",
      "[8] ì¹´í…Œê³ ë¦¬: ì—¬í–‰/í”„ë¦¬ë¯¸ì—„ > í•´ì™¸ì´ìš© (í•´ì™¸ì´ìš©)\n",
      "   ğŸ“ AI ìš”ì•½: ë‰´íƒ€ì„ì¹´ë“œëŠ” í•´ì™¸ ì´ìš© ì‹œ 5% í• ì¸ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
      "   ğŸ¢ ì£¼ìš” ê°€ë§¹ì : í•´ì™¸ ê°€ë§¹ì , ì˜¨ë¼ì¸ ì‚¬ì´íŠ¸\n",
      "   âœ… ìƒì„¸ ì¡°ê±´: ì „ì›” ì‹¤ì ì— ë”°ë¥¸ ì›”ê°„ í†µí•© í• ì¸ í•œë„ ì´ë‚´ì—ì„œ ì ìš©\n",
      "   ğŸ’¡ í˜œíƒ ìƒì„¸: í•´ì™¸ ì´ìš©ìš”ê¸ˆ 5% í• ì¸\n",
      "-----------------------------------------------------------------------------\n",
      "[9] ì¹´í…Œê³ ë¦¬: ë””ì§€í„¸/í†µì‹  > í†µì‹  (í†µì‹ )\n",
      "   ğŸ“ AI ìš”ì•½: ì´ë™í†µì‹ ìš”ê¸ˆ ìë™ë‚©ë¶€ ì‹œ 5% í• ì¸ í˜œíƒ ì œê³µ\n",
      "   ğŸ¢ ì£¼ìš” ê°€ë§¹ì : SKT, KT, LG U+\n",
      "   âœ… ìƒì„¸ ì¡°ê±´: ì´ë™í†µì‹ ìš”ê¸ˆ ìë™ë‚©ë¶€ ê²°ì œ ì‹œ í• ì¸ ì ìš©\n",
      "   ğŸ’¡ í˜œíƒ ìƒì„¸: 5% í• ì¸, ì›” 1íšŒ ìµœì´ˆ ìŠ¹ì¸ ê±´ì— ëŒ€í•´ ì ìš©\n",
      "-----------------------------------------------------------------------------\n",
      "[10] ì¹´í…Œê³ ë¦¬: ì‡¼í•‘/ìƒí™œ > ëŒ€í˜•ë§ˆíŠ¸ (ëŒ€í˜•ë§ˆíŠ¸)\n",
      "   ğŸ“ AI ìš”ì•½: ì£¼ë§ ë° ê³µíœ´ì¼ì— 3ëŒ€ ë§ˆíŠ¸ì—ì„œ 5% í• ì¸ í˜œíƒ ì œê³µ\n",
      "   ğŸ¢ ì£¼ìš” ê°€ë§¹ì : ì´ë§ˆíŠ¸, í™ˆí”ŒëŸ¬ìŠ¤, ë¡¯ë°ë§ˆíŠ¸\n",
      "   âœ… ìƒì„¸ ì¡°ê±´: ì „ì›” ì‹¤ì ì— ë”°ë¥¸ ì›”ê°„ í†µí•© í• ì¸ í•œë„ ì´ë‚´ì—ì„œ ì ìš©\n",
      "   ğŸ’¡ í˜œíƒ ìƒì„¸: 3ëŒ€ ë§ˆíŠ¸ì—ì„œ 5% í• ì¸\n",
      "   âš ï¸ ì‹¤ì  ì œì™¸: ['ë¬´ì´ì í• ë¶€ ì´ìš©ê¸ˆì•¡']\n",
      "-----------------------------------------------------------------------------\n",
      "[11] ì¹´í…Œê³ ë¦¬: êµí†µ/ìë™ì°¨ > ì£¼ìœ  (ì£¼ìœ )\n",
      "   ğŸ“ AI ìš”ì•½: ì£¼ë§ ë° ê³µíœ´ì¼ì— S-Oilì—ì„œ ë¦¬í„°ë‹¹ 60ì› í• ì¸, ì£¼ì¤‘ì—ëŠ” 40ì› í• ì¸ ì œê³µ.\n",
      "   ğŸ¢ ì£¼ìš” ê°€ë§¹ì : S-Oil\n",
      "   âœ… ìƒì„¸ ì¡°ê±´: ì „ì›” ì‹¤ì ì— ë”°ë¥¸ ì›”ê°„ í†µí•© í• ì¸ í•œë„ ì´ë‚´ì—ì„œ ì ìš©\n",
      "   ğŸ’¡ í˜œíƒ ìƒì„¸: ì£¼ë§ & ê³µíœ´ì¼ ë¦¬í„°ë‹¹ 60ì› í• ì¸, ì£¼ì¤‘ ë¦¬í„°ë‹¹ 40ì› í• ì¸, 1ì¼ 1íšŒ, 1íšŒ ì£¼ìœ ê¸ˆì•¡ 10ë§Œì› í•œë„\n",
      "-----------------------------------------------------------------------------\n",
      "[12] ì¹´í…Œê³ ë¦¬: ê¸°íƒ€/ì•ˆë‚´ > ìœ ì˜ì‚¬í•­ (ìœ ì˜ì‚¬í•­)\n",
      "   ğŸ“ AI ìš”ì•½: ë‰´íƒ€ì„ì¹´ë“œëŠ” ì „ì›” ì‹¤ì ì— ë”°ë¼ ì›”ê°„ í†µí•© í• ì¸ í•œë„ê°€ ì œê³µë˜ëŠ” ì¹´ë“œì…ë‹ˆë‹¤.\n",
      "   ğŸ¢ ì£¼ìš” ê°€ë§¹ì : êµ­ë‚´ ê°€ë§¹ì , êµí†µì¹´ë“œ, í†µì‹ ë£Œ ìë™ì´ì²´\n",
      "   âœ… ìƒì„¸ ì¡°ê±´: ì „ì›” ì‹¤ì  30ë§Œì› ì´ìƒ ì‹œ 1ë§Œì›, 50ë§Œì› ì´ìƒ ì‹œ 2ë§Œì›, 70ë§Œì› ì´ìƒ ì‹œ 3ë§Œì› í• ì¸\n",
      "   ğŸ’¡ í˜œíƒ ìƒì„¸: ì²­êµ¬í• ì¸ ë°©ì‹ìœ¼ë¡œ ì ìš©, ì¹´ë“œ ìˆ˜ë ¹ì›” ë° ìµì›”ê¹Œì§€ëŠ” 1ë§Œì› í• ì¸ ë˜ëŠ” ì „ì›” ì‹¤ì ì— ë”°ë¥¸ í• ì¸ í•œë„ ì¤‘ ë†’ì€ ê¸ˆì•¡ ì ìš©\n",
      "   âš ï¸ ì‹¤ì  ì œì™¸: ['ë‹¨ê¸°ì¹´ë“œëŒ€ì¶œ', 'ì¥ê¸°ì¹´ë“œëŒ€ì¶œ', 'ì—°íšŒë¹„', 'ê°ì¢… ìˆ˜ìˆ˜ë£Œ', 'ê°ì¢… ì„¸ê¸ˆ', 'ê³ ìš©ì‚°ì¬ë³´í—˜', 'ìƒí’ˆê¶Œ', 'ê¸°í”„íŠ¸ì¹´ë“œ ì¶©ì „Â·êµ¬ë§¤', 'í¬ì¸íŠ¸ ì‚¬ìš©', 'ê°ì¢… ë“±ë¡ê¸ˆ', 'ê°ì¢… ë³´í—˜ë£Œ', 'ê°ì¢… ê³µê³¼ê¸ˆ', 'ê³¼íƒœë£Œ ë‚©ë¶€ì•¡', 'ë§¤ì¶œì·¨ì†Œ ê¸ˆì•¡', 'ë¬´ì´ìí• ë¶€', 'êµí†µìš”ê¸ˆ', 'ì•„íŒŒíŠ¸ê´€ë¦¬ë¹„']\n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def print_all_card_details(target_card_id):\n",
    "    # 1. í•´ë‹¹ IDì— ë§ëŠ” ëª¨ë“  ì¡°ê°(fragments) ì°¾ê¸°\n",
    "    card_fragments = [item for item in master_data if item['metadata']['card_id'] == target_card_id]\n",
    "    \n",
    "    if not card_fragments:\n",
    "        print(f\"âŒ ID {target_card_id}ì— í•´ë‹¹í•˜ëŠ” ì¹´ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "\n",
    "    # 2. ê³µí†µ ì •ë³´ ì¶œë ¥ (ì²« ë²ˆì§¸ ì¡°ê° ê¸°ì¤€)\n",
    "    base_info = card_fragments[0]['metadata']\n",
    "    print(f\"\\n{'='*30} CARD FACT CHECK {'='*30}\")\n",
    "    print(f\"ğŸ’³ ì¹´ë“œëª…: {base_info['card_name']} ({base_info['corp']})\")\n",
    "    print(f\"ğŸ†” Card ID: {base_info['card_id']}\")\n",
    "    print(f\"ğŸ’° ì—°íšŒë¹„: {base_info['annual_fee']}\")\n",
    "    print(f\"ğŸ“‰ ìµœì†Œì‹¤ì : {base_info['min_performance']}ì›\")\n",
    "    print(f\"{'='*77}\\n\")\n",
    "\n",
    "    # 3. ê° í˜œíƒ ì¹´í…Œê³ ë¦¬ë³„ ìƒì„¸ ë‚´ìš© ì¶œë ¥\n",
    "    for i, fragment in enumerate(card_fragments):\n",
    "        meta = fragment['metadata']\n",
    "        ai = fragment['ai_structured']\n",
    "        \n",
    "        print(f\"[{i+1}] ì¹´í…Œê³ ë¦¬: {meta['main_category']} > {meta['sub_category']} ({meta['category']})\")\n",
    "        print(f\"   ğŸ“ AI ìš”ì•½: {ai['summary']}\")\n",
    "        print(f\"   ğŸ¢ ì£¼ìš” ê°€ë§¹ì : {', '.join(ai['merchants'])}\")\n",
    "        print(f\"   âœ… ìƒì„¸ ì¡°ê±´: {ai['condition']}\")\n",
    "        print(f\"   ğŸ’¡ í˜œíƒ ìƒì„¸: {ai['benefit_detail']}\")\n",
    "        \n",
    "        # ì‹¤ì  ì œì™¸ í•­ëª©ì´ë‚˜ ìœ ì˜ì‚¬í•­ì´ ìˆë‹¤ë©´ ì¶”ê°€ ì¶œë ¥\n",
    "        if ai.get('performance_exclusions') and ai['performance_exclusions'][0] != \"ì •ë³´ ì—†ìŒ\":\n",
    "            print(f\"   âš ï¸ ì‹¤ì  ì œì™¸: {ai['performance_exclusions']}\")\n",
    "        \n",
    "        print(\"-\" * 77)\n",
    "\n",
    "# ì‹¤í–‰: ì‹ í•œì¹´ë“œ Mr.Life(ID 13)ì˜ ëª¨ë“  ë‚´ìš© í™•ì¸\n",
    "print_all_card_details(483)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sesac-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
