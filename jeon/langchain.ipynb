{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3f392d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain langchain-openai langchain-cohere langchain-community chromadbb\n",
    "# !pip install -U langchain langchain-openai langchain-community langchain-cohere chromadb sentence-transformers python-dotenv\n",
    "# ! pip install langchain_classic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0d5cc1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05bd5877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from typing import List, Any, Dict\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LangChain ë° ê´€ë ¨ ëª¨ë“ˆ\n",
    "from langchain_classic.retrievers.contextual_compression import ContextualCompressionRetriever\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_cohere import CohereRerank\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e3e1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import List, Any, Dict\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "class GemmaEmbeddings:\n",
    "    def __init__(self, model_path: str):\n",
    "        self.model = SentenceTransformer(model_path)\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        return self.model.encode([f\"title: none | text: {text}\" for text in texts]).tolist()\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        return self.model.encode(f\"task: search result | query: {text}\").tolist()\n",
    "\n",
    "class CardANDRetriever(BaseRetriever):\n",
    "\n",
    "    vectorstore: Any\n",
    "    card_map: Dict\n",
    "    intent_extractor: Any\n",
    "    search_depth: int = 200\n",
    "\n",
    "    def _get_relevant_documents(self, query: str) -> List[Document]:\n",
    "        # 1. ë™ì  ì˜ë„ ì¶”ì¶œ (LLM í™œìš©)\n",
    "        keywords_json = self.intent_extractor.invoke({\"question\": query})\n",
    "        try:\n",
    "            search_intents = json.loads(keywords_json.replace(\"```json\", \"\").replace(\"```\", \"\"))\n",
    "        except:\n",
    "            search_intents = [query]\n",
    "        print(f\"ì¶”ì¶œëœ í‚¤ì›Œë“œ: {search_intents}\")\n",
    "\n",
    "        # 2. ê° ì˜ë„ë³„ ê²€ìƒ‰ ë° ì ìˆ˜ ìˆ˜ì§‘ (ì›ë³¸ Step 4 - 1ë‹¨ê³„)\n",
    "        intent_scores = []\n",
    "        for intent in search_intents:\n",
    "            results = self.vectorstore.similarity_search_with_relevance_scores(intent, k=self.search_depth)\n",
    "            # IDë¥¼ í‚¤ë¡œ, ì ìˆ˜ë¥¼ ê°’ìœ¼ë¡œ ì €ì¥\n",
    "            current_hits = {str(doc.metadata['card_id']): score for doc, score in results}\n",
    "            intent_scores.append(current_hits)\n",
    "\n",
    "        # 3. êµì§‘í•©(AND) í•„í„°ë§ (ì›ë³¸ Step 4 - 2ë‹¨ê³„)\n",
    "        common_ids = set(intent_scores[0].keys())\n",
    "        for hits in intent_scores[1:]:\n",
    "            common_ids &= set(hits.keys())\n",
    "        \n",
    "        if not common_ids:\n",
    "            common_ids = set(list(intent_scores[0].keys())[:20])\n",
    "\n",
    "        # 4. ì ìˆ˜ í•©ì‚° ë° ë°ì´í„° ë³µì› (ì›ë³¸ Step 4 - 3ë‹¨ê³„)\n",
    "        final_docs = []\n",
    "        for c_id in list(common_ids):\n",
    "            # ì¢…í•© ì ìˆ˜ ê³„ì‚°: $$Score_{total} = \\sum Score_{intent}$$\n",
    "            total_score = sum(intent_map[c_id] for intent_map in intent_scores if c_id in intent_map)\n",
    "            \n",
    "            card = self.card_map.get(str(c_id))\n",
    "            if not card: continue\n",
    "            \n",
    "            content = f\"ì¹´ë“œëª…: {card['name']} | ìƒì„¸í˜œíƒ: {' / '.join(card['full_details'])} | ì¡°ê±´: {card['structured'].get('condition', '')}\"\n",
    "            final_docs.append(Document(\n",
    "                page_content=content, \n",
    "                metadata={\"total_score\": total_score, **card}\n",
    "            ))\n",
    "            \n",
    "        # 5. ìµœì¢… ì •ë ¬ (ì›ë³¸ Step 4 - 4ë‹¨ê³„)\n",
    "        return sorted(final_docs, key=lambda x: x.metadata['total_score'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c794649",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CardConciergeRAG:\n",
    "    def __init__(self, model_path, db_path, data_path):\n",
    "        self.embeddings = GemmaEmbeddings(model_path)\n",
    "        self.db_path = db_path\n",
    "        self.data_path = data_path\n",
    "        \n",
    "        self.card_map = self._setup_card_map()\n",
    "        self.vectorstore = Chroma(\n",
    "            collection_name=\"card_benefits\",  \n",
    "            persist_directory=db_path, \n",
    "            embedding_function=self.embeddings\n",
    "        )\n",
    "        \n",
    "        self._check_and_index()\n",
    "        self.chain = self._build_chain()\n",
    "\n",
    "    def _setup_card_map(self):\n",
    "        \"\"\"ë°ì´í„° ë³‘í•© ë° 'ë¦¬ìŠ¤íŠ¸ ì† ë¦¬ìŠ¤íŠ¸' ë°©ì§€ ë¡œì§ì´ ì ìš©ëœ ë§ˆìŠ¤í„° ë§µ ìƒì„±\"\"\"\n",
    "        with open(self.data_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        mapping = {}\n",
    "        for item in data:\n",
    "            meta = item['metadata']\n",
    "            c_id = str(meta['card_id'])\n",
    "            ai_s = item['ai_structured']\n",
    "            \n",
    "            if c_id not in mapping:\n",
    "                mapping[c_id] = {\n",
    "                    \"name\": meta['card_name'], \n",
    "                    \"corp\": meta['corp'],\n",
    "                    \"metadata\": meta, \n",
    "                    \"full_details\": [item['content']], \n",
    "                    \"structured\": {}\n",
    "                }\n",
    "                # ëª¨ë“  í•„ë“œ ì´ˆê¸°í™” (ë¦¬ìŠ¤íŠ¸ë¡œ í†µì¼)\n",
    "                for k, v in ai_s.items():\n",
    "                    if v and v != \"ì •ë³´ ì—†ìŒ\":\n",
    "                        mapping[c_id][\"structured\"][k] = list(v) if isinstance(v, list) else [v]\n",
    "                    else:\n",
    "                        mapping[c_id][\"structured\"][k] = []\n",
    "            else:\n",
    "                mapping[c_id][\"full_details\"].append(item['content'])\n",
    "                target_s = mapping[c_id][\"structured\"]\n",
    "                \n",
    "                for k, v in ai_s.items():\n",
    "                    if v and v != \"ì •ë³´ ì—†ìŒ\":\n",
    "                        if k not in target_s: target_s[k] = []\n",
    "                        if isinstance(v, list):\n",
    "                            # ì¤‘ë³µ ì œê±°í•˜ë©° ë³‘í•©\n",
    "                            target_s[k].extend([x for x in v if x not in target_s[k]])\n",
    "                        elif isinstance(v, dict):\n",
    "                            # ì‚¼ì„±ì¹´ë“œì™€ ê°™ì€ ë”•ì…”ë„ˆë¦¬ ë°ì´í„° ì²˜ë¦¬\n",
    "                            dict_str = \", \".join([f\"{key}: {val}\" for key, val in v.items()])\n",
    "                            if dict_str not in target_s[k]: target_s[k].append(dict_str)\n",
    "                        else:\n",
    "                            if v not in target_s[k]: target_s[k].append(v)\n",
    "        return mapping\n",
    "\n",
    "    def _check_and_index(self):\n",
    "        current_count = self.vectorstore._collection.count()\n",
    "        if current_count == 0:\n",
    "            print(\"ChromaDB ì¸ë±ì‹± ì‹œì‘...\")\n",
    "            with open(self.data_path, 'r', encoding='utf-8') as f:\n",
    "                master_data = json.load(f)\n",
    "            docs = []\n",
    "            for item in master_data:\n",
    "                metadata = item['metadata'].copy()\n",
    "                metadata['card_id'] = str(metadata['card_id'])\n",
    "                docs.append(Document(page_content=item['embedding_input'], metadata=metadata))\n",
    "            batch_size = 500\n",
    "            for i in range(0, len(docs), batch_size):\n",
    "                self.vectorstore.add_documents(docs[i : i + batch_size])\n",
    "            print(f\"ì¸ë±ì‹± ì™„ë£Œ. (ì´ {len(docs)}ê±´)\")\n",
    "        else:\n",
    "            print(f\"ê¸°ì¡´ DB ë¡œë“œ ì™„ë£Œ (ë°ì´í„°: {current_count}ê±´)\")\n",
    "\n",
    "    def _build_chain(self):\n",
    "        # 1. ì˜ë„ ì¶”ì¶œê¸° (ê°€ì´ë“œ ë° ì˜ˆì‹œ í¬í•¨)\n",
    "        intent_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "        ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬, ì¹´ë“œ í˜œíƒ ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰ì— ê°€ì¥ ì í•©í•œ 2~3ê°œì˜ ìƒì„¸ ê²€ìƒ‰ ë¬¸ì¥ì„ ìƒì„±í•´ì¤˜.\n",
    "        [ê°€ì´ë“œ]\n",
    "        - ë‹¨ìˆœí•œ í‚¤ì›Œë“œê°€ ì•„ë‹Œ, í˜œíƒì˜ ì¢…ë¥˜ì™€ ëŒ€í‘œ ë¸Œëœë“œê°€ í¬í•¨ëœ ì§§ì€ ë¬¸ì¥ìœ¼ë¡œ ë§Œë“œì„¸ìš”.\n",
    "        - ì˜ˆ: \"ì»¤í”¼ í• ì¸ë˜ê³  êµí†µë¹„ ì•„ë¼ëŠ” ì¹´ë“œ\" -> [\"ìŠ¤íƒ€ë²…ìŠ¤ íˆ¬ì¸ ë“± ì»¤í”¼ ì „ë¬¸ì  í• ì¸ í˜œíƒ\", \"ë²„ìŠ¤ ì§€í•˜ì²  íƒì‹œ ëŒ€ì¤‘êµí†µ ì´ìš© í• ì¸ í˜œíƒ\"]\n",
    "        \n",
    "        ì§ˆë¬¸: {question}\n",
    "        í˜•ì‹: [\"ë¬¸ì¥1\", \"ë¬¸ì¥2\"] (JSON ë¦¬ìŠ¤íŠ¸ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”)\n",
    "        \"\"\")\n",
    "        \n",
    "        intent_extractor = (\n",
    "            intent_prompt \n",
    "            | ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0.1, model_kwargs={\"top_p\": 0.9}) \n",
    "            | StrOutputParser()\n",
    "        )\n",
    "\n",
    "        base_retriever = CardANDRetriever(\n",
    "            vectorstore=self.vectorstore, card_map=self.card_map, \n",
    "            intent_extractor=intent_extractor, search_depth=200\n",
    "        )\n",
    "        \n",
    "        compressor = CohereRerank(model=\"rerank-v3.5\", top_n=3)\n",
    "        retriever = ContextualCompressionRetriever(base_compressor=compressor, base_retriever=base_retriever)\n",
    "\n",
    "        # 3. ë‹µë³€ ìƒì„± í”„ë¡¬í”„íŠ¸\n",
    "        prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "        ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ìµœê³ ì˜ 'ì‹ ìš©/ì²´í¬ì¹´ë“œ ì¶”ì²œ ì „ë¬¸ê°€, Gemma-Bot'ì…ë‹ˆë‹¤. \n",
    "        ì œê³µëœ [ì¹´ë“œ ë°ì´í„°]ë¥¼ ë¶„ì„í•˜ì—¬ ì§ˆë¬¸ì— ì „ë¬¸ì ì´ë©´ì„œë„ ë‹¤ì •í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.\n",
    "\n",
    "        ì‚¬ìš©ì ì§ˆë¬¸: {question}\n",
    "        [ì¹´ë“œ ë°ì´í„°]: {context}\n",
    "\n",
    "        [ë‹µë³€ ì‘ì„± ê°€ì´ë“œ]\n",
    "        1. **ì „ë¬¸ê°€ ì¸ì‚¬**: ì§ˆë¬¸ìì˜ ë‹ˆì¦ˆë¥¼ ë¶„ì„í–ˆìŒì„ ì–¸ê¸‰í•˜ë©° ë‹¤ì •í•˜ê²Œ ëŒ€í™”ë¥¼ ì‹œì‘í•˜ì„¸ìš”.\n",
    "        2. **Top 3 ëª©ë¡**: ì¶”ì²œ ìˆœì„œ(1~3ìœ„)ë¥¼ ì ˆëŒ€ ë°”ê¾¸ì§€ ë§ˆì„¸ìš”.\n",
    "        3. **ìƒì„¸ ë¶„ì„ ë° ë§í¬**: 1ìœ„ ì¹´ë“œì˜ í˜œíƒì„ ì•„ì£¼ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•˜ê³ , ëì— \"ğŸ”— [ì¹´ë“œ ìƒì„¸ì •ë³´ í™•ì¸í•˜ê¸°](ìƒì„¸ ë§í¬)\"ë¥¼ í¬í•¨í•˜ì„¸ìš”.\n",
    "        4. **ì¡°ì–¸**: ì œì™¸ í•­ëª©ê³¼ ì‹¤ì  ìœ ì˜ˆ ê¸°ê°„, ì¶”ê°€ ì•ˆë‚´ ì •ë³´(DCC, ì—°íšŒë¹„ ë“±)ë¥¼ ì°¸ê³ í•˜ì—¬ ì‹¤ì „ íŒì„ ì¡°ì–¸í•˜ì„¸ìš”.\n",
    "        5. **í†¤ì•¤ë§¤ë„ˆ**: í‘œ(Table) ê¸ˆì§€, ë¶ˆë › í¬ì¸íŠ¸ í™œìš©.\n",
    "        \"\"\")\n",
    "\n",
    "        # 4. ë°ì´í„° êµ¬ì¡°í™” í•¨ìˆ˜ (ìš”ì•½ + ì›ë¬¸ ì „ì²´ í†µí•© ë²„ì „)\n",
    "        def format_docs(docs):\n",
    "            formatted = []\n",
    "\n",
    "            for i, doc in enumerate(docs):\n",
    "                m = doc.metadata\n",
    "                s = m.get('structured', {})\n",
    "                raw_meta = m.get('metadata', {})\n",
    "                card_id = str(raw_meta.get('card_id')) # ID ì¶”ì¶œ\n",
    "                \n",
    "                # [í•µì‹¬] card_mapì—ì„œ í•´ë‹¹ IDì˜ ëª¨ë“  ì›ë¬¸(full_details)ì„ ê°€ì ¸ì™€ í•©ì¹©ë‹ˆë‹¤.\n",
    "                card_full_info = self.card_map.get(card_id, {})\n",
    "                # ë¦¬ìŠ¤íŠ¸ë¡œ ì €ì¥ëœ ì—¬ëŸ¬ ì¹´í…Œê³ ë¦¬ì˜ ì›ë¬¸ì„ ë¬¸ë‹¨ìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ í•©ì¹¨\n",
    "                all_raw_contents = \"\\n\\n\".join(card_full_info.get(\"full_details\", [\"ì›ë¬¸ ì •ë³´ ì—†ìŒ\"]))\n",
    "\n",
    "                # ë°©íƒ„ join ë¡œì§\n",
    "                def safe_join(data_list):\n",
    "                    if not data_list: return \"ì •ë³´ ì—†ìŒ\"\n",
    "                    flat = []\n",
    "                    for item in data_list:\n",
    "                        if isinstance(item, list): flat.extend([str(x) for x in item])\n",
    "                        else: flat.append(str(item))\n",
    "                    return \", \".join(dict.fromkeys(flat))\n",
    "\n",
    "                # ì¹´ë“œê³ ë¦´ë¼ ë§í¬\n",
    "                card_link = f\"https://www.card-gorilla.com/card/detail/{card_id}\" if card_id != 'None' else \"ë§í¬ ì—†ìŒ\"\n",
    "\n",
    "                # LLMì— ì£¼ì…ë  ì´ˆì •ë°€ ì»¨í…ìŠ¤íŠ¸\n",
    "                info = (\n",
    "                    f\"### [ì¶”ì²œ ìˆœìœ„ {i+1}ìœ„] {m.get('name')} ({m.get('corp')})\\n\"\n",
    "                    f\"- ì—°íšŒë¹„: {raw_meta.get('annual_fee', 'ì •ë³´ ì—†ìŒ')}\\n\"\n",
    "                    f\"- ì „ì›” ì‹¤ì  ê¸°ì¤€: {raw_meta.get('min_performance', 'ì •ë³´ ì—†ìŒ')}ì› ì´ìƒ\\n\"\n",
    "                    f\"- ìƒì„¸ ë§í¬: {card_link}\\n\"\n",
    "                    f\"\\n  [A. í•µì‹¬ ìš”ì•½ ë°ì´í„°]\\n\"\n",
    "                    f\"  â–¶ í†µí•© ìš”ì•½: {safe_join(s.get('summary'))}\\n\"\n",
    "                    f\"  â–¶ ê°€ë§¹ì  ëª©ë¡: {safe_join(s.get('merchants'))}\\n\"\n",
    "                    f\"  â–¶ ì‹¤ì  ìœ ì˜ˆ/ì¡°ê±´: {safe_join(s.get('grace_period'))} / {safe_join(s.get('payment_conditions'))}\\n\"\n",
    "                    f\"  â–¶ ì œì™¸ í•­ëª©(í˜œíƒ/ì‹¤ì ): {safe_join(s.get('benefit_exclusions'))} / {safe_join(s.get('performance_exclusions'))}\\n\"\n",
    "                    f\"  â–¶ ê¸°íƒ€ ê³ ìœ  ì •ë³´: {safe_join(s.get('additional_info'))}\\n\"\n",
    "                    f\"\\n  [B. ì¹´ë“œ í˜œíƒ ë°ì´í„° ì›ë¬¸ ì „ì²´]\\n\"\n",
    "                    f\"{all_raw_contents}\\n\" \n",
    "                    f\"==================================================\\n\"\n",
    "                )\n",
    "                \n",
    "                # print(f\"\\nâœ… {i+1}ìœ„ ì¹´ë“œ ë°ì´í„° í†µí•© ê²°ê³¼:\")\n",
    "                # print(info)\n",
    "                # print(\"-\" * 80)\n",
    "                \n",
    "                formatted.append(info)\n",
    "            \n",
    "            return \"\\n\\n\".join(formatted)\n",
    "\n",
    "        return (\n",
    "            {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "            | prompt \n",
    "            | ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0.1, model_kwargs={\"top_p\": 0.1}, max_tokens=1500) \n",
    "            | StrOutputParser()\n",
    "        )\n",
    "\n",
    "    def ask(self, query):\n",
    "        return self.chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a6d28131",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer you are loading from './models/gemma-300m-4080super-extreme' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê¸°ì¡´ DB ë¡œë“œ ì™„ë£Œ (ë°ì´í„°: 7757ê±´)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeon\\AppData\\Local\\Temp\\ipykernel_28604\\533101141.py:1: UserWarning: Parameters {'top_p'} should be specified explicitly. Instead they were passed in as part of `model_kwargs` parameter.\n",
      "  concierge = CardConciergeRAG(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ ì¶”ì¶œëœ í‚¤ì›Œë“œ: ['ë°°ë‹¬ì˜ë¯¼ì¡± ìš”ê¸°ìš” ì¿ íŒ¡ì´ì¸  ë°°ë‹¬ ìŒì‹ í• ì¸ í˜œíƒ', 'ë„·í”Œë¦­ìŠ¤ ë””ì¦ˆë‹ˆí”ŒëŸ¬ìŠ¤ ì™“ì±  OTT ìŠ¤íŠ¸ë¦¬ë° í• ì¸ í˜œíƒ']\n",
      "ì•ˆë…•í•˜ì„¸ìš”! ì‚¬íšŒì´ˆë…„ìƒìœ¼ë¡œì„œ ë°°ë‹¬ ìŒì‹ í• ì¸ê³¼ OTT ìŠ¤íŠ¸ë¦¬ë° í• ì¸ í˜œíƒì„ ì›í•˜ì‹œëŠ” ì , ê¼¼ê¼¼íˆ ë¶„ì„í•´ ë³´ì•˜ìŠµë‹ˆë‹¤. ìƒí™œë¹„ ì ˆì•½ê³¼ ì¦ê±°ìš´ ì½˜í…ì¸  ì†Œë¹„ë¥¼ ë™ì‹œì— ì±™ê¸¸ ìˆ˜ ìˆëŠ” ì¹´ë“œ ì¶”ì²œì„ ë“œë¦´ê²Œìš”. ğŸ˜Š\n",
      "\n",
      "---\n",
      "\n",
      "### 1ìœ„. ì‚¼ì„± iD SELECT ALL ì¹´ë“œ (ì‚¼ì„±ì¹´ë“œ)\n",
      "\n",
      "- **ë°°ë‹¬ì•± í• ì¸**: ë°°ë‹¬ì˜ë¯¼ì¡±, ìš”ê¸°ìš”, ì¿ íŒ¡ì´ì¸  ë“± ë°°ë‹¬ì•±ì—ì„œ 7% í• ì¸ (ì „ì›” ì‹¤ì  40ë§Œì› ì´ìƒ ì‹œ, ì›” ìµœëŒ€ 7,000~15,000ì› í• ì¸)\n",
      "- **OTT ìŠ¤íŠ¸ë¦¬ë° í• ì¸**: ë„·í”Œë¦­ìŠ¤, ë””ì¦ˆë‹ˆ+, ìœ íŠœë¸Œ í”„ë¦¬ë¯¸ì—„, í‹°ë¹™ ë“± ë””ì§€í„¸ ì½˜í…ì¸  ì •ê¸°ê²°ì œ ì‹œ 50% í• ì¸ (ì›” ìµœëŒ€ 5,000ì› í• ì¸)\n",
      "- **ìƒí™œ í¸ì˜ í• ì¸**: ìƒí™œì¡í™”, ê³µì—°, ì„œì  ë“±ì—ì„œ 5% í• ì¸\n",
      "- **ì „ì›” ì‹¤ì **: 40ë§Œì› ì´ìƒ (ë°œê¸‰ì›”+1ê°œì›”ì€ ì‹¤ì  ë¯¸ë‹¬ ì‹œì—ë„ í˜œíƒ ì œê³µ)\n",
      "- **ì—°íšŒë¹„**: 20,000ì› (êµ­ë‚´ì „ìš©/í•´ì™¸ê²¸ìš© ë™ì¼)\n",
      "- **ê¸°íƒ€**: í•´ì™¸ ê°€ë§¹ì  ë° í•´ì™¸ ì§ì ‘êµ¬ë§¤ ì‹œ 2% í• ì¸, ë§¤ì›” ëª¨ë‹ˆëª¨ ì•±ì´ë‚˜ ì‚¼ì„±ì¹´ë“œ í™ˆí˜ì´ì§€ì—ì„œ í• ì¸ ì˜µì…˜ ë³€ê²½ ê°€ëŠ¥\n",
      "\n",
      "ğŸ”— [ì¹´ë“œ ìƒì„¸ì •ë³´ í™•ì¸í•˜ê¸°](https://www.card-gorilla.com/card/detail/2885)\n",
      "\n",
      "---\n",
      "\n",
      "### 2ìœ„. ì›ë”ì¹´ë“œ 2.0 DAILY (í•˜ë‚˜ì¹´ë“œ)\n",
      "\n",
      "- **ë°°ë‹¬ì•± í• ì¸**: ë°°ë‹¬ì˜ë¯¼ì¡±, ìš”ê¸°ìš”, ì¿ íŒ¡ì´ì¸  10% í• ì¸ (ì „ì›” ì‹¤ì  40ë§Œì› ì´ìƒ, ì›” ìµœëŒ€ 4,000~10,000ì›)\n",
      "- **OTT ìŠ¤íŠ¸ë¦¬ë° í• ì¸**: ë„·í”Œë¦­ìŠ¤, ë””ì¦ˆë‹ˆí”ŒëŸ¬ìŠ¤, Wavve, ìœ íŠœë¸Œí”„ë¦¬ë¯¸ì—„ 40% í• ì¸ (ì›” ìµœëŒ€ 8,000~15,000ì›)\n",
      "- **ê¸°íƒ€ í• ì¸**: íƒì‹œ, ëŒ€ì¤‘êµí†µ, í¸ì˜ì , ì˜¨ë¼ì¸ì‹í’ˆ ë“± ë‹¤ì–‘í•œ ìƒí™œ í• ì¸ í¬í•¨\n",
      "- **ì „ì›” ì‹¤ì **: 40ë§Œì› ì´ìƒ\n",
      "- **ì—°íšŒë¹„**: 19,900ì› (êµ­ë‚´ì „ìš©/í•´ì™¸ê²¸ìš© ë™ì¼)\n",
      "- **ìœ ì˜ì‚¬í•­**: ê³µì‹ í™ˆí˜ì´ì§€/ì•± ê²°ì œ ê±´ì— í•œí•˜ë©°, ìŒì‹ì  ì§ì ‘ ê²°ì œë‚˜ ê°„í¸ê²°ì œ, ì•±ìŠ¤í† ì–´ ê²°ì œëŠ” ì œì™¸\n",
      "\n",
      "ğŸ”— [ì¹´ë“œ ìƒì„¸ì •ë³´ í™•ì¸í•˜ê¸°](https://www.card-gorilla.com/card/detail/2445)\n",
      "\n",
      "---\n",
      "\n",
      "### 3ìœ„. ì‚¼ì„± iD SELECT ON ì¹´ë“œ (ì‚¼ì„±ì¹´ë“œ)\n",
      "\n",
      "- **ë°°ë‹¬ì•± í• ì¸**: ë°°ë‹¬ì˜ë¯¼ì¡±, ì¿ íŒ¡ì´ì¸ , ìš”ê¸°ìš” 5% í• ì¸ (ì „ì›” ì‹¤ì  30ë§Œì› ì´ìƒ, ì›” ìµœëŒ€ 5,000ì›)\n",
      "- **OTT ìŠ¤íŠ¸ë¦¬ë° í• ì¸**: ë„·í”Œë¦­ìŠ¤, ë””ì¦ˆë‹ˆ+, ìœ íŠœë¸Œ, í‹°ë¹™ ì¸ì•± ê²°ì œ í¬í•¨ 50% í• ì¸ (ì›” ìµœëŒ€ 5,000~10,000ì›)\n",
      "- **ì™¸ì‹ ë° ì‡¼í•‘ í• ì¸**: ê¸ˆ~ì¼ìš”ì¼ ì™¸ì‹ 10% í• ì¸, ì˜¨ë¼ì¸ ì‡¼í•‘ëª° 5~10% í• ì¸\n",
      "- **ì „ì›” ì‹¤ì **: 30ë§Œì› ì´ìƒ (ë°œê¸‰ì›”+1ê°œì›” ì‹¤ì  ë¯¸ë‹¬ ì‹œì—ë„ í˜œíƒ ì œê³µ)\n",
      "- **ì—°íšŒë¹„**: 20,000ì› (êµ­ë‚´ì „ìš©/í•´ì™¸ê²¸ìš© ë™ì¼)\n",
      "\n",
      "ğŸ”— [ì¹´ë“œ ìƒì„¸ì •ë³´ í™•ì¸í•˜ê¸°](https://www.card-gorilla.com/card/detail/2886)\n",
      "\n",
      "---\n",
      "\n",
      "### ë¹„ì„œì˜ ë‚ ì¹´ë¡œìš´ ì¡°ì–¸\n",
      "\n",
      "- **ì‹¤ì  ìœ ì˜ˆ ê¸°ê°„ í™œìš©**: ì‚¼ì„± iD SELECT ALLê³¼ ON ì¹´ë“œëŠ” ë°œê¸‰ì›”+1ê°œì›” ë™ì•ˆ ì „ì›” ì‹¤ì  30~40ë§Œì› ë¯¸ë§Œì´ì–´ë„ í˜œíƒì´ ì œê³µë˜ë‹ˆ, ì²˜ìŒ ì¹´ë“œ ì‚¬ìš© ì‹œ ë¶€ë‹´ì„ ì¤„ì¼ ìˆ˜ ìˆì–´ìš”.\n",
      "- **ë°°ë‹¬ì•± í• ì¸ ì¡°ê±´**: ë°°ë‹¬ì•± í• ì¸ì€ ê³µì‹ ì•±/í™ˆí˜ì´ì§€ ê²°ì œì— í•œì •ë˜ë©°, ê°€ë§¹ì  ì§ì ‘ ê²°ì œë‚˜ ê°„í¸ê²°ì œ(ì‚¼ì„±ì¹´ë“œ ì œì™¸)ëŠ” ì œì™¸ë˜ëŠ” ê²½ìš°ê°€ ë§ìœ¼ë‹ˆ ê²°ì œ ë°©ë²•ì„ ê¼­ í™•ì¸í•˜ì„¸ìš”.\n",
      "- **OTT í• ì¸ í•œë„**: OTT í• ì¸ì€ ì›” ìµœëŒ€ 5,000~15,000ì›ìœ¼ë¡œ, ë„‰ë„‰í•œ í• ì¸ í•œë„ë¥¼ ê°€ì§„ ì›ë”ì¹´ë“œ 2.0 DAILYê°€ ìŠ¤íŠ¸ë¦¬ë° ì´ìš©ì´ ë§ë‹¤ë©´ ë§¤ë ¥ì ì…ë‹ˆë‹¤.\n",
      "- **ì—°íšŒë¹„ì™€ í˜œíƒ ê· í˜•**: ì—°íšŒë¹„ëŠ” 2ë§Œì› ë‚´ì™¸ë¡œ ë¹„ìŠ·í•˜ë‹ˆ, ë³¸ì¸ì˜ ì›” ì¹´ë“œ ì‚¬ìš© íŒ¨í„´ê³¼ í• ì¸ í•œë„, ì‹¤ì  ì¡°ê±´ì„ ê³ ë ¤í•´ ì„ íƒí•˜ì„¸ìš”.\n",
      "- **í•´ì™¸ ì´ìš© ì‹œ DCC ìˆ˜ìˆ˜ë£Œ ì£¼ì˜**: í•´ì™¸ ê²°ì œ ì‹œ ì›í™” ê²°ì œ(DCC) ìˆ˜ìˆ˜ë£Œê°€ ë¶™ì„ ìˆ˜ ìˆìœ¼ë‹ˆ, í•´ì™¸ ì´ìš©ì´ ì¦ë‹¤ë©´ í•´ì™¸ê²¸ìš© ì¹´ë“œ ë°œê¸‰ í›„ DCC ì°¨ë‹¨ ì„¤ì •ì„ ê¶Œì¥í•©ë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "ì‚¬íšŒì´ˆë…„ìƒ ì‹œì ˆì€ ì§€ì¶œ ê´€ë¦¬ê°€ ì¤‘ìš”í•œ ë§Œí¼, ë³¸ì¸ì˜ ì†Œë¹„ íŒ¨í„´ì— ë§ëŠ” ì¹´ë“œë¥¼ ì˜ ì„ íƒí•˜ì…”ì„œ ì•Œëœ°í•˜ê²Œ í˜œíƒ ì±™ê¸°ì‹œê¸¸ ì‘ì›í•©ë‹ˆë‹¤! ê¶ê¸ˆí•œ ì  ìˆìœ¼ë©´ ì–¸ì œë“  ë§ì”€í•´ ì£¼ì„¸ìš”. ğŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "concierge = CardConciergeRAG(\n",
    "    model_path='./models/gemma-300m-4080super-extreme',\n",
    "    db_path='./data/chroma_db',\n",
    "    data_path='./data/FINAL_MASTER_DATA_FIXED_7757.json'\n",
    ")\n",
    "\n",
    "print(concierge.ask(\"ì‚¬íšŒì´ˆë…„ìƒì¸ë° ë°°ë‹¬ì˜ë¯¼ì¡± ìš”ê¸°ìš” ì¿ íŒ¡ì´ì¸  ë°°ë‹¬ ìŒì‹ í• ì¸ í˜œíƒì´ ìˆê³ , ë„·í”Œë¦­ìŠ¤ ë””ì¦ˆë‹ˆí”ŒëŸ¬ìŠ¤ ì™“ì±  OTT ìŠ¤íŠ¸ë¦¬ë° í• ì¸ í˜œíƒë„ ìˆëŠ” ì¹´ë“œë¥¼ ì¶”ì²œí•´ì¤˜\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b39c51a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting card_chatbot.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile card_chatbot.py\n",
    "\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "from typing import List, Any, Dict\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "from openai import OpenAI\n",
    "import cohere\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "\n",
    "# LangChain ê´€ë ¨\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_cohere import CohereRerank\n",
    "\n",
    "# íŒ¨í‚¤ì§€ ê²½ë¡œ ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•œ ì²˜ë¦¬\n",
    "try:\n",
    "    from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
    "except ImportError:\n",
    "    from langchain.retrievers import ContextualCompressionRetriever\n",
    "\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "\n",
    "# 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "# ==========================================\n",
    "# [CUSTOM CLASS] 1. ì„ë² ë”© ë° ë¦¬íŠ¸ë¦¬ë²„ ì„¤ì •\n",
    "# ==========================================\n",
    "\n",
    "class GemmaEmbeddings:\n",
    "    \"\"\"Gemma-300m ì „ìš© ì„ë² ë”© í´ë˜ìŠ¤\"\"\"\n",
    "    def __init__(self, model_path: str):\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.model = SentenceTransformer(model_path, device=device)\n",
    "        \n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        return self.model.encode([f\"title: none | text: {text}\" for text in texts]).tolist()\n",
    "    \n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        return self.model.encode(f\"task: search result | query: {text}\").tolist()\n",
    "\n",
    "class CardANDRetriever(BaseRetriever):\n",
    "    \"\"\"ë©€í‹° ì˜ë„ êµì§‘í•©(AND) ê²€ìƒ‰ ë° ì „ì²´ ë°ì´í„° ë³µì› ë¦¬íŠ¸ë¦¬ë²„\"\"\"\n",
    "    vectorstore: Any\n",
    "    card_map: Dict\n",
    "    intent_extractor: Any\n",
    "    search_depth: int = 200\n",
    "\n",
    "    def _get_relevant_documents(self, query: str) -> List[Document]:\n",
    "        # 1. ì˜ë„ ì¶”ì¶œ (LLM í™œìš©)\n",
    "        keywords_json = self.intent_extractor.invoke({\"question\": query})\n",
    "        try:\n",
    "            search_intents = json.loads(keywords_json.replace(\"```json\", \"\").replace(\"```\", \"\"))\n",
    "        except:\n",
    "            search_intents = [query]\n",
    "        \n",
    "        # 2. ê° ì˜ë„ë³„ ê²€ìƒ‰ ìˆ˜í–‰\n",
    "        intent_scores = []\n",
    "        for intent in search_intents:\n",
    "            results = self.vectorstore.similarity_search_with_relevance_scores(intent, k=self.search_depth)\n",
    "            current_hits = {str(doc.metadata['card_id']): score for doc, score in results}\n",
    "            intent_scores.append(current_hits)\n",
    "\n",
    "        # 3. êµì§‘í•©(AND) í•„í„°ë§\n",
    "        common_ids = set(intent_scores[0].keys())\n",
    "        for hits in intent_scores[1:]:\n",
    "            common_ids &= set(hits.keys())\n",
    "        \n",
    "        if not common_ids:\n",
    "            common_ids = set(list(intent_scores[0].keys())[:20])\n",
    "\n",
    "        # 4. ì „ì²´ ë°ì´í„° ë³µì› (ê²€ìƒ‰ì€ idxë¡œ, ë‹µë³€ ë°ì´í„°ëŠ” ì›ë³¸ ì „ì²´ë¡œ)\n",
    "        final_docs = []\n",
    "        for c_id in common_ids:\n",
    "            total_score = sum(intent_map[c_id] for intent_map in intent_scores if c_id in intent_map)\n",
    "            card = self.card_map.get(c_id) # ì—¬ê¸°ì„œ ëª¨ë“  ì •ë³´ê°€ ë‹´ê¸´ Dictë¥¼ ê°€ì ¸ì˜´\n",
    "            if not card: continue\n",
    "            \n",
    "            # LLMì—ê²Œ ì „ë‹¬í•  í’ë¶€í•œ ì»¨í…ìŠ¤íŠ¸ ìƒì„±\n",
    "            # ì—¬ëŸ¬ ì¹´í…Œê³ ë¦¬ì˜ contentë¥¼ í•©ì³ì„œ ì „ë‹¬\n",
    "            full_benefits = \" / \".join(card['full_details'])\n",
    "            \n",
    "            final_docs.append(Document(\n",
    "                page_content=full_benefits,\n",
    "                metadata={\n",
    "                    \"total_score\": total_score,\n",
    "                    \"card_id\": c_id,\n",
    "                    \"name\": card['name'],\n",
    "                    \"corp\": card['corp'],\n",
    "                    \"annual_fee\": card['metadata'].get('annual_fee'),\n",
    "                    \"min_performance\": card['metadata'].get('min_performance'),\n",
    "                    \"structured\": card['structured'] # ai_structured ì „ì²´ í¬í•¨\n",
    "                }\n",
    "            ))\n",
    "            \n",
    "        return sorted(final_docs, key=lambda x: x.metadata['total_score'], reverse=True)\n",
    "\n",
    "# ==========================================\n",
    "# [CORE] 2. ë©”ì¸ RAG í´ë˜ìŠ¤\n",
    "# ==========================================\n",
    "\n",
    "class CardConciergeRAG:\n",
    "    def __init__(self, model_path, db_path, data_path):\n",
    "        self.embeddings = GemmaEmbeddings(model_path)\n",
    "        self.data_path = data_path\n",
    "        \n",
    "        self.card_map = self._setup_card_map()\n",
    "        self.vectorstore = Chroma(\n",
    "            collection_name=\"card_benefits\",  \n",
    "            persist_directory=db_path, \n",
    "            embedding_function=self.embeddings\n",
    "        )\n",
    "        self.chain = self._build_chain()\n",
    "\n",
    "    def _setup_card_map(self):\n",
    "        \"\"\"ì›ë³¸ JSONì„ ID ê¸°ë°˜ìœ¼ë¡œ ë§µí•‘ (ëª¨ë“  ì¹´í…Œê³ ë¦¬ ì •ë³´ í†µí•©)\"\"\"\n",
    "        with open(self.data_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        mapping = {}\n",
    "        for item in data:\n",
    "            c_id = str(item['metadata']['card_id'])\n",
    "            if c_id not in mapping:\n",
    "                mapping[c_id] = {\n",
    "                    \"name\": item['metadata']['card_name'], \n",
    "                    \"corp\": item['metadata']['corp'],\n",
    "                    \"metadata\": item['metadata'],\n",
    "                    \"full_details\": [item['content']], \n",
    "                    \"structured\": item['ai_structured']\n",
    "                }\n",
    "            else:\n",
    "                mapping[c_id][\"full_details\"].append(item['content'])\n",
    "        return mapping\n",
    "\n",
    "    def _build_chain(self):\n",
    "        # ì˜ë„ ì¶”ì¶œê¸°\n",
    "        intent_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "        ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì¹´ë“œ ê²€ìƒ‰ì— ê°€ì¥ ì í•©í•œ 2~3ê°œì˜ ê²€ìƒ‰ ë¬¸ì¥ì„ ìƒì„±í•˜ì„¸ìš”.\n",
    "        í˜•ì‹: [\"ë¬¸ì¥1\", \"ë¬¸ì¥2\"] (JSON ë¦¬ìŠ¤íŠ¸ë¡œë§Œ ì‘ë‹µ)\n",
    "        ì§ˆë¬¸: {question}\n",
    "        \"\"\")\n",
    "        intent_extractor = (\n",
    "            intent_prompt \n",
    "            | ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0.1, model_kwargs={\"top_p\": 0.9}) \n",
    "            | StrOutputParser()\n",
    "        )\n",
    "\n",
    "        # ë¦¬íŠ¸ë¦¬ë²„ + ë¦¬ë­ì»¤\n",
    "        base_retriever = CardANDRetriever(\n",
    "            vectorstore=self.vectorstore, \n",
    "            card_map=self.card_map, \n",
    "            intent_extractor=intent_extractor,\n",
    "            search_depth=200\n",
    "        )\n",
    "        compressor = CohereRerank(model=\"rerank-v3.5\", top_n=3)\n",
    "        retriever = ContextualCompressionRetriever(base_compressor=compressor, base_retriever=base_retriever)\n",
    "\n",
    "        # ìµœì¢… ë‹µë³€ í”„ë¡¬í”„íŠ¸ (ì „ë¬¸ê°€ í˜ë¥´ì†Œë‚˜)\n",
    "        prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "        ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ìµœê³ ì˜ 'ì‹ ìš©/ì²´í¬ì¹´ë“œ ì¶”ì²œ ì „ë¬¸ê°€, Gemma-Bot'ì…ë‹ˆë‹¤. \n",
    "        ì œê³µëœ [ì¹´ë“œ ë°ì´í„°]ë¥¼ ë¶„ì„í•˜ì—¬ ì „ë¬¸ì ì´ë©´ì„œë„ ë‹¤ì •í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.\n",
    "\n",
    "        ì‚¬ìš©ì ì§ˆë¬¸: {question}\n",
    "        [ì¹´ë“œ ë°ì´í„°]: {context}\n",
    "\n",
    "        [ë‹µë³€ ì‘ì„± ê°€ì´ë“œ]\n",
    "        1. **ì „ë¬¸ê°€ ì¸ì‚¬**: ì†Œë¹„ ë‹ˆì¦ˆë¥¼ ì •í™•íˆ ë¶„ì„í–ˆìŒì„ ì•Œë¦¬ë©° ì‹ ë¢°ê° ìˆê²Œ ì‹œì‘í•˜ì„¸ìš”.\n",
    "        2. **ìˆœìœ„ ê³ ìˆ˜**: Top 1, 2, 3 ìˆœì„œë¥¼ ì ˆëŒ€ ë°”ê¾¸ì§€ ë§ˆì„¸ìš”.\n",
    "        3. **ìƒì„¸ ë¶„ì„**: 1ìœ„ ì¹´ë“œì˜ í˜œíƒ(ìˆ˜ì¹˜, í•œë„, ì‹¤ì )ì„ êµ¬ì²´ì ì¸ ì˜ˆì‹œì™€ í•¨ê»˜ ìƒì„¸íˆ ì„¤ëª…í•˜ì„¸ìš”.\n",
    "           ë¶„ì„ ë§ˆì§€ë§‰ì—ëŠ” \"ğŸ”— [ì¹´ë“œ ìƒì„¸ì •ë³´ í™•ì¸í•˜ê¸°](ìƒì„¸ ë§í¬)\"ë¥¼ í¬í•¨í•˜ì„¸ìš”.\n",
    "        4. **ë¹„ì„œì˜ ì¡°ì–¸**: í˜œíƒ ì œì™¸ í•­ëª©(benefit_exclusions)ê³¼ ì‹¤ì  ì œì™¸ í•­ëª©(performance_exclusions)ì„ ì°¸ê³ í•˜ì—¬ ì£¼ì˜ì‚¬í•­ì„ ì˜ˆë¦¬í•˜ê²Œ ì¡°ì–¸í•˜ì„¸ìš”.\n",
    "        5. **í†¤ì•¤ë§¤ë„ˆ**: í‘œ(Table) ì‚¬ìš© ê¸ˆì§€, ë¶ˆë › í¬ì¸íŠ¸ í™œìš©, ë‹µë³€ì€ í•µì‹¬ ìœ„ì£¼ë¡œ ëª…í™•í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.\n",
    "        \"\"\")\n",
    "\n",
    "        # ë°ì´í„° êµ¬ì¡°í™” í•¨ìˆ˜ (ê²€ìƒ‰ ê²°ê³¼ -> LLMìš© í…ìŠ¤íŠ¸)\n",
    "        def format_docs(docs):\n",
    "            formatted = []\n",
    "            for i, doc in enumerate(docs):\n",
    "                m = doc.metadata\n",
    "                s = m.get('structured', {})\n",
    "                info = (\n",
    "                    f\"### [ì¶”ì²œ ìˆœìœ„ {i+1}ìœ„] {m.get('name')} ({m.get('corp')})\\n\"\n",
    "                    f\"- ì—°íšŒë¹„: {m.get('annual_fee', 'ì •ë³´ ì—†ìŒ')}\\n\"\n",
    "                    f\"- ì „ì›” ì‹¤ì  ê¸°ì¤€: {m.get('min_performance', 'ì •ë³´ ì—†ìŒ')}ì›\\n\"\n",
    "                    f\"- ìƒì„¸ ë§í¬: https://www.card-gorilla.com/card/detail/{m.get('card_id')}\\n\"\n",
    "                    f\"- í˜œíƒ ìš”ì•½: {s.get('summary', 'ì •ë³´ ì—†ìŒ')}\\n\"\n",
    "                    f\"- í˜œíƒ ì œì™¸: {', '.join(s.get('benefit_exclusions', ['ì •ë³´ ì—†ìŒ']))}\\n\"\n",
    "                    f\"- ì‹¤ì  ì œì™¸: {', '.join(s.get('performance_exclusions', ['ì •ë³´ ì—†ìŒ']))}\\n\"\n",
    "                    f\"- ì¶”ê°€ ì •ë³´: {s.get('additional_info', 'ì •ë³´ ì—†ìŒ')}\\n\"\n",
    "                    f\"- ìƒì„¸ í˜œíƒ ë°ì´í„°: {doc.page_content}\\n\"\n",
    "                )\n",
    "                formatted.append(info)\n",
    "            return \"\\n\\n\".join(formatted)\n",
    "\n",
    "        return (\n",
    "            {\n",
    "                \"context\": retriever | format_docs, \n",
    "                \"question\": RunnablePassthrough()\n",
    "            }\n",
    "            | prompt \n",
    "            | ChatOpenAI(\n",
    "                model=\"gpt-4.1-mini\", \n",
    "                temperature=0.1, \n",
    "                model_kwargs={\"top_p\": 0.1},\n",
    "                max_tokens=1500\n",
    "            ) \n",
    "            | StrOutputParser()\n",
    "        )\n",
    "\n",
    "    def ask(self, query):\n",
    "        return self.chain.invoke(query)\n",
    "\n",
    "# ==========================================\n",
    "# [CLI] 3. CMD ì¸í„°í˜ì´ìŠ¤\n",
    "# ==========================================\n",
    "\n",
    "def run_chatbot():\n",
    "    print(\"\\nğŸš€ ì¹´ë“œ ì¶”ì²œ ì „ë¬¸ê°€ Gemma-Bot ì‹œìŠ¤í…œ ê°€ë™ ì¤‘...\")\n",
    "    \n",
    "    try:\n",
    "        concierge = CardConciergeRAG(\n",
    "            model_path='./models/gemma-300m-4080super-extreme',\n",
    "            db_path='./data/chroma_db',\n",
    "            data_path='./data/FINAL_MASTER_DATA_FIXED_7757.json'\n",
    "        )\n",
    "        print(\"âœ… ìƒë‹´ ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"   ğŸ’³ ëŒ€í•œë¯¼êµ­ ìµœê³ ì˜ ì¹´ë“œ ì¶”ì²œ ì „ë¬¸ê°€, Gemma-Bot   \")\n",
    "    print(\"      (ì¢…ë£Œí•˜ì‹œë ¤ë©´ 'ì¢…ë£Œ' ë˜ëŠ” 'q'ë¥¼ ì…ë ¥í•˜ì„¸ìš”)      \")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"\\n[ğŸ‘¤ ì§ˆë¬¸]: \").strip()\n",
    "        if user_input.lower() in ['ì¢…ë£Œ', 'q', 'exit']: break\n",
    "        if not user_input: continue\n",
    "\n",
    "        print(\"\\n[ğŸ¤– Gemma-Bot]: ìµœì ì˜ ì¹´ë“œë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...\", end=\"\", flush=True)\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            response = concierge.ask(user_input)\n",
    "            print(f\"\\r[ğŸ¤– Gemma-Bot] ({time.time() - start_time:.2f}ì´ˆ):\")\n",
    "            print(\"-\" * 60 + \"\\n\" + response + \"\\n\" + \"-\" * 60)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nâŒ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_chatbot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sesac-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
