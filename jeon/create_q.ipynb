{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44aeee11",
   "metadata": {},
   "source": [
    "# ëª¨ë¸ë§ì„ ìœ„í•œ ì§ˆë¬¸ ìƒì„± ì½”ë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9503f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7edf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import time\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 1. ëª¨ë¸ ì„¤ì • (ê°€ì„±ë¹„ ì¢‹ì€ gpt-5-nano í™œìš©)\n",
    "llm = ChatOpenAI(model=\"gpt-5-nano\", temperature=0.7)\n",
    "\n",
    "def generate_triplet_dataset(input_file, output_file, num_samples=10):\n",
    "    # ë°ì´í„° ë¡œë“œ\n",
    "    try:\n",
    "        with open(input_file, 'r', encoding='utf-8') as f:\n",
    "            all_benefits = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_file}\")\n",
    "        return\n",
    "\n",
    "    # í”„ë¡¬í”„íŠ¸ ì„¤ì •: í˜ë¥´ì†Œë‚˜ê°€ ë‹´ê¸´ ìì—°ìŠ¤ëŸ¬ìš´ êµ¬ì–´ì²´ ì§ˆë¬¸ ìœ ë„\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"ë‹¹ì‹ ì€ ê¸ˆìœµ ë„ë©”ì¸ íŠ¹í™” ë°ì´í„° ì—”ì§€ë‹ˆì–´ì…ë‹ˆë‹¤.\"),\n",
    "        (\"user\", \"\"\"ì•„ë˜ [í˜œíƒ ì •ë³´]ë¥¼ ë³´ê³ , ì´ í˜œíƒì„ í•„ìš”ë¡œ í•˜ëŠ” ì‚¬ìš©ìê°€ ë˜ì§ˆ ë²•í•œ ì•„ì£¼ ìì—°ìŠ¤ëŸ¬ìš´ ì§ˆë¬¸ 1ê°œë¥¼ ìƒì„±í•˜ì„¸ìš”.\n",
    "\n",
    "[í˜œíƒ ì •ë³´]: {benefit_content}\n",
    "\n",
    "ì¡°ê±´:\n",
    "1. ì§ˆë¬¸(anchor)ì€ \"~ì‚´ì´ê³  ~í•˜ëŠ” ìƒí™©ì¸ë°\"ì™€ ê°™ì´ êµ¬ì²´ì ì¸ ìƒí™©ê³¼ í˜ë¥´ì†Œë‚˜ê°€ ëŠê»´ì ¸ì•¼ í•©ë‹ˆë‹¤.\n",
    "2. ì§ˆë¬¸ì€ ì¹´ë“œ ì´ë¦„ì´ë‚˜ ìƒí’ˆëª…ì„ ì§ì ‘ ì–¸ê¸‰í•˜ì§€ ë§ê³ , 'í˜œíƒì˜ í•„ìš”ì„±'ì— ì§‘ì¤‘í•˜ì„¸ìš”.\n",
    "3. ê²°ê³¼ëŠ” ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”.\n",
    "{{\n",
    "    \"anchor\": \"ìƒì„±ëœ êµ¬ì–´ì²´ ì§ˆë¬¸\",\n",
    "    \"positive\": \"ì œê³µëœ í˜œíƒ ì •ë³´ ë¬¸êµ¬ ê·¸ëŒ€ë¡œ ìœ ì§€\"\n",
    "}}\n",
    "\"\"\")\n",
    "    ])\n",
    "\n",
    "    dataset = []\n",
    "    \n",
    "    # í•™ìŠµ ë°ì´í„° ìƒì„±ì„ ìœ„í•œ ìƒ˜í”Œë§ (í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ num_samplesë§Œí¼ ì§„í–‰)\n",
    "    selected_benefits = all_benefits[:num_samples]\n",
    "    print(f\"ğŸš€ ì´ {len(selected_benefits)}ê±´ì˜ í˜œíƒì— ëŒ€í•´ ì§ˆë¬¸ ìƒì„± ë° ë°ì´í„°ì…‹ êµ¬ì¶• ì‹œì‘...\")\n",
    "\n",
    "    for i, benefit in enumerate(selected_benefits):\n",
    "        content = benefit.get('content')\n",
    "        metadata = benefit.get('metadata')\n",
    "        \n",
    "        # 1. LLMì„ í†µí•œ Anchor(ì§ˆë¬¸) ìƒì„±\n",
    "        chain = prompt | llm\n",
    "        try:\n",
    "            response = chain.invoke({\"benefit_content\": content})\n",
    "            ai_data = json.loads(response.content.strip().replace('```json', '').replace('```', ''))\n",
    "            \n",
    "            # 2. Negative ë°ì´í„° êµ¬ì„± (Hard Negative ì „ëµ)\n",
    "            # ë™ì¼í•œ ì¹´ë“œì˜ ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬ í˜œíƒì„ ìš°ì„ ì ìœ¼ë¡œ ì˜¤ë‹µìœ¼ë¡œ ì„ íƒ (ëª¨ë¸ì´ í—·ê°ˆë¦¬ê²Œ ë§Œë“¤ê¸° ìœ„í•¨)\n",
    "            same_card_others = [\n",
    "                b['content'] for b in all_benefits \n",
    "                if b['metadata']['card_id'] == metadata['card_id'] and b['metadata']['category'] != metadata['category']\n",
    "            ]\n",
    "            \n",
    "            if same_card_others:\n",
    "                negative_text = random.choice(same_card_others)\n",
    "            else:\n",
    "                # ë‹¤ë¥¸ ì¹´ë“œì˜ í˜œíƒì„ ë¬´ì‘ìœ„ë¡œ ì„ íƒ\n",
    "                other_random_benefit = random.choice([b for b in all_benefits if b['metadata']['card_id'] != metadata['card_id']])\n",
    "                negative_text = other_random_benefit['content']\n",
    "\n",
    "            # 3. ìµœì¢… Triplet êµ¬ì¡° ìƒì„±\n",
    "            result_item = {\n",
    "                \"anchor\": ai_data['anchor'],\n",
    "                \"positive\": content, # ì›ë˜ì˜ í˜œíƒ ë‚´ìš©\n",
    "                \"negative\": negative_text,\n",
    "                \"metadata\": {\n",
    "                    \"category\": metadata['category'],\n",
    "                    \"card_id\": metadata['card_id'],\n",
    "                    \"card_name\": metadata['card_name']\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            dataset.append(result_item)\n",
    "            print(f\"âœ… [{i+1}/{num_samples}] '{metadata['card_name']}'ì˜ '{metadata['category']}' ë°ì´í„° ìƒì„± ì™„ë£Œ\")\n",
    "            \n",
    "            # API ì œí•œ ë°©ì§€\n",
    "            time.sleep(0.5)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì—ëŸ¬ ë°œìƒ (Index {i}): {e}\")\n",
    "\n",
    "    # ê²°ê³¼ ì €ì¥\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(dataset, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"\\nâœ¨ ë°ì´í„°ì…‹ êµ¬ì¶• ì™„ë£Œ! íŒŒì¼ëª…: {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ì‹ ìš©ì¹´ë“œ ë°ì´í„°ë¥¼ ë¨¼ì € ì‹œë„í•´ë³´ì„¸ìš”.\n",
    "    generate_triplet_dataset('all_credit_benefits_rag.json', 'sbert_train_dataset.json', num_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1103f800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import random\n",
    "import nest_asyncio\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 1. ì£¼í”¼í„° ë…¸íŠ¸ë¶ ì´ë²¤íŠ¸ ë£¨í”„ ì¶©ëŒ ë°©ì§€\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# 2. ë¹„ë™ê¸° ëª¨ë¸ ë° í”„ë¡¬í”„íŠ¸ ì„¤ì •\n",
    "llm = ChatOpenAI(model=\"gpt-5-nano\", temperature=0.7)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ë‹¹ì‹ ì€ ì¹´ë“œ ì¶”ì²œ ì±—ë´‡ì˜ í•™ìŠµ ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\"),\n",
    "    (\"user\", \"\"\"ì•„ë˜ [í˜œíƒ ì •ë³´]ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìê°€ ë¬¼ì–´ë³¼ ë²•í•œ ìì—°ìŠ¤ëŸ¬ìš´ ì§ˆë¬¸ 1ê°œë¥¼ ìƒì„±í•˜ì„¸ìš”.\n",
    "    [í˜œíƒ ì •ë³´]: {benefit_content}\n",
    "    \n",
    "    ì¡°ê±´:\n",
    "    1. ì§ˆë¬¸(anchor)ì€ \"~ì‚´ì´ê³  ~í•œ ìƒí™©ì¸ë°\"ì™€ ê°™ì´ êµ¬ì²´ì ì¸ í˜ë¥´ì†Œë‚˜ê°€ ëŠê»´ì ¸ì•¼ í•©ë‹ˆë‹¤.\n",
    "    2. ê²°ê³¼ëŠ” ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”.\n",
    "    {{\n",
    "        \"anchor\": \"ìƒì„±ëœ ì§ˆë¬¸\",\n",
    "        \"positive\": \"ì œê³µëœ í˜œíƒ ì •ë³´ ë¬¸êµ¬ ê·¸ëŒ€ë¡œ ìœ ì§€\"\n",
    "    }}\n",
    "    \"\"\")\n",
    "])\n",
    "\n",
    "async def process_batch(batch_chunks, all_data):\n",
    "    chain = prompt | llm\n",
    "    tasks = [chain.ainvoke({\"benefit_content\": b['content']}) for b in batch_chunks]\n",
    "    \n",
    "    # return_exceptions=Trueë¡œ ì„¤ì •í•˜ì—¬ ì¼ë¶€ ìš”ì²­ ì‹¤íŒ¨ ì‹œì—ë„ ì „ì²´ê°€ ë©ˆì¶”ì§€ ì•Šê²Œ í•¨\n",
    "    responses = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "    \n",
    "    batch_results = []\n",
    "    for idx, res in enumerate(responses):\n",
    "        if isinstance(res, Exception):\n",
    "            # Rate Limit(429) ì—ëŸ¬ ë°œìƒ ì‹œ ë¡œê·¸ ì¶œë ¥\n",
    "            print(f\"âš ï¸ ìš”ì²­ ì‹¤íŒ¨ (ID {batch_chunks[idx]['metadata']['card_id']}): {res}\")\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            raw_content = res.content.strip().replace('```json', '').replace('```', '')\n",
    "            ai_data = json.loads(raw_content)\n",
    "            meta = batch_chunks[idx]['metadata']\n",
    "            \n",
    "            # Hard Negative ì„ íƒ\n",
    "            same_card_others = [\n",
    "                item['content'] for item in all_data \n",
    "                if item['metadata']['card_id'] == meta['card_id'] and item['metadata']['category'] != meta['category']\n",
    "            ]\n",
    "            negative_text = random.choice(same_card_others) if same_card_others else \"ê´€ë ¨ ì—†ëŠ” í˜œíƒ ì •ë³´ì…ë‹ˆë‹¤.\"\n",
    "\n",
    "            batch_results.append({\n",
    "                \"anchor\": ai_data['anchor'],\n",
    "                \"positive\": ai_data['positive'],\n",
    "                \"negative\": negative_text,\n",
    "                \"metadata\": {\n",
    "                    \"category\": meta['category'],\n",
    "                    \"card_id\": meta['card_id']\n",
    "                }\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ë°ì´í„° íŒŒì‹± ì—ëŸ¬: {e}\")\n",
    "            \n",
    "    return batch_results\n",
    "\n",
    "async def main():\n",
    "    input_file = 'all_credit_benefits_rag.json'\n",
    "    output_file = 'final_sbert_dataset.json'\n",
    "    \n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        all_benefits = json.load(f)\n",
    "\n",
    "    # ğŸš€ ë³‘ë ¬ ì²˜ë¦¬ ì†ë„ ì¡°ì ˆ (Rate Limitì— ê±¸ë¦¬ë©´ 10~15ë¡œ ì¤„ì´ì„¸ìš”)\n",
    "    batch_size = 20 \n",
    "    final_dataset = []\n",
    "    \n",
    "    print(f\"ğŸš€ ì´ {len(all_benefits)}ê±´ ì²˜ë¦¬ ì‹œì‘... (ë³‘ë ¬ í¬ê¸°: {batch_size})\")\n",
    "\n",
    "    for i in range(0, len(all_benefits), batch_size):\n",
    "        batch_chunks = all_benefits[i:i+batch_size]\n",
    "        results = await process_batch(batch_chunks, all_benefits)\n",
    "        final_dataset.extend(results)\n",
    "        \n",
    "        # 200ê°œë§ˆë‹¤ ì§„í–‰ ìƒí™© ì €ì¥ (ì£¼ê¸° ë‹¨ì¶•)\n",
    "        if (i + batch_size) % 200 == 0:\n",
    "            with open(output_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(final_dataset, f, ensure_ascii=False, indent=2)\n",
    "            print(f\"ğŸ’¾ {i + batch_size}/{len(all_benefits)} ì§„í–‰ ì¤‘... (íŒŒì¼ ì €ì¥ ì™„ë£Œ)\")\n",
    "        \n",
    "        # API ì„œë²„ íœ´ì‹ ì‹œê°„ (í•„ìˆ˜)\n",
    "        await asyncio.sleep(0.5)\n",
    "\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(final_dataset, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"âœ¨ ëª¨ë“  ì‘ì—… ì™„ë£Œ! ì´ {len(final_dataset)}ê°œ ìƒì„±ë¨.\")\n",
    "\n",
    "# --- ì£¼í”¼í„° ì‹¤í–‰ë¶€ ---\n",
    "if __name__ == \"__main__\":\n",
    "    # asyncio.run(main()) ëŒ€ì‹  awaitë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ê±°ë‚˜ nest_asyncioì™€ í•¨ê»˜ í˜¸ì¶œ\n",
    "    try:\n",
    "        loop = asyncio.get_event_loop()\n",
    "        loop.run_until_complete(main())\n",
    "    except Exception as e:\n",
    "        # ì´ë¯¸ ë£¨í”„ê°€ ë„ëŠ” ì¤‘ì´ë¼ë©´ ë°”ë¡œ await ì‹œë„\n",
    "        await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9eeaca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c58b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import json\n",
    "import random\n",
    "import nest_asyncio\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 1. ì£¼í”¼í„° ë…¸íŠ¸ë¶ í™˜ê²½ ì„¤ì •\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# 2. ëª¨ë¸ ì„¤ì • (gpt-4o-miniëŠ” TPM ì œí•œì´ ì—„ê²©í•˜ë¯€ë¡œ ì†ë„ ì¡°ì ˆì´ í•„ìˆ˜ì…ë‹ˆë‹¤)\n",
    "llm = ChatOpenAI(model=\"gpt-5-nano\", temperature=0.7)\n",
    "OUTPUT_FILE = 'final_compact_dataset2.json'\n",
    "\n",
    "# 3. í˜ë¥´ì†Œë‚˜ ì •ì˜\n",
    "PERSONA_EXAMPLES = \"\"\"\n",
    "[ì°¸ê³  í˜ë¥´ì†Œë‚˜ ì˜ˆì‹œ]\n",
    "1. 20ëŒ€ ì·¨ì—…ì¤€ë¹„ìƒ: ëŒ€ì¤‘êµí†µìœ¼ë¡œ ë§¤ì¼ í•™ì›ì— í†µì›í•˜ë©°, ì‹ë¹„ë¥¼ ì•„ë¼ê¸° ìœ„í•´ í¸ì˜ì ì—ì„œ ë¼ë‹ˆë¥¼ í•´ê²°í•¨.\n",
    "2. 30ëŒ€ ì—¬ì„± ì§ì¥ì¸: í•´ì™¸ì—¬í–‰ì„ ì¢‹ì•„í•˜ë©°, ë³‘ì›ì„ ë§ì´ ì´ìš©í•˜ê³  ìì°¨ë¥¼ ì†Œì§€í•¨.\n",
    "3. 20ëŒ€ ì‚¬íšŒì´ˆë…„ìƒ: ìì·¨ ì¤‘ì´ë¼ ê³µê³¼ê¸ˆ ë¶€ë‹´ì´ í¬ë©°, ë°°ë‹¬ ì•±ê³¼ ìŠ¤íŠ¸ë¦¬ë° êµ¬ë…ì„ ì¦ê¹€.\n",
    "4. 40ëŒ€ í•™ë¶€ëª¨: ìë…€ í•™ì›ë¹„ì™€ ë§ˆíŠ¸ ì¥ë³´ê¸°ê°€ ì£¼ ì§€ì¶œì´ë©° ì£¼ìœ ë¹„ ì ˆê°ì„ ì›í•¨.\n",
    "5. 30ëŒ€ ìê¸°ê³„ë°œëŸ¬: ìš´ë™ ì„¼í„° ê²°ì œê°€ ì¦ê³  ì˜¨ë¼ì¸ ì‡¼í•‘ê³¼ ì¹´í˜ ì´ìš©ì´ ë§ìŒ.\n",
    "\"\"\"\n",
    "\n",
    "# 4. í”„ë¡¬í”„íŠ¸ ì •ì˜\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", f\"ë‹¹ì‹ ì€ ì¹´ë“œ í˜œíƒ ë°ì´í„° ìš”ì•½ ë° ì§ˆë¬¸ ìƒì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\\n{PERSONA_EXAMPLES}\"),\n",
    "    (\"user\", \"\"\"ì•„ë˜ [í˜œíƒ ì •ë³´]ë¥¼ ë³´ê³  ì§ˆë¬¸ê³¼ 'ìš”ì•½ëœ ì •ë‹µ' ìŒì„ ìƒì„±í•˜ì„¸ìš”.\n",
    "\n",
    "[í˜œíƒ ì •ë³´]: {benefit_content}\n",
    "\n",
    "ì¡°ê±´:\n",
    "1. anchor: ì œì‹œëœ í˜ë¥´ì†Œë‚˜ë¥¼ ì°¸ê³ í•˜ì—¬ ì•„ì£¼ êµ¬ì²´ì ì¸ ìƒí™©ì´ ë‹´ê¸´ ì§ˆë¬¸ì„ ë§Œë“œì„¸ìš”.\n",
    "2. positive: ìœ„ í˜œíƒ ì •ë³´ì—ì„œ 'í•µì‹¬ í˜œíƒ'ê³¼ 'ì£¼ìš” ì¡°ê±´(ì „ì›”ì‹¤ì  ë“±)'ë§Œ ì¶”ì¶œí•˜ì—¬ 200~300ì ë‚´ì™¸ë¡œ ìš”ì•½í•˜ì„¸ìš”. ë¶ˆí•„ìš”í•œ ë¬¸êµ¬(ì—ë””í„° ì •ë³´ ë“±)ëŠ” ì œê±°í•˜ì„¸ìš”.\n",
    "3. ê²°ê³¼ëŠ” ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”.\n",
    "{{\n",
    "    \"anchor\": \"í˜ë¥´ì†Œë‚˜ ì§ˆë¬¸\",\n",
    "    \"positive\": \"ìš”ì•½ëœ í•µì‹¬ í˜œíƒ ë‚´ìš©\"\n",
    "}}\n",
    "\"\"\")\n",
    "])\n",
    "\n",
    "# 5. [ì¶”ê°€] ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ ê°œë³„ í˜¸ì¶œ í•¨ìˆ˜\n",
    "async def invoke_with_retry(chain, content, max_retries=5):\n",
    "    for i in range(max_retries):\n",
    "        try:\n",
    "            # 60ì´ˆ íƒ€ì„ì•„ì›ƒ ì ìš©í•˜ì—¬ ê°œë³„ ìš”ì²­ì´ ë¬´í•œ ëŒ€ê¸°í•˜ëŠ” ê²ƒ ë°©ì§€\n",
    "            return await asyncio.wait_for(chain.ainvoke({\"benefit_content\": content}), timeout=60.0)\n",
    "        except Exception as e:\n",
    "            if \"rate_limit\" in str(e).lower() or \"429\" in str(e):\n",
    "                # ì§€ìˆ˜ ë°±ì˜¤í”„: 2, 4, 8, 16ì´ˆ... + ëœë¤ ë…¸ì´ì¦ˆ\n",
    "                wait_time = (2 ** (i + 1)) + random.uniform(0, 1)\n",
    "                print(f\"â³ Rate Limit ë°œìƒ! {wait_time:.2f}ì´ˆ í›„ ì¬ì‹œë„... ({i+1}/{max_retries})\")\n",
    "                await asyncio.sleep(wait_time)\n",
    "            else:\n",
    "                # ì¼ë°˜ ì—ëŸ¬(íŒŒì‹± ë“±)ëŠ” ìƒìœ„ë¡œ ë˜ì§\n",
    "                raise e\n",
    "    return None\n",
    "\n",
    "# 6. ë¹„ë™ê¸° ë°°ì¹˜ ì²˜ë¦¬ í•¨ìˆ˜\n",
    "async def process_batch(batch_chunks, all_data):\n",
    "    chain = prompt | llm\n",
    "    # ê°œë³„ í•­ëª©ë§ˆë‹¤ ì¬ì‹œë„ ë¡œì§(invoke_with_retry)ì„ ì ìš©\n",
    "    tasks = [invoke_with_retry(chain, b['content']) for b in batch_chunks]\n",
    "    responses = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "    \n",
    "    batch_results = []\n",
    "    for idx, res in enumerate(responses):\n",
    "        if res is None or isinstance(res, Exception): \n",
    "            continue\n",
    "        try:\n",
    "            raw_content = res.content.strip().replace('```json', '').replace('```', '')\n",
    "            ai_data = json.loads(raw_content)\n",
    "            meta = batch_chunks[idx]['metadata']\n",
    "            \n",
    "            same_card_others = [\n",
    "                item['content'] for item in all_data \n",
    "                if item['metadata']['card_id'] == meta['card_id'] and item['metadata']['category'] != meta['category']\n",
    "            ]\n",
    "            \n",
    "            raw_neg = random.choice(same_card_others) if same_card_others else \"ì´ ì§ˆë¬¸ê³¼ ì§ì ‘ì ì¸ ê´€ë ¨ì´ ì—†ëŠ” í˜œíƒì…ë‹ˆë‹¤.\"\n",
    "            negative_text = raw_neg[:300] + \"...\" if len(raw_neg) > 300 else raw_neg\n",
    "\n",
    "            batch_results.append({\n",
    "                \"anchor\": ai_data['anchor'],\n",
    "                \"positive\": ai_data['positive'],\n",
    "                \"negative\": negative_text,\n",
    "                \"metadata\": {\n",
    "                    \"card_name\": meta['card_name'],\n",
    "                    \"category\": meta['category'],\n",
    "                    \"card_id\": meta['card_id'],\n",
    "                    \"corp\": meta.get('corp', 'ì•Œ ìˆ˜ ì—†ìŒ')\n",
    "                }\n",
    "            })\n",
    "        except:\n",
    "            continue\n",
    "    return batch_results\n",
    "\n",
    "# 7. ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜\n",
    "async def main():\n",
    "    # ë°ì´í„° ë¡œë“œ\n",
    "    files = ['all_credit_benefits_rag.json', 'all_check_benefits_rag.json']\n",
    "    all_benefits = []\n",
    "    for f in files:\n",
    "        if os.path.exists(f):\n",
    "            with open(f, 'r', encoding='utf-8') as f_in:\n",
    "                all_benefits.extend(json.load(f_in))\n",
    "\n",
    "    final_dataset = []\n",
    "    if os.path.exists(OUTPUT_FILE):\n",
    "        try:\n",
    "            with open(OUTPUT_FILE, 'r', encoding='utf-8') as f_out:\n",
    "                final_dataset = json.load(f_out)\n",
    "                print(f\"ğŸ”„ ê¸°ì¡´ ë°ì´í„° ë°œê²¬: {len(final_dataset)}ê±´ ì´í›„ë¶€í„° ì¬ê°œí•©ë‹ˆë‹¤.\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    processed_indices = len(final_dataset)\n",
    "    \n",
    "    # âœ… [ìˆ˜ì •] ë°°ì¹˜ ì‚¬ì´ì¦ˆë¥¼ ì¤„ì—¬ì„œ TPM ë¶€í•˜ ê°ì†Œ (20 -> 10)\n",
    "    batch_size = 10 \n",
    "\n",
    "    print(f\"ğŸš€ ì´ {len(all_benefits)}ê±´ ì¤‘ {len(all_benefits) - processed_indices}ê±´ ì²˜ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "    for i in range(processed_indices, len(all_benefits), batch_size):\n",
    "        batch = all_benefits[i:i+batch_size]\n",
    "        \n",
    "        try:\n",
    "            # ë°°ì¹˜ë‹¹ íƒ€ì„ì•„ì›ƒì€ ë„‰ë„‰í•˜ê²Œ 200ì´ˆ ì„¤ì •\n",
    "            results = await asyncio.wait_for(process_batch(batch, all_benefits), timeout=200.0)\n",
    "            final_dataset.extend(results)\n",
    "            \n",
    "            with open(OUTPUT_FILE, 'w', encoding='utf-8') as out:\n",
    "                json.dump(final_dataset, out, ensure_ascii=False, indent=2)\n",
    "            \n",
    "            print(f\"ğŸ’¾ {min(i + batch_size, len(all_benefits))} / {len(all_benefits)} ì™„ë£Œ\")\n",
    "            \n",
    "            # âœ… [ìˆ˜ì •] ë°°ì¹˜ ì™„ë£Œ í›„ ê°•ì œ íœ´ì‹ ì‹œê°„ ë¶€ì—¬ (TPM ì•ˆì •í™”)\n",
    "            await asyncio.sleep(1.0) \n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ë£¨í”„ ë‚´ë¶€ ì—ëŸ¬: {e}. 5ì´ˆ ëŒ€ê¸° í›„ ë‹¤ìŒ ë°°ì¹˜ ì‹œë„...\")\n",
    "            await asyncio.sleep(5)\n",
    "            continue\n",
    "\n",
    "    print(f\"âœ¨ ì‘ì—… ì™„ë£Œ! íŒŒì¼: {OUTPUT_FILE}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sesac-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
